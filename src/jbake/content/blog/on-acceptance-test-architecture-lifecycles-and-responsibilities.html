title=On acceptance test architecture, lifecycles and responsibilitiesdate=2013-12-18type=posttags=acceptance test, atdd, cucumber, fitnesse, gherkin, SUT, tdd, test automation, test fixturestatus=publishedsummary=I was recently in a conversation with testers about how acceptance tests should be structured.   As we revisit how Blackboard conducts test automation, we were looking at patterns and practices to employ.  I shared my following perspective on how to think about the architecture of your acceptance test infrastructure, the lifecycle of a specification, as well as who should conduct which step.~~~~~~<p>I was recently in a conversation with testers about how acceptance tests should be structured.   As we revisit how Blackboard conducts test automation, we were looking at patterns and practices to employ.  I shared my following perspective on how to think about the architecture of your acceptance test infrastructure, the lifecycle of a specification, as well as who should conduct which step.  This post is really a teaser post, as I am merely smearing pretty pictures on the web, without much background.  Isn't that what follow-up blogs are for?</p><h1>Acceptance Test Composition</h1><p><img alt="Acceptance Test Architecture" src="http://farm8.staticflickr.com/7386/11433880614_d8966527ab.jpg" /></p><p>A well formed acceptance test architecture is composed of five core components:</p><ol><li><b><span style="text-decoration:underline;">Specification</span></b> - This is the document that describes what the system should be doing. The requirement that will be exercised by the application.  In an automated testing framework, this is usually implemented in <a title="Gherkin " href="https://github.com/cucumber/cucumber/wiki/Gherkin" target="_blank">Gherkin</a> (<a title="Cucumber" href="https://github.com/cucumber/cucumber" target="_blank">Cucumber</a>) or a wiki (<a title="Fitnesse" href="http://fitnesse.org/" target="_blank">Fitnesse</a>).  It should be easily read and understood by all members of the organization at any level and written in the business language.  I recommend collaboratively white boarding your specs (a la <a title="Three Amigos Meeting" href="https://www.scrumalliance.org/community/articles/2013/2013-april/introducing-the-three-amigos" target="_blank">Three Amigos meeting</a>) and have somebody write it in the technology later.</li><li><b><span style="text-decoration:underline;">Fixture</span></b> - This is the glue code.  This code understands the format that the specification is written in, and knows how to talk to either the application driver or the Automation Layer to implement the features of a test.  This is generally code.  Ideally it is written in a language similar to the SUT so everybody can update it.  In Cucumber, these are the <a title="Step Definitions" href="https://github.com/cucumber/cucumber/wiki/Step-Definitions" target="_blank">Step Definitions</a> and in Fitnesse these <a title="Fitnesse Fixtures" href="http://fitnesse.org/FitNesse.UserGuide.FixtureGallery" target="_blank">Fixtures</a>.</li><li><b><span style="text-decoration:underline;">Automation (DSL)</span></b> - Don't start building this from day one.  The automation layer is the <a title="Domain Specific Language" href="http://martinfowler.com/books/dsl.html" target="_blank">Domain Specific Language (DSL)</a> that will evolve as you build out your fixtures.  It is an abstraction layer over the application driver.  If you design this correctly to be a <a title="Fluent Interface" href="http://martinfowler.com/bliki/FluentInterface.html" target="_blank">fluent API</a> or even a full on DSL, then you will find that non-technical members of the team can look at this an possibly even contribute here.  But don't set out to build a DSL...cause that ain't easy.</li><li><b><span style="text-decoration:underline;">Application Driver</span></b> - This is the code that knows how to talk to the system under test.  For a web application, this is typically a framework like <a title="Selenium" href="http://www.seleniumhq.org/" target="_blank">Selenium</a>.  If you are writing tests for a web service, then you will need to pick a tool that can send/receive SOAP or REST messages.  If your application is a batch processing system that takes a package of zipped XML files and puts them in the database, then you need to build a custom framework that knows how to build the zip file, and verify the database got updated properly.</li><li><b><span style="text-decoration:underline;">System Under Test (SUT)</span></b> - This is the product you are building.  This is what you are testing.</li></ol><h1>Acceptance Test Lifecycle</h1><p><img alt="Specification by Example Phases" src="http://farm8.staticflickr.com/7298/11433913676_995322ff97.jpg" /><br />An acceptancetest should evolve collaboratively via a cross functional team.  I think about it in three phases:</p><ol><li><b><span style="text-decoration:underline;">Collaborate and Define</span></b> - This is typically where you have a 'Three Amigos Meeting' where members of the business/analysts, testers, and engineers (and others too) will get together and write the requirement and the acceptance criteria.  This can happen on a white board or on paper.</li><li><b><span style="text-decoration:underline;">Automation Phase</span></b> - Once a specification has been authored, then the specification will be captured in the automated testing tool and checked into version control.  Then the test fixture and DSL will be authored to automate the failing test.</li><li><b><span style="text-decoration:underline;">Verification Phase</span></b> - This is the last phase.  The code to satisfy the test is written now.  The details of the DSL might also be filled in here (for instance, elements on the page to be called).  The test is then run and re-run until it passes.  When the test passes, the feature is "DONE".  The verification will continue via continuous integration.</li></ol><p>You may note that you this may smell like <a title="Test Driven Development" href="http://en.wikipedia.org/wiki/Test-driven_development" target="_blank">Test Driven Development</a>.  It should, cause it is...or <a title="(PDF) Chapter on ATDD" href="http://www.manning-source.com/books/koskela/Chapter9Sample.pdf" target="_blank">Acceptance Test Driven Development</a>.</p><h1>Responsibilities</h1><p><img alt="Specification by Example Roles" src="http://farm4.staticflickr.com/3673/11433879264_41b8eb6bfd.jpg" /><br />I would also like to comment on who should do what.</p><ul><li><b><span style="text-decoration:underline;">Business and/or Analyst</span></b> - should focus on the user story and the acceptance criteria.</li><li><b><span style="text-decoration:underline;">QA</span></b> - should focus on the user story, acceptance criteria, the test fixture and the DSL.</li><li><b><span style="text-decoration:underline;">Engineer</span></b> - An engineer should be involved in all aspects of the acceptance test.  They are ultimately responsible for satisfying the requirement.</li></ul><p>I firmly believe that an engineer (or an Engineer in Test) needs to be focused on the DSL layer and the SUT.  This is heavy coding and design and should be not be where "testers learning to code" should focus their time.</p>