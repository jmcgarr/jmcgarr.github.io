<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Mike McGarr's Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keywords" content="">
    <meta name="generator" content"JBake">

    <!-- Le styles -->
    <link href="/css/bootstrap.min.css" rel="stylesheet">
    <link href="/css/asciidoctor.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link href="/css/bootstrap-responsive.min.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="/js/html5shiv.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="favicon.ico">
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-49993013-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
  </head>
  <body>
    <div id="wrap">
	
	<!-- Fixed navbar -->
      <div class="navbar navbar-fixed-top">
        <div class="navbar-inner">
          <div class="container">
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="brand" href="/">Mike McGarr's Blog</a>
            <div class="nav-collapse collapse">
              <ul class="nav">
                <li><a href="/about.html">About</a></li>
                <li><a href="/archive.html">Blog</a></li>
                <li><a href="/feed.xml">Subscribe</a></li>
              </ul>
            </div><!--/.nav-collapse -->
          </div>
        </div>
      </div>
      <div class="container">
	<div class="page-header">
		<h1>Blog</h1>
	</div>
  			<a href="/blog/on-acceptance-test-architecture-lifecycles-and-responsibilities.html"><h1>On acceptance test architecture, lifecycles and responsibilities</h1></a>
  			<p>18 December 2013</p>
  			<p><p>I was recently in a conversation with testers about how acceptance tests should be structured.   As we revisit how Blackboard conducts test automation, we were looking at patterns and practices to employ.  I shared my following perspective on how to think about the architecture of your acceptance test infrastructure, the lifecycle of a specification, as well as who should conduct which step.  This post is really a teaser post, as I am merely smearing pretty pictures on the web, without much background.  Isn't that what follow-up blogs are for?</p>
<h1>Acceptance Test Composition</h1>
<p><img alt="Acceptance Test Architecture" src="http://farm8.staticflickr.com/7386/11433880614_d8966527ab.jpg" /></p>
<p>A well formed acceptance test architecture is composed of five core components:</p>
<ol>
<li><b><span style="text-decoration:underline;">Specification</span></b> - This is the document that describes what the system should be doing. The requirement that will be exercised by the application.  In an automated testing framework, this is usually implemented in <a title="Gherkin " href="https://github.com/cucumber/cucumber/wiki/Gherkin" target="_blank">Gherkin</a> (<a title="Cucumber" href="https://github.com/cucumber/cucumber" target="_blank">Cucumber</a>) or a wiki (<a title="Fitnesse" href="http://fitnesse.org/" target="_blank">Fitnesse</a>).  It should be easily read and understood by all members of the organization at any level and written in the business language.  I recommend collaboratively white boarding your specs (a la <a title="Three Amigos Meeting" href="https://www.scrumalliance.org/community/articles/2013/2013-april/introducing-the-three-amigos" target="_blank">Three Amigos meeting</a>) and have somebody write it in the technology later.</li>
<li><b><span style="text-decoration:underline;">Fixture</span></b> - This is the glue code.  This code understands the format that the specification is written in, and knows how to talk to either the application driver or the Automation Layer to implement the features of a test.  This is generally code.  Ideally it is written in a language similar to the SUT so everybody can update it.  In Cucumber, these are the <a title="Step Definitions" href="https://github.com/cucumber/cucumber/wiki/Step-Definitions" target="_blank">Step Definitions</a> and in Fitnesse these <a title="Fitnesse Fixtures" href="http://fitnesse.org/FitNesse.UserGuide.FixtureGallery" target="_blank">Fixtures</a>.</li>
<li><b><span style="text-decoration:underline;">Automation (DSL)</span></b> - Don't start building this from day one.  The automation layer is the <a title="Domain Specific Language" href="http://martinfowler.com/books/dsl.html" target="_blank">Domain Specific Language (DSL)</a> that will evolve as you build out your fixtures.  It is an abstraction layer over the application driver.  If you design this correctly to be a <a title="Fluent Interface" href="http://martinfowler.com/bliki/FluentInterface.html" target="_blank">fluent API</a> or even a full on DSL, then you will find that non-technical members of the team can look at this an possibly even contribute here.  But don't set out to build a DSL...cause that ain't easy.</li>
<li><b><span style="text-decoration:underline;">Application Driver</span></b> - This is the code that knows how to talk to the system under test.  For a web application, this is typically a framework like <a title="Selenium" href="http://www.seleniumhq.org/" target="_blank">Selenium</a>.  If you are writing tests for a web service, then you will need to pick a tool that can send/receive SOAP or REST messages.  If your application is a batch processing system that takes a package of zipped XML files and puts them in the database, then you need to build a custom framework that knows how to build the zip file, and verify the database got updated properly.</li>
<li><b><span style="text-decoration:underline;">System Under Test (SUT)</span></b> - This is the product you are building.  This is what you are testing.</li>
</ol>
<h1>Acceptance Test Lifecycle</h1>
<p><img alt="Specification by Example Phases" src="http://farm8.staticflickr.com/7298/11433913676_995322ff97.jpg" /><br />
An acceptancetest should evolve collaboratively via a cross functional team.  I think about it in three phases:</p>
<ol>
<li><b><span style="text-decoration:underline;">Collaborate and Define</span></b> - This is typically where you have a 'Three Amigos Meeting' where members of the business/analysts, testers, and engineers (and others too) will get together and write the requirement and the acceptance criteria.  This can happen on a white board or on paper.</li>
<li><b><span style="text-decoration:underline;">Automation Phase</span></b> - Once a specification has been authored, then the specification will be captured in the automated testing tool and checked into version control.  Then the test fixture and DSL will be authored to automate the failing test.</li>
<li><b><span style="text-decoration:underline;">Verification Phase</span></b> - This is the last phase.  The code to satisfy the test is written now.  The details of the DSL might also be filled in here (for instance, elements on the page to be called).  The test is then run and re-run until it passes.  When the test passes, the feature is "DONE".  The verification will continue via continuous integration.</li>
</ol>
<p>You may note that you this may smell like <a title="Test Driven Development" href="http://en.wikipedia.org/wiki/Test-driven_development" target="_blank">Test Driven Development</a>.  It should, cause it is...or <a title="(PDF) Chapter on ATDD" href="http://www.manning-source.com/books/koskela/Chapter9Sample.pdf" target="_blank">Acceptance Test Driven Development</a>.</p>
<h1>Responsibilities</h1>
<p><img alt="Specification by Example Roles" src="http://farm4.staticflickr.com/3673/11433879264_41b8eb6bfd.jpg" /><br />
I would also like to comment on who should do what.</p>
<ul>
<li><b><span style="text-decoration:underline;">Business and/or Analyst</span></b> - should focus on the user story and the acceptance criteria.</li>
<li><b><span style="text-decoration:underline;">QA</span></b> - should focus on the user story, acceptance criteria, the test fixture and the DSL.</li>
<li><b><span style="text-decoration:underline;">Engineer</span></b> - An engineer should be involved in all aspects of the acceptance test.  They are ultimately responsible for satisfying the requirement.</li>
</ul>
<p>I firmly believe that an engineer (or an Engineer in Test) needs to be focused on the DSL layer and the SUT.  This is heavy coding and design and should be not be where "testers learning to code" should focus their time.</p>
</p>
  			<a href="/blog/2013-six-month-check-point.html"><h1>2013 Six Month Check-point</h1></a>
  			<p>01 July 2013</p>
  			<p><p>It has been far too long since <a href="http://earlyandoften.wordpress.com/2013/03/19/improving-my-shell-fu-oh-my-zsh/" target="_blank">I last blogged</a>.  There have been a number of reasons, most notably work, family and golf (yeah golf!).  But too much has happened since I last blogged…so I need to get back into it.</p>
<p>Before I go into all the fun things I have been doing, I figured I would do a quick status check on <a title="Goals for 2013" href="http://earlyandoften.wordpress.com/2013/02/05/goals-for-2013/" target="_blank">the goals I set at the beginning of the year</a>.  Let's go through them one by one:</p>
<ul>
<li><strong>Reading List</strong> - Like everything else, I have slowed a down my reading a bit.  Here's what I have read so far.
<ul>
<li><a title="A Game of Thrones: A Feast for Crows" href="http://www.amazon.com/dp/055358202X" target="_blank">Game of Thrones: A Feast for Crows</a></li>
<li><a title="Game of Thrones: A Dance of Dragons (Amazon)" href="http://www.amazon.com/Dance-Dragons-Song-Fire-Book/dp/0553582011/ref=pd_sim_b_3" target="_blank">Game of Thrones: A Dance of Dragons</a></li>
<li><a title="The Phoenix Project" href="http://www.amazon.com/The-Phoenix-Project-Helping-Business/dp/0988262592" target="_blank">The Phoenix Project</a></li>
<li><a title="Kanban book" href="http://www.amazon.com/Kanban-Successful-Evolutionary-Technology-Business/dp/0984521402" target="_blank">Kanban</a></li>
<li><a title="Putting out of Your Mind" href="http://www.amazon.com/Putting-Out-Your-Mind-Rotella/dp/0743212134" target="_blank">Putting out of your Mind</a></li>
</ul>
</li>
<li><strong>Blackboard</strong> - Am I killing it?  I guess I didn't really set a <a title="SMART Criteria " href="http://en.wikipedia.org/wiki/SMART_criteria" target="_blank">SMART</a> goal here.  Definitely have a long way to go for me to declare success, but I am having a blast!</li>
<li><strong>Blogging</strong> - This is a big blemish.  I was supposed to write 1 blog entry a week for the year.  So far, this entry marks 11th entry.  I am 14 weeks behind schedule.  Challenge accepted!</li>
<li><strong>DC Continuous Integration, Delivery and Deployment Meetup</strong> - <a title="The DC CI Meetup" href="http://www.meetup.com/DC-continuous-integration" target="_blank">This group</a> has far exceeded my expectations.  Here are the metrics:
<ul>
<li>Targeted 250 members, <a title="DC CI Membership" href="http://www.meetup.com/DC-continuous-integration/members/" target="_blank">currently at 360+</a>.  Awesome!</li>
<li>We have met once a month so far</li>
<li>No workshops scheduled</li>
</ul>
</li>
<li><strong>Public Speaking</strong> - I will talk about this more in future blogs, but so far.  Here's where I stand:
<ul>
<li>Public Speaking Events - I have given three talks this year, two of them were repeats. This is complete.</li>
<li>New Talks Given - None given, but one scheduled.  More on that later.</li>
</ul>
</li>
<li><strong>Chef</strong> - I have made some progress but not as much as I would like.  I am hoping the addition of a new team member will help create some progress in this area.</li>
<li><strong>Jenkins Plugins</strong> - Technically speaking, I was able to do this.  I had <a title="Accepted Pull Request" href="https://github.com/jenkinsci/job-dsl-plugin/pull/30" target="_blank">a pull request accepted</a> for the <a title="Jenkins Job DSL plugin" href="https://github.com/jenkinsci/job-dsl-plugin" target="_blank">Jenkins Job DSL plugin</a>.  We recently had an <a title="Twitter Feed of Innovation Day" href="https://twitter.com/search?q=%23bbinnovate13&amp;src=hash" target="_blank">Innovation Day</a> (hack event) at Blackboard and <a title="Michael Dumont" href="https://twitter.com/thedumontster" target="_blank">Michael Dumont</a> and I were able to add a simple feature to the <a title="Etsy Master Project Plugin" href="https://github.com/etsy/jenkins-master-project" target="_blank">Etsy Master Project Jenkins Plugin</a>.  Pull request pending.</li>
<li><strong>Ruby</strong> - No progress to date, other than Chef work.  Hopefully I can find a window to focus on this.</li>
</ul>
<p>All in all, I do feel like this year is right on track, with the exception of this blog.  I have promised myself to focus more on blogging, so expect good things.</p>
</p>
  			<a href="/blog/improving-my-shell-fu-oh-my-zsh.html"><h1>Improving my Shell-fu: Oh My Zsh</h1></a>
  			<p>19 March 2013</p>
  			<p><p>I have been recently diving head first into the wonderful world of the shell.  Having spent a fair amount of my career on Windows machines at work (even though I have been using Mac's at home for 6+ years), it's only in the past year that I have made the full switch to 100% Mac for work and home.  I have found that this has enabled me to focus on learning more about the shell.  (no more cmd for me!)</p>
<p>As part of this experience, I have also picked up a bunch of tips and tools from a bunch of my co-workers here at <a title="Blackboard" href="http://www.blackboard.com/" target="_blank">Blackboard</a>.  I also have been picking up some tips from various other sources, most notably the <a title="Changelog podcast" href="http://thechangelog.com/podcast/" target="_blank">Changelog podcast</a>.  I wanted to start sharing of these tools, setups and experiences since I am excited about them.  Rather than one giant blog, I will release them in a series of blogs called <a title="Shell-fu series of blogs" href="http://earlyandoften.wordpress.com/tag/shell-fu/" target="_blank">Shell-fu</a>.  The first Shell-fu blog is on <a title="Oh my Zsh" href="https://github.com/robbyrussell/oh-my-zsh" target="_blank">Oh My Zsh</a> (OMZ).</p>
<h2>Oh My Zsh</h2>
<p>I have heard about <a title="Zsh" href="http://www.zsh.org/" target="_blank">zsh</a> for a while and I knew people were switching over in droves.  It wasn't until I heard the Changelog podcast <a title="Changelog podcast on Oh My Zsh" href="http://thechangelog.com/episode-0-6-1-oh-my-zsh-with-robby-russell/" target="_blank">episode on Oh My Zsh</a> that I decided to give it a try.  I was impressed with how simple it was to install and setup (Note: make sure you backup all your dot files from your home directory first, just in case):</p>
<pre class="prettyprint linenums language-bash">
curl -L https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh | sh
</pre>
<p>These are the OMZ killer features.</p>
<h2>Zsh</h2>
<p>The best feature of Oh My Zsh is Zsh itself.  I am just learning Zsh, but so far there are immediately two things it does much better than bash.</p>
<h4>Autocomplete</h4>
<p>Zsh is built with an autocomplete feature that is awesome.  When I type 'vi &lt;tab&gt;', zsh will present me with a list of the files in my current directory.  If I press &lt;tab&gt; a second time though, it highlights the first one in the list.  At which point I can just cycle through the files with my arrow keys and select the one I want.  Pretty cool huh?  the autocomplete can also help you see what commands are in your path.  Type 'v &lt;tab&gt;' and I can see all the commands that start with v.</p>
<p>The autocomplete is very much command aware as well.  <a title="Mike Grouchy" href="http://mikegrouchy.com/" target="_blank">Mike Grouchy's</a> <a title="Zsh is your friend" href="http://mikegrouchy.com/blog/2012/01/zsh-is-your-friend.html" target="_blank">Zsh blog</a> shows how when you type 'kill &lt;tab&gt;', you get a list of the available processes you can kill.  Now that is awesome!</p>
<p>I also stumbled upon this feature recently.  The autocomplete works with your history to combine into an awesome feature.  If I type 'ssh &lt;up arrow&gt;' it will go back into my history to the last ssh command I ran.  Wow!</p>
<h4>Autocorrect</h4>
<p>If you type a command, Zsh will help you out.  For instance, if I type 'vargant up &lt;enter&gt;', Zsh stops me and says are you sure this command is right.  Looks like you are trying to type 'vagrant'.  It gives you four options: (n)o, (y)es, (a)bort, and (e)dit.  (n)o will run the uncorrected command, (y) runs the autocorrected command, (a) exits to a blank prompt and (e) exits to a prompt with the command you wrote written out.</p>
<pre>
mmcgarr@mmcgarrmbp:~/Code » vargant up
zsh: correct 'vargant' to 'vagrant' [nyae" frameborder="0" allowfullscreen></iframe>?
mmcgarr@mmcgarrmbp:~/Code » vargant up
</pre>
<h2>Themes</h2>
<p>At first, I wanted to try OMZ because I wanted to checkout all of the themes.  This sounds dumb, but I was curious how if there were any good shell themes out there.  I had been previously using <a title="dotfiles" href="https://github.com/jmcgarr/dotfiles" target="_blank">dotfiles</a> on Bash and aware of some the things you can add to your prompt.  OMZ has over 60 themes you can try out and are easily configured via the ~/.zshrc file.  I tried the 'random' feature at first which shows a new theme for every prompt you open.  This is a great way to explore the themes.  I have currently settled on 'dpoggi' theme (see screenshot below).  Check out all the themes <a title="Oh my Zsh themes" href="https://github.com/robbyrussell/oh-my-zsh/wiki/themes" target="_blank">here</a>.</p>
<p>Additionally, you will note in the below screenshot, that my prompt says '(master)' with a lightning bolt.  Most of the themes have built in git awareness.  Which means when you are in the directory of a git project, it will show you which branch you are in, as well as whether or not you uncommitted changes (the lightning bolt).  Each of them does this a bit different.  Worth exploring.</p>
<h2>Plugins</h2>
<p>The next thing I checked out were the plugins.  OMZ comes with a bunch of plugins.  These plugins add shell magic for specific frameworks, like auto-complete and additional context information.  Of course you can see that these plugins are building upon Zsh's awesome auto-complete features.  For example, I added the vagrant OMZ plugin and when I type 'vagrant &lt;tab&gt;', it presents me with a list of the available commands for vagrant.</p>
<p><a href="http://earlyandoften.files.wordpress.com/2013/03/ohmyzsh-vagrant.png"><img class="aligncenter size-large" alt="ohmyzsh-vagrant" src="http://earlyandoften.files.wordpress.com/2013/03/ohmyzsh-vagrant.png?w=594" width="594" height="256" /></p>
<p></a>Enabling/disabling a plugin is as simple as editing the ~/.zshrc file and updating the following line.  As you can see, I enabled the vagrant, knife and gradle plugins (git enabled by default).</p>
<pre class="prettyprint linenums">
plugins=(git vagrant knife gradle)
</pre>
<p>For a list of all the plugins, check out <a title="Oh My Zsh Plugins" href="https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins" target="_blank">this wiki page</a>.</p>
<h2>Conclusion</h2>
<p><span style="font-size:13px;">OMZ and Zsh have a ton of other features that I will not get into in this blog post.  You should definitely check out their <a title="Oh My Zsh Cheatsheet" href="https://github.com/robbyrussell/oh-my-zsh/wiki/Cheatsheet" target="_blank">cheatsheet</a> as well.  If you are on a Mac and just using bash, I highly recommend trying Oh My Zsh.  It is awesome and worth it!</span></p>
</p>
  			<a href="/blog/mastering-jenkins-making-bulk-updates-to-jobs.html"><h1>Mastering Jenkins: Making Bulk Updates to Jobs</h1></a>
  			<p>11 March 2013</p>
  			<p><p>I recently needed to make the same update to a large number of Jenkins jobs.  Essentially, we decided to change our naming convention for our jobs.  A simple change.  In order to achieve this, I took advantage of the Jenkins Script Console.</p>
<p>The Jenkins Script Console allows you to run Groovy code against Jenkins to execute a task.  The Script Console provides access to Jenkins' underlying API's, which allows you to conduct almost any task.  The Script Console is available to any running Jenkins instance at '/script' or through the menus by navigating to 'Manage Jenkins &gt; Script Console'.  In order to effectively use the Script Console, you will likely need to become familiar with <a title="Jenkins JavaDocs" href="http://javadoc.jenkins-ci.org/" target="_blank">Jenkins' API's</a>.</p>
<p><a href="http://earlyandoften.files.wordpress.com/2013/03/jenkins-script-console.png"><img class="aligncenter size-large wp-image-1402" alt="Jenkins Script Console" src="http://earlyandoften.files.wordpress.com/2013/03/jenkins-script-console.png?w=594" width="594" height="533" /></a></p>
<p>In my case, I wanted to execute a script that found all jobs matching a particular naming convention and rename them.  In our case, we had two naming conventions being used and we wanted them to all match.  We had jobs names that followed one of two formats:</p>
<ul>
<li>camel case, with underscores and dashes like:  'FUN-ArtifactName_Branch-Commit'</li>
<li>human readable like: 'FUN-ArtifactName (Branch)'</li>
</ul>
<p>My goal was to rename both sets of job names to look like 'fun-artifactname_branch-commit' (lower case, underscores and dashes).  Here's the script I executed:</p>
<pre class="prettyprint languague-groovy">
for (item in Hudson.instance.items) {
    name = item.name
    if (name.startsWith('FUN-')) {
      if (name.endsWith('Commit')) {
        def newName = name.toLowerCase()
        item.renameTo(newName)
      } else {
        def newName = name.replaceFirst(/\s\(/, &quot;_&quot;)
        newName = newName.replaceFirst(/\)/, &quot;-commit&quot;)
        newName = newName.toLowerCase()
        item.renameTo(newName)
      }
    }
}
</pre>
<p>Like I said before, you need to understand Jenkins' underlying API's. In this script, I am iterating through the items on Jenkins (formerly Hudson, hence the old class name). I then grab the name of the item of only rename those items starting with the 'FUN-' prefix. For jobs in the camel case format, they all have a 'Commit' at the end of their name. For them, I just make sure the name is lowercase. For the human readable names, I need to use the replaceFirst method to reformat the names. Also note that I need to call the renameTo() method. That's it!</p>
<p>For more examples of Groovy scripts for the Jenkins Script Console, I recommend you check out the <a title="Jenkins Script Console Wiki Page" href="https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+Script+Console" target="_blank">Jenkins Script Console wiki page</a>.</p>
</p>
  			<a href="/blog/dc-tech-ops-meetup.html"><h1>DC Tech Ops Meetup Alliance (aka the Super Friends)</h1></a>
  			<p>21 February 2013</p>
  			<p><p>On Tuesday night, my meetup group (<a title="DC Continuous Integration, Delivery, &amp; Deployment Group" href="http://www.meetup.com/DC-continuous-integration/" target="_blank">DC Continuous Integration, Delivery and Deployment Group</a>) joined forces with a number of other groups to present the most awesome gathering we have ever known.  The meeting was the brainchild of <a title="Nathen Harvey" href="http://www.nathenharvey.com/" target="_blank">Nathen Harvey</a>, who runs the <a title="DevOpsDC" href="http://www.meetup.com/DevOpsDC/" target="_blank">DevOpsDC</a> and <a title="MongoDC" href="http://www.meetup.com/Washington-DC-MongoDB-Users-Group/" target="_blank">MongoDC</a> user groups and works for <a title="OpsCode" href="http://www.opscode.com/" target="_blank">OpsCode</a> as their Technical Community Manager.  Nathen sent an email with the subject of 'DC Tech Ops Meetup Alliance (aka the Super Friends)'...how could I not be in.</p>
<p><a title="DevOpsDC Meeting Invite" href="http://www.meetup.com/DevOpsDC/events/97686352/" target="_blank">The</a> meeting brought together <a title="Big Data DC" href="http://www.meetup.com/bigdatadc/" target="_blank">Big Data DC</a>, <a title="Crabby Admins" href="http://crabbyadmins.org/" target="_blank">Crabby Admins - LOPSA, Baltimore Chapter</a>, <a title="DCAST" href="http://www.meetup.com/D-CAST/" target="_blank">DC Agile Software Testing Group (DCAST)</a>, <a title="DC Continuous Integration, Delivery and Deployment Group" href="http://www.meetup.com/DC-continuous-integration/" target="_blank">DC Continuous Integration, Delivery, &amp; Deployment Group</a>, <a title="DevOpsDC" href="http://www.meetup.com/DevOpsDC/" target="_blank">DevOpsDC</a>, <a title="LOPSA" href="http://www.meetup.com/lopsadc/" target="_blank">LOPSA DC - The League of Professional System Administrators</a>, <a title="NOVA MySQL" href="http://www.meetup.com/NOVA-MySQL/" target="_blank">NOVA MySQL</a>, <a title="Arlington Ruby" href="http://www.meetup.com/Arlington-Ruby/" target="_blank">Arlington Ruby</a> and <a title="DC Ruby User Group" href="http://www.dcrug.org/" target="_blank">DC Ruby User Group</a>.</p>
<p>For the meeting, we brought in some great speakers.  First, we had <a title="Avleen Vig" href="https://twitter.com/avleen" target="_blank">Avleen Vig</a> and <a title="Patrick McDonnell" href="https://twitter.com/mcdonnps" target="_blank">Patrick McDonnell</a> from <a title="Etsy" href="http://www.etsy.com/" target="_blank">Etsy</a> to talk about <a title="OpsSchool" href="http://www.opsschool.org/en/latest/" target="_blank">Ops School</a>.  Here's the video:</p>
<p><iframe width="640" height="360" src="//www.youtube.com/embed/0gx7oQaAy6g" frameborder="0" allowfullscreen></iframe></p>
<p>After Avleen and Patrick, <a title="Theo Schlossnagle" href="http://omniti.com/is/theo-schlossnagle" target="_blank">Theo Schlossnagle</a>, CEO of <a title="OmniTI" href="http://omniti.com/" target="_blank">OmniTI</a>  was up next.  We were lucky enough that he gave two presentations.  The first was a short presentation on How to Tie Your Shoes the Right Way (I love the unicorns):</p>
<p><iframe width="640" height="360" src="//www.youtube.com/embed/UQ6UNhdP6Ic" frameborder="0" allowfullscreen></iframe></p>
<p>Next, Theo gave a great presentation on careers.  It was spot on and definitely worth watching.  Here's the video:</p>
<p><iframe width="640" height="360" src="//www.youtube.com/embed/qyxUIY72ywc" frameborder="0" allowfullscreen></iframe></p>
<p>I want to send a special thank you to Nathen for making this all happen.  It was a great night.  I definitely look forward to further collaborations between DevOpsDc and my meetup.  If you are looking for the original meeting invite, here it is.  Enjoy the videos.</p>
</p>
  			<a href="/blog/the-phoenix-project.html"><h1>Book Review: The Phoenix Project</h1></a>
  			<p>21 February 2013</p>
  			<p><p><img alt="" src="https://pbs.twimg.com/media/BBQcthgCAAAlL8D.jpg:large" width="1" height="1" /><a href="http://earlyandoften.files.wordpress.com/2013/02/thephoenixproject.jpg"><img align="left" alt="thePhoenixProject" src="http://earlyandoften.files.wordpress.com/2013/02/thephoenixproject.jpg?w=300" width="300" height="225" /></a>I recently completed '<a title="The Phoenix Project Book" href="http://itrevolution.com/books/phoenix-project-devops-novel/" target="_blank">The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win</a>' and thought I would write a review.  I mainly wanted to capture notes and thoughts about the book for myself.</p>
<p><strong>The Story</strong></p>
<p>First off, hat's off to the authors (<a title="Gene Kim" href="http://itrevolution.com/authors/gene-kim/" target="_blank">Gene Kim</a>, <a title="Kevin Behr" href="http://itrevolution.com/authors/kevin-behr/" target="_blank">Kevin Behr</a>, and <a title="George Spafford" href="http://itrevolution.com/authors/george-spafford/" target="_blank">George Spafford</a>) for turning the world of IT, operations and DevOps into a riveting story.  I could not tear myself away from the book and was genuinely interested.  It was definitely a page turner.  I found myself really hating certain characters which made the story that much better.  The book moves at a frantic pace as problems and issues pile upon each other.</p>
<p>The book tells the fictional story of Bill Palmer, an IT manager at Parts Unlimited (also fictional).  Bill is suddenly promoted to VP of IT Operations and the future of the company is quickly put on his shoulders.  Bill finds himself in production outage after outage, trying to keep the business operational.  His attempts to improve the operation's team success are filled with trials and challenges.   Bill is guided towards the path of righteousness by Erik Reid, a potential board member and lean expert.</p>
<p>I found myself drawing parallels between Bill Palmer's (the book's main character) plight and some of the challenges I was facing at <a title="Blackboard, Inc." href="http://www.blackboard.com/">Blackboard</a>.  Now I have to admit that my situation is very different (not nearly as hectic), but I definitely took a lot from this book.</p>
<p><strong>It's all about Culture</strong></p>
<p>If you read enough about the DevOps movement, you will hear this slogan beat into your skull.  DevOps is not about a tool that you can install or a position on a team?  DevOps is about how well your company can work together to break down functional silos to collectively achieve business goals.  The Phoenix Project definitely stays true to this principle.  As I read through the early chapters, I was so captivated by the story that I didn't even notice that '<a title="DevOps" href="http://en.wikipedia.org/wiki/DevOps" target="_blank">DevOps</a>', '<a title="Continuous Delivery" href="http://continuousdelivery.com/" target="_blank">continuous delivery</a>', '<a title="John Allspaw" href="https://twitter.com/allspaw" target="_blank">John Allspaw</a>',  or '<a title="Deployment Pipeline" href="http://www.informit.com/articles/article.aspx?p=1621865" target="_blank">deployment pipeline</a>' didn't show up until page 294.  When I finally read that portion of the book, it hit me.  Everything Bill had done up to that point was slowly change the team's view of work and their role in the organization.  Cultural changes.</p>
<p><strong>The Three Ways</strong></p>
<p>Throughout the book, Erik squires Bill in the  "<a title="The Three Ways." href="http://itrevolution.com/the-three-ways-principles-underpinning-devops/" target="_blank">Three Ways</a>".  The "Three Ways" are sprinkled throughout the book Bill tries to get a handle on his team's workload and figure out why they aren't producing work.  As the character Erik puts it,</p>
<blockquote><p>The First Way helps us understand how to create fast flow of work as it moves from Development into IT Operations, because that's what's between the business and the customer.  The Second Way shows us how to shorten and amplify feedback loops, so we can fix quality at the source and avoid rework.  And the Third Way shows us how to create a culture that simultaneously fosters experimentation, learning from failure, and understanding that repetition and practice are prerequisites to mastery.</p></blockquote>
<p>If you have studied Agile or Lean, you will find these sound familiar.  It's my understanding that Kevin, Gene and George's other book, <a title="The Visible Ops Handbook" href="http://www.amazon.com/The-Visible-Ops-Handbook-Implementing/dp/0975568612/ref=sr_1_1?ie=UTF8&amp;qid=1361375322&amp;sr=8-1&amp;keywords=the+visible+ops+handbook" target="_blank">the Visible Ops Handbook</a> goes into more depth on the "Three Ways".  I have been told it's a nice companion to the Phoenix Project, and I plan on reading it.</p>
<p><strong><a href="http://earlyandoften.files.wordpress.com/2013/02/250px-obiwanhs-swe.jpg"><img align="left" alt="250px-ObiWanHS-SWE" src="http://earlyandoften.files.wordpress.com/2013/02/250px-obiwanhs-swe.jpg?w=225" width="138" height="185" /></a>Realistic?</strong></p>
<p>There were definitely times that the book felt more fiction than realistic.  When the sky was falling, Bill somehow stumbled upon the correct solution to the problem on the first go.  Yes the process of improving Parts Unlimited was iterative, but Bill never seemed to be offtrack.  And that was of course due to the help on his own personal <a title="Obi Wan Kenobi" href="http://en.wikipedia.org/wiki/Obi-Wan_Kenobi" target="_blank">Obi Wan Kenobi</a> (aka Erik).  Erik played the role of the wise Jedi master beautifully, through his cryptic guidance of Bill towards the "Three Ways".  I looked at Erik's guidance of Bill as a great lesson for individuals trying to transform your team by yourself.  Seek help.  You can do it on your own, but employing an expert will make your life much easier.</p>
<p>I am also not sure that one can avoid studying the art of <a title="Change management" href="http://en.wikipedia.org/wiki/Change_management" target="_blank">change management</a>.  The book touches briefly on the topic indirectly, but it is much harder to change a culture than book leads you to believe.  That's not to say the lessons in the book aren't valuable, but the timeline should be taken with a grain of salt.  The book depicts a company on the edge of collapse.  Not everybody will find themselves with such a motivating catalyst for change.  More than likely you will find stern resistance to new ideas and approaches.  Be prepared to fight.</p>
<p><strong>Conclusion</strong></p>
<p>I thoroughly enjoyed the book and highly recommend it to anybody interested in DevOps, who works in IT, or works in an organization that has a dysfunctional IT shop.  It's a fast pace book that will leave with a long list of other books to read.  I also recommend you check out <a title="Jez Humble" href="http://jezhumble.net/" target="_blank">Jez Humble's</a> <a title="Jez Humble reviews the Phoenix Project" href="http://continuousdelivery.com/2013/01/book-review-the-phoenix-project/" target="_blank">review of The Phoenix Project</a>.  (Note: I didn't read any other reviews until I had written my own, I am happy with the similarities) Go out and buy it now!</p>
</p>
  			<a href="/blog/boyds-law-of-iteration.html"><h1>Boyds Law of Iteration</h1></a>
  			<p>15 February 2013</p>
  			<p><p>My boss <a title="Steve Feldman" href="https://twitter.com/PerfForensics" target="_blank">Steve</a> asked me the other day why I have never posted anything about Boyd's Law of Iteration.  "Your blog's name is 'Early and Often', right?".  He's right, I have no excuse.</p>
<p>Boyd's Law is the basis for most popular software development approaches.  <a title="Lean" href="http://en.wikipedia.org/wiki/Lean_manufacturing" target="_blank">Lean</a>, <a title="Agile" href="http://agilemanifesto.org/" target="_blank">Agile</a>, <a title="Continuous Delivery" href="http://continuousdelivery.com/" target="_blank">Continuous Delivery</a>, <a title="DevOps" href="http://en.wikipedia.org/wiki/DevOps" target="_blank">DevOps</a>, <a title="Lean Startup" href="http://theleanstartup.com/" target="_blank">Lean Startup</a>...all have their foundation in the concept that you release changes faster and more frequently.  In other words, you must iterate quickly.  Furthermore, the speed you can iterate is more important than the quality of iteration.</p>
<p>John Boyd was pilot and aircraft designer interested in dogfights between MiG-15s and F-86s.  From <a title="A Better Path to Enterprise Architectures" href="http://msdn.microsoft.com/en-us/library/aa479371.aspx" target="_blank">A Better Path to Enterprise Architectures</a> (via <a title="Boyd's Law of Iteration" href="http://www.codinghorror.com/blog/2007/02/boyds-law-of-iteration.html" target="_blank">Coding Horror</a>):</p>
<blockquote><p>Boyd decided that the primary determinant to winning dogfights was not observing, orienting, planning, or acting better. The primary determinant to winning dogfights was observing, orienting, planning, and acting <em>faster</em>. In other words, how quickly one could iterate. <em>Speed of iteration</em>, Boyd suggested,<em>beats quality of iteration</em>.</p></blockquote>
<p>This view is somewhat counterintuitive to how people and organizations approach quality.  If something is broken or hard or painful, the immediate reaction is to slow down, take your time, and wait until you are absolutely sure before you move forward.  This leads to long iterations and what lean practitioners would call large batches (more on <a title="Small Batches" href="http://www.startuplessonslearned.com/2009/02/work-in-small-batches.html" target="_blank">small batches</a>).</p>
<p>Imagine you want to fire a rocket to hit a target.  You have two rockets, one has a laser guidance system and the other has no guidance system.  Which of these rockets is more likely to hit the target?  Even if you were to fire the guided missile in the completely opposite direction, I am willing to bet you would still put your money on it.  Why?  Because the guided missile is capable of making small adjustments while in flight to ensure it is always aimed at the target.  These adjustments can compensate for changes in the wind, air density and anything else that impacts flight (not an aeronautical engineer, sorry).</p>
<p>The missile without a guidance system has one iteration and one iteration only to hit it's target.  If your aim is off by a fraction of a degree, it can miss the target by a mile.  Guided missiles win because they are able to iterate quickly.  They adapt to changes (like a moving target).  Like the guided missile, organizations that can release software in frequently are able to adjust quickly.  Organizations that plan, do, check and act slowly often find themselves months or years into a project with little to show, other than they are aiming at the wrong target.</p>
<p>In the book Continuous Delivery, the authors define 8 Principles of Software Delivery, the fourth being "If it hurts, do it more frequently, and bring the pain forward".  I find this principle a great way to get people thinking about how they can iterate faster.  It takes a lot of work to implement this but it provides a tangible rule for people to apply.</p>
<p>It is also important to mention that when thinking of iterations, you should think about the whole value stream and not just your team's role.  An iteration is how long it takes an idea (even before it is a "requirement") to get into the hands of customers (deployed or shipped).  It is not the time it takes the development to implement the requirements and deliver to QA.  You must look at how the whole organization works to deliver value (aka ship to customers), not just a portion of the process.  You can't optimize engineering and not consider QA, for instance.  <a title="Optimize the whole" href="http://www.allaboutagile.com/lean-principle-7-optimise-the-whole/" target="_blank">Optimize the whole</a>.</p>
</p>
  			<a href="/blog/build-script-best-practice.html"><h1>Build Scripts and External Dependencies</h1></a>
  			<p>15 February 2013</p>
  			<p><p><a href="http://xkcd.com/293/"><img align="right" alt="" src="http://imgs.xkcd.com/comics/rtfm.png" width="245" height="304" /></a> I recently ran across some project code that when checked out of version control, failed with an obscure warning.  After some digging around in the code, I realized the script made a reference to an external plugin library.  I had no clue where to acquire this library or setup this build.  I had to reach out to other developers to find out what was causing the failure.  The dependency turned out that a second project needed to be checked out from source control and added to the PATH.  I was also told that I should have <a title="Read the Fucking Manual" href="http://en.wikipedia.org/wiki/RTFM" target="_blank">RTFM</a>.</p>
<p><strong>No External Dependencies</strong></p>
<p>I strongly believe that a project checked out from version control should be as simple and independent as possible.  I should just grab the code and run the build.  I try to avoid at all costs having environment dependencies, save the bare minimum (like a JDK and build tool installed).  This will allow teams to quickly switch between projects and be productive quickly.</p>
<blockquote><p><em><strong>Note</strong>: <a title="Gradle" href="http://www.gradle.org/" target="_blank">Gradle</a> provides an awesome way to minimize external dependencies even further.  The <a title="Gradle Wrapper" href="http://www.gradle.org/docs/current/userguide/gradle_wrapper.html" target="_blank">Gradle Wrapper</a> is a small bit of code you check-into your project that downloads and runs Gradle.  All you need is Java installed on the machine.  The <a title="Grails" href="http://grails.org/" target="_blank">Grails</a> project has also adopted this approach with the <a title="Grails Wrapper" href="http://grails.org/doc/2.1.0/guide/single.html#wrapper" target="_blank">Grails Wrapper</a>.    I think this is an awesome step in the right direction.</em></p></blockquote>
<p>Modern build tools do a great job of managing external dependencies such as libraries, but usually provide a facility to customize build execution through a personal file in your home directory.  I generally avoid these types of customizations.</p>
<p><strong>If you must...</strong></p>
<p>If however, your build script must rely on an external dependency, then it should check and warn the user explicitly.  The error message I see when I run the build should tell me exactly what I need to do to fix the problem (like where the "f*cking manual" is and what page to read).  This makes debugging build scripts for new users straightforward.</p>
<p><strong>...and fail fast</strong></p>
<p>Additionally, if your build script is going to fail because of a missing external dependency, do it quickly.  If your build script's <em>deploy</em> phase depends on a password file being in your home directory, then ideally it should fail as soon as I call the build script with an appropriate warning.  I shouldn't have to wait on the <em>compile</em>, <em>unit tests</em> and <em>package</em> phases to finish before it fails.  This may be hard to do with some build tools (looking at you Maven), but others make this very easy (love you Gradle).</p>
<p><b> Fail intelligently</b></p>
<p>Lastly, if I call the <em>compile</em> phase, don't fail the build if I am missing a dependency needed for the <em>deploy</em> phase.  I should only see a warning if I am trying to execute the task.  I may want to write a build script that requires secure access to a username and password on the continuous integration server, but developers will never execute this phase.  I don't want them to have to setup a username and password for something they will never execute.</p>
<p>Gradle makes this very easy to do.  Gradle has three phases of build execution: initialization, configuration and execution.  The initialization phase is to build a project graph (for multi-module projects), the configuration phase builds a task graph and the execute phase executes the project tasks.  You can write code that checks the contents of the task graph and conditionally executes logic.  For information on how to do this in Gradle, <a title="Gradle: Configuring the DAG" href="http://www.gradle.org/docs/current/userguide/userguide_single.html#configure-by-dag" target="_blank">read the f*cking manual</a>.</p>
</p>
  			<a href="/blog/continuous-delivery-applied-dc-agile-engineering-conference.html"><h1>Continuous Delivery Applied @ DC Agile Engineering Conference</h1></a>
  			<p>07 February 2013</p>
  			<p><p>Yesterday I posted a video of <a title="Sam Brown" href="https://twitter.com/SamuelBrownIV" target="_blank">Sam Brown</a> and I giving a talk on <a title="Improving Design through TDD" href="http://earlyandoften.wordpress.com/2013/02/06/improving-designs-through-tdd/" target="_blank">Improving Design through TDD</a>.  We gave this talk at the DC Agile Engineering Conference last December.  I was also lucky enough to give a second that day on Continuous Delivery Applied.  Like the previous talk, this one was also recorded and I am sharing it here.</p>
<p><iframe width="640" height="360" src="//www.youtube.com/embed/J1eOaG7Z9Hc" frameborder="0" allowfullscreen></iframe></p>
<p>Here are the slides:<br />
<iframe src="http://www.slideshare.net/slideshow/embed_code/15643627" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/DCAEC/continuousdeliveryapplied-agilerichmond121115200249phpapp02" title="Continuous Delivery Applied" target="_blank">Continuous Delivery Applied</a> </strong> from <strong><a href="http://www.slideshare.net/DCAEC" target="_blank">DC Agile Engineering Conference</a></strong> </div></p>
</p>
  			<a href="/blog/improving-designs-through-tdd.html"><h1>Improving Designs through TDD</h1></a>
  			<p>06 February 2013</p>
  			<p><p>Last December, I was invited to speak at the first annual <a title="DC Agile Engineering Conference" href="http://dc-agile-engineering-conference.eventbrite.com/" target="_blank">DC Agile Engineering Conference</a>.  For this conference, I collaborated with a former colleague of mine, <a title="Sam Brown IV" href="https://twitter.com/SamuelBrownIV" target="_blank">Sam Brown</a> on one of my talks.  Sam and I are both proponents of Test Driven Development and practiced it together on projects, so it made sense for us to talk about TDD.</p>
<p>The focus of our talk was on how Test Driven Development improves the design of an application.  We were lucky enough that our talk was recorded, and I would like to share this talk here with you today.</p>
<p><iframe width="640" height="360" src="//www.youtube.com/embed/5-K8RH0WLXg" frameborder="0" allowfullscreen></iframe></p>
<p>Here are the slides for the talk:</p>
<p><iframe src="http://www.slideshare.net/slideshow/embed_code/15574515" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/excellaco/improving-design-through-test-driven-development-tdd" title="Improving Design Through Test Driven Development (TDD)" target="_blank">Improving Design Through Test Driven Development (TDD)</a> </strong> from <strong><a href="http://www.slideshare.net/excellaco" target="_blank">Excella Consulting</a></strong> </div></p>
</p>
  			<a href="/blog/goals-for-2013.html"><h1>Goals for 2013</h1></a>
  			<p>05 February 2013</p>
  			<p><p>Yes, while it is already February 2013, I decided that I should provide myself a commitment device for the year.</p>
<h3>Reading List</h3>
<p>Let's start with what I plan on reading for the year.  My list of books is long, but it is exciting.</p>
<ul>
<li><span style="line-height:13px;"><a title="A Feast for Crows" href="http://www.amazon.com/Feast-Crows-Song-Fire-Book/dp/055358202X/ref=pd_sim_b_3" target="_blank">Game of Thrones: A Feast for Crows</a> (80% done...)</span></li>
<li><a title="The Phoenix Project" href="http://itrevolution.com/books/phoenix-project-devops-novel/" target="_blank">The Phoenix Project</a></li>
<li><a href="http://www.packtpub.com/devops-quickstart-guide/book" target="_blank">Continuous Delivery and DevOps: A Quickstart Guide</a></li>
<li><a title="Management 3.0" href="http://www.amazon.com/Management-3-0-Developers-Developing-Addison-Wesley/dp/0321712471" target="_blank">Management 3.0</a></li>
<li><a title="ATDD by Example" href="http://www.amazon.com/ATDD-Example-Test-Driven-Development-Addison-Wesley/dp/0321784154" target="_blank">ATDD by Example</a></li>
<li><a title="Kanban" href="http://www.amazon.com/Kanban-Successful-Evolutionary-Technology-Business/dp/0984521402/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1359949561&amp;sr=1-1&amp;keywords=kanban" target="_blank">Kanban</a></li>
<li><a title="A Dance with Dragons" href="http://www.amazon.com/Dance-Dragons-Song-Fire-Book/dp/0553801473/ref=pd_sim_b_3" target="_blank">Game of Thrones: A Dance of Dragons</a></li>
<li><a title="Domain Driven Design" href="http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1359949589&amp;sr=1-1&amp;keywords=domain+driven+design" target="_blank">Domain Driven Design</a></li>
<li><a title="Coaching Agile Teams" href="http://www.amazon.com/Coaching-Agile-Teams-ScrumMasters-Addison-Wesley/dp/0321637704/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1359949615&amp;sr=1-1&amp;keywords=coaching+agile+teams" target="_blank">Coaching Agile Teams</a></li>
<li><a title="W. Edwards Deming" href="http://en.wikipedia.org/wiki/W._Edwards_Deming" target="_blank">Something on Deming</a>...(not sure what yet)</li>
</ul>
<h3>Blackboard</h3>
<p>Plain and simple...kill it.  I love this job and all the opportunities it presents.  I love the work environment and everybody who is there.  There are some great challenges and a fast paced environment.  No metrics that I can use to track my progress come to mind, other than my happiness.</p>
<h3>Blogging</h3>
<p>When 2012 ended and I tallied up all my blog posts, I had to say I was quiet disappointed with the number of posts.  20!  That's it.  Well, for 2013, I plan on pushing myself.  1 blog entry a week.  That's 52 entries.  Now I know what you are saying, "Mike, it's February and this is only your second post".  Well, I am going to post as much as possible to catch up.</p>
<h3>DC Continuous Integration Meetup</h3>
<p>I am proud of the progress we have made on the <a title="DC Continuous Integration, Delivery and Deployment Meetup" href="http://www.meetup.com/DC-continuous-integration/" target="_blank">DC Continuous Integration, Delivery and Deployment Meetup</a>.  This group has had some great meetings and we have some great ones coming up.</p>
<p>My goal is to continue the success the group has had before.  I plan on alternating meeting locations between Blackboard in Chinatown, DC and Excella in Arlington, VA.  I also want to continue to find speakers that want to share their real experiences implementing continuous integration, continuous delivery or even continuous deployment.  I will try my best to turn away speakers who want to push corporate agendas.</p>
<p>Regarding metrics, here we go:</p>
<ul>
<li><span style="line-height:13px;">Increase membership to 250 members (currently 179)</span></li>
<li>12 meetings for the year (1 per month)</li>
<li>At least one meeting is a hands on workshop</li>
</ul>
<h3>Public Speaking</h3>
<p>By the end of 2012, I have two good presentations in my bag of tricks and I would like to ideally develop two more.  I would like to continue speaking at user groups and conferences throughout the year.  My goal is to have at least 4 talks this year, 2 of which are new talks.</p>
<h3>Chef</h3>
<p>My goal plain and simple where is to learn <a title="Chef" href="http://www.opscode.com/chef/" target="_blank">Chef</a>.  I have familiarity with Puppet and how it works but right now we are leaning towards using Chef.  By the end of 2013 I want to have extensive knowledge of building Chef based solutions.</p>
<h3>Jenkins Plugins</h3>
<p>I have extensive knowledge of <a title="Jenkins" href="http://jenkins-ci.org/" target="_blank">Jenkins</a> and how to install and utilize it.  I would like to learn more of is <a title="Extending Jenkins" href="https://wiki.jenkins-ci.org/display/JENKINS/Extend+Jenkins" target="_blank">Jenkins' plugin architecture</a>.  My goal is to contribute to an open source Jenkins plugin.  Additionally, I would love to start my plugin.</p>
<h3>Learn Ruby</h3>
<p>This is a simple enough task.  I have spent most of my career on the JVM and I feel it is time to branch out a bit.  Yes, I could learn Ruby on JRuby, but I might as well take the full-on plunge.  My goal is to be able to be able to hold my own in a Ruby environment.  Pretty simple.  This dovetails nicely with my Chef goal.</p>
<h3>In Summary</h3>
<p>So, to tally up my goals for 2013, I have to:</p>
<ul>
<li><span style="line-height:13px;">Read 10 books</span></li>
<li>Post 52 blog entries</li>
<li>Host 12 meetup meetings (DCCI)</li>
<li>Increase membership to 250+ members (DCCI)</li>
<li>Host a hands-on workshop meeting (DCCI)</li>
<li>Give 4 talks (2 new presentations)</li>
<li>Learn Chef</li>
<li>Learn Ruby</li>
<li>Contribute to Jenkins open source plugin</li>
</ul>
</p>
  			<a href="/blog/looking-back-on-2012.html"><h1>Looking back on 2012</h1></a>
  			<p>04 February 2013</p>
  			<p><p>2012 has been an exciting year, full of change and merriment. Here's my retrospective.</p>
<h3>Excella Consulting<a href="http://earlyandoften.files.wordpress.com/2013/02/excella.jpg"><img align="right" alt="excella" src="http://earlyandoften.files.wordpress.com/2013/02/excella.jpg?w=150" width="150" height="150" /></a></h3>
<p>The majority of 2012 I spent working at Excella Consulting, a great local IT and Agile consulting firm. While there, I worked on advancing their Java Center of Excellence. &nbsp;I enjoyed my stay there and learned a lot from everybody. &nbsp;I worked with some great clients and had a blast. &nbsp;Excella is a bunch of smart individuals and I highly recommend hiring them or working for them. &nbsp;They are a great place to work.</p>
<h3><a href="http://earlyandoften.files.wordpress.com/2013/02/speaking.jpg"><img align="left" alt="speaking" src="http://earlyandoften.files.wordpress.com/2013/02/speaking.jpg?w=300" width="300" height="179" /></a>Public Speaking</h3>
<p>One of the highlights of 2012 has to be the number of public speaking engagements I had throughout the year. Most of my talks centered on my favorite topic, Continuous Delivery. I was able to speak at not only user groups, but a couple of conferences as well. Here's a quick run-down of the public speaking engagements I had in 2012:</p>
<ul>
<li>February 2012 -&nbsp;<a href="https://sites.google.com/site/mcjugmd/" rel="nofollow">Montgomery County Java User's Group</a>&nbsp;-&nbsp;<a href="http://www.slideshare.net/jmcgarr/continuous-delivery-tools-and-techniques" rel="nofollow">Continuous Delivery: Tools and Techniques</a></li>
<li>September 2012 -&nbsp;<a href="http://aplndc.com/" rel="nofollow">DC Agile Leadership Network</a>&nbsp;-&nbsp;<a href="http://alndcseptember2012-eorg.eventbrite.com/" rel="nofollow">Continuous Delivery Applied</a>&nbsp;<a href="http://www.slideshare.net/jmcgarr/continuous-delivery-applied" rel="nofollow">(slides)</a></li>
<li>September 2012 -&nbsp;<a href="http://www.meetup.com/DC-continuous-integration/" rel="nofollow">DC Continuous Integration, Delivery and Deployment Meetup</a>&nbsp;-&nbsp;<a href="http://www.meetup.com/DC-continuous-integration/events/80979862/" rel="nofollow">Introduction to Continuous Delivery</a><a href="http://www.slideshare.net/jmcgarr/continuous-delivery-applied-dc-ci-user-group" rel="nofollow">(slides)</a></li>
<li>October 2012 -&nbsp;<a href="http://agiledc.org/" rel="nofollow">Agile DC</a>&nbsp;-&nbsp;<a href="http://www.slideshare.net/jmcgarr/continuous-delivery-applied-agiledc" rel="nofollow">Continuous Delivery Applied</a></li>
<li>November 2012 -&nbsp;<a href="http://agilerichmond.com/" rel="nofollow">Agile Richmond</a>&nbsp;-&nbsp;<a href="http://www.slideshare.net/jmcgarr/continuous-delivery-applied-agile-richmond" rel="nofollow">Continuous Delivery Applied</a></li>
<li>December 2012 -&nbsp;<a href="http://dc-agile-engineering-conference.eventbrite.com/" rel="nofollow">DC Agile Engineering Conference</a>&nbsp;-&nbsp;<a href="http://www.slideshare.net/excellaco/improving-design-through-test-driven-development-tdd" rel="nofollow">Improving Design through Test Driven Development</a></li>
<li>December 2012 -&nbsp;<a href="http://dc-agile-engineering-conference.eventbrite.com/" rel="nofollow">DC Agile Engineering Conference</a>&nbsp;-&nbsp;<a href="http://www.slideshare.net/excellaco/continuous-delivery-applied-15574679" rel="nofollow">Continuous Delivery Applied</a></li>
</ul>
<p>It is hard to pick my favorite speaking engagement. It was an honor to speak at Agile DC and a lot of fun being a part of the first DC Agile Engineering Conference. It was also awesome to go to Richmond to speak. I love the crowd at MCJUG as well.</p>
<h3>The DC Continuous Integration, Delivery and Deployment Meetup<a href="http://earlyandoften.files.wordpress.com/2013/02/cd_book_web1.jpg"><img align="right" alt="cd_book_web1" src="http://earlyandoften.files.wordpress.com/2013/02/cd_book_web1.jpg" width="148" height="200" /></a></h3>
<p>In 2012, I started the&nbsp;<a href="http://www.meetup.com/DC-continuous-integration/" rel="nofollow">DC Continuous Integration, Delivery and Deployment Meetup</a>. This has been an awesome experience and a lot of fun to get not only my friends to speak, but also some industry big wigs. The group meets once a month to discuss real-life war stories. While we have only had four meetings, it has been an awesome experience that I hope to build on in 2013. Please join the group and come out and have fun. I am hoping to have future meetings at BB HQ.</p>
<p>The highlights of this group was having&nbsp;<a href="https://twitter.com/PaulDuvall" rel="nofollow">Paul Duvall</a>, the primary author of THE&nbsp;<a href="http://www.amazon.com/Continuous-Integration-Improving-Software-Reducing/dp/0321336380" rel="nofollow">Continuous Integration</a>&nbsp;book, came to speak about&nbsp;<a href="http://www.meetup.com/DC-continuous-integration/events/81129322/" rel="nofollow">Continuous Delivery in the Cloud</a>. Depsite the A/V outage in the middle of his talk, he did a great job and it was a great experience.</p>
<p>Our first meeting of 2013 is tomorrow night, where Sanjeev Sharma from IBM will talk about&nbsp;<a href="http://dc-agile-engineering-conference.eventbrite.com/" rel="nofollow">DevOps for Mobile applications</a>.</p>
<h3>Early and Often</h3>
<p>While I do enjoy blogging, I was only able to compose 20 blog posts in 2012. That's a pretty low number all things considered. My blog did get some decent traffic, with a total of 25K views over the year. Unfortunately, my most popular posts were not from this year, but from previous years. I hope to double the number of posts in 2013.</p>
<p style="text-align:center;"><a href="http://earlyandoften.files.wordpress.com/2013/02/steve-feldman.png"><img class="size-medium wp-image-1335 aligncenter" alt="steve-feldman" src="http://earlyandoften.files.wordpress.com/2013/02/steve-feldman.png?w=300" width="300" height="184" /></a><br />
<sub>All pictures of Stephen Feldman from Google Image Search.</sub></p>
<h3>Meeting Steve</h3>
<p>Sometime in the middle of summer, my friend <a title="Andy Glover" href="http://thediscoblog.com/" target="_blank">Andy Glover</a> sent me an email asking if I was interested in a DevOps gig at <a title="Blackboard, Inc." href="http://www.blackboard.com/" target="_blank">Blackboard</a>. The email was from <a title="Steve Feldman" href="https://twitter.com/PerfForensics" target="_blank">Steve Feldman</a> who was looking for a team lead. &nbsp;At the time, I was already contemplating my next move and agreed to meet Steve for coffee. I was working at a client in DC and decided to walk to BB for coffee. It was a pretty long walk, but it was worth it. Steve shows up in a golf shirt, short and sandals. That was the first good sign. The second good sign was that Steve had brought with him a printout of&nbsp;<a href="http://earlyandoften.wordpress.com/2011/03/04/alm/" rel="nofollow">a blog entry I had written from 2011</a>. Steve and I hit it off and he explained what he was looking for. This sounded great. The third good sign was when Steve invited me to play golf. I love golf. It was a great course and a great day.</p>
<p>Over the course of the months, Steve and I continued to discuss the opportunity. Eventually I met with other members of Blackboard and an offer was made. I promptly turned in my resignation at Excella Consulting and joined Blackboard as the Director of Learn DevOps.</p>
<h3>Getting started at Blackboard</h3>
<p>November saw my first day at Blackboard. I was excited to have an office and a great team to work with. I knew that I would be spending the first month or so learning as much as I could about the DevOps team and how Blackboard develops Learn. I spent most of November in&nbsp;one on onemeetings. Besides HR tasks, little else was accomplished.</p>
<p>In December, I started working on my assessment of the Learn Product Development organization. It was exciting working with members of the various departments and learning all I could about how the "cheese was made". &nbsp;The process took longer than I expected but I put together a presentation for management and it went well. &nbsp;Now, I have just have to execute on my plan. &nbsp;The fun begins!</p>
</p>
  			<a href="/blog/a-roadmap-unit-testing.html"><h1>A roadmap for unit testing</h1></a>
  			<p>04 December 2012</p>
  			<p><p>I was recently asked by an old friend how they can get started writing unit tests on their existing application.  He was looking for guidance and more or less a roadmap of how to get started.  I decided to share what I sent him here.</p>
<p>So, if there is already code written for an application that you want to add unit tests to, this is harder, but not impossible.  Essentially, the problem you will run into is the code you are trying to unit test isn't testable.</p>
<p><b>Working Effectively with Legacy Code</b><br />
Production code without unit tests is considered legacy code.  More than likely it will no small task adding unit tests to your existing application.  Most legacy applications were not designed to be testable.  The code has concrete dependencies that make it hard externalize during unit testing to isolate the class.</p>
<p>I would consider reading up on how to unit test legacy code.  The seminal tome on this topic is Michael Feather's "<a href="http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052">Working Effectively with Legacy Code</a>".  The title doesn't sound sexy, but it is essentially a guide for how to write unit tests for a legacy application.  If you don't have time for the book, you can get a preview of his thoughts and techniques in <a title="Working Effectively with Legacy Code (Presentation)" href="http://www.slideshare.net/nashjain/working-effectively-with-legacy-code-presentation" target="_blank">this presentation</a> of his and in this prebook article of his thoughts.</p>
<p><b>Roadmap</b><br />
You can follow these steps to add unit tests to your code.  You may progress through them over the course of days or weeks.  I make assumptions that you are working on a Java application, but most of the guidance can be applied generally.</p>
<ol>
<li><span style="text-decoration:underline;">Setting up the code</span>
<ol>
<li>Add JUnit, Mockito and PowerMock (optional) to your project's build script tool
<ol>
<li>Use dependency management like Maven, Gradle, or Ivy.</li>
<li>If you aren't using a build tool, stop and add one now!</li>
</ol>
</li>
<li>Run the build tool's eclipse setup (mvn eclipse:eclipse or gradle cleanEclipse eclipse)
<ol>
<li>I prefer using the build tool to manage IDE project files.</li>
</ol>
</li>
<li>Open Eclipse/IntelliJ and you should be able to create unit tests</li>
</ol>
</li>
<li><span style="text-decoration:underline;">Learning to write good unit tests</span>
<ol>
<li>Learn <a href="https://github.com/kentbeck/junit/wiki">JUnit</a> syntax</li>
<li>A unit test should fit into <a href="http://pragprog.com/magazines/2012-01/unit-tests-are-first">this criteria</a>.</li>
<li>Write each test in the <a href="http://c2.com/cgi/wiki?ArrangeActAssert">Arrange Act Assert</a> format
<ol>
<li>FYI, this is the same as Given When Then, which is <a href="http://dannorth.net/introducing-bdd/">Behavior Driven Development</a>.</li>
</ol>
</li>
<li><a href="http://earlyandoften.wordpress.com/2010/05/07/practical-unit-testing/">Use this guide</a> as well to figure out which code to start testing:
<ol>
<li>I wouldn't move on to the next step until you feel comfortable</li>
</ol>
</li>
</ol>
</li>
<li><span style="text-decoration:underline;">Using Test Doubles</span>
<ol>
<li>First, learn what <a href="http://www.martinfowler.com/bliki/TestDouble.html">Test Doubles</a> are.</li>
<li><a href="http://www.markhneedham.com/blog/2009/12/13/tdd-only-mock-types-you-own/">Mock Roles, Not Objects</a></li>
<li><a href="https://code.google.com/p/mockito/">Mockito has some great documentation</a>.</li>
<li>The best place to learn how to use Mock object properly is by reading this book: <a href="http://www.amazon.com/Growing-Object-Oriented-Software-Guided-Tests/dp/0321503627">Growing Object Oriented Code, Guided by Tests</a></li>
</ol>
</li>
<li><span style="text-decoration:underline;">Learning TDD</span>
<ol>
<li>The best way to learn, is to practice.</li>
<li>Learn from <a href="http://butunclebob.com/ArticleS.UncleBob.TheBowlingGameKata">Uncle Bob's Bowling Game Kata</a>
<ol>
<li><a href="http://butunclebob.com/files/downloads/Bowling%20Game%20Kata.ppt">Download his Powerpoint</a> and follow along.  Pretty good.</li>
<li>Try to solve this particular problem on your own.  Just write code and throw it away.  The experience is important</li>
</ol>
</li>
<li><a href="http://www.meetup.com/DC-Software-Craftsmanship/">DC Software Craftsmanship User Group</a> - all they do is do TDD.  It's awesome!</li>
<li>Try these <a href="http://codingdojo.org/cgi-bin/wiki.pl?KataCatalogue">other code katas</a></li>
</ol>
</li>
</ol>
<p>The process of learning to write good unit tests, how use Test Doubles, how to do TDD and finally how it all fits together can a long time to set in, but it is well worth it.</p>
</p>
  			<a href="/blog/a-new-adventure-begins.html"><h1>A new adventure begins</h1></a>
  			<p>02 December 2012</p>
  			<p><p><a href="http://earlyandoften.wordpress.com/2012/12/02/a-new-adventure-begins/blackboard_logo_235x227/" rel="attachment wp-att-1280"><img align="right" alt="Blackboard_Logo_235x227" src="http://earlyandoften.files.wordpress.com/2012/12/blackboard_logo_235x227.gif?w=235" height="227" width="235" /></a>November 5th was my first day at <a title="Blackboard" href="http://www.blackboard.com/" target="_blank">Blackboard, Inc.</a> as the Director for <a title="Learn" href="http://www.blackboard.com/Platforms/Learn/Overview.aspx" target="_blank">Learn</a> DevOps, and I couldn't be more excited.  I joined a smart and energetic team that is interested in delivering high quality software to their customers.  My role will allow me to apply my knowledge and interests in continuous integration, test automation, deployment automation and more to a mature software product development team.  I look forward to posting more on this blog about my new experiences at Blackboard.</p>
</p>
  			<a href="/blog/upcoming-talks.html"><h1>Upcoming Talks</h1></a>
  			<p>22 October 2012</p>
  			<p><p>I haven't posted in a while, but I wanted to share some upcoming talks I will be giving before the end of the new year.</p>
<p><a href="http://earlyandoften.files.wordpress.com/2012/10/agiledc.png"><img align="right" title="agiledc" alt="" src="http://earlyandoften.files.wordpress.com/2012/10/agiledc.png" height="100" width="242" /></a>Tomorrow I will closing the day at <a title="AgileDC" href="http://agiledc.org/" target="_blank">AgileDC</a> with my <a title="Continuous Delivery Applied presenation" href="http://www.slideshare.net/jmcgarr/continuous-delivery-applied" target="_blank">Continuous Delivery Applied</a> presentation.  This will be my first time attending AgileDC and I am very excited to be ask to present.  I've made some updates and improvements to my talk, so come out and see it again.  I am looking forward to it and I hope to see everybody there.</p>
<p><a href="http://earlyandoften.files.wordpress.com/2012/10/agile-richmond.jpg"><img align="left" title="agile-richmond" alt="" src="http://earlyandoften.files.wordpress.com/2012/10/agile-richmond.jpg?w=300" height="80" width="210" /></a>On November 14, I will continue my speaking "tour" in Richmond.  The great folks at <a title="Agile Richmond" href="http://agilerichmond.org/" target="_blank">Agile Richmond</a> have asked me to come down and give my <strong>Continuous Delivery Applied</strong> presentation.  I look forward to heading south, and meeting up with some good friends while I am there as well.</p>
<p><a href="http://earlyandoften.files.wordpress.com/2012/10/excella.png"><img align="right" title="excella" alt="" src="http://earlyandoften.files.wordpress.com/2012/10/excella.png" height="140" width="181" /></a>On December 7th, I will be participating in <a title="Excella Consulting" href="http://www.excella.com/" target="_blank">Excella Consulting</a>'s first conference, the <a title="2012 DC Agile Engineering Conference" href="http://dc-agile-engineering-conference.eventbrite.com/" target="_blank">DC Agile Engineering Conference</a>.  This event is a one-day single track conference that takes place the day before the <a title="Global Day of Coderetreat" href="http://globalday.coderetreat.org/" target="_blank">Global Day of Coderetreat</a>.  For this conference, I will collaborating on 2 separate talks.  In the first talk, <a title="Samuel Brown" href="https://twitter.com/SamuelBrownIV" target="_blank">Sam Brown</a> and I will be talking about <strong>Improving Designs through TDD</strong>.  In this talk we will share our experiences using Test Driven Development to improve the design of our code.  In the second talk, <a title="Roberto Hernandez" href="https://twitter.com/hernandezrobert" target="_blank">Roberto Hernandez</a> and I will discuss Continuous Delivery.  Both Roberto and I have been speaking about <strong>Continuous Delivery</strong> for some time, so this talk should be a lot of fun.</p>
<p>I hope to see each and every one of you at one or all of my talks.</p>
</p>
  			<a href="/blog/openjdk-6-install-lucid.html"><h1>How to install OpenJDK 6 on Ubuntu 10.04 (Lucid Lynx)</h1></a>
  			<p>08 September 2012</p>
  			<p><p>I have been playing with <a title="Vagrant" href="http://vagrantup.com/" target="_blank">Vagrant</a> and <a title="Puppet" href="http://puppetlabs.com/puppet/puppet-open-source/" target="_blank">Puppet</a> a lot recently and I had some trouble getting <a title="OpenJDK 6" href="http://openjdk.java.net/projects/jdk6/" target="_blank">OpenJDK 6</a> to install on <a title="Ubuntu 10.04" href="http://releases.ubuntu.com/lucid/" target="_blank">Ubuntu 10.04 (Lucid Lynx)</a>. &nbsp;Since I had so much trouble finding the consolidated answer, I've decided to post my solution here.</p>
<p>The problem stems from the fact I want to install OpenJDK via a <a title="Debian package" href="http://www.debian.org/distrib/packages" target="_blank">Debian package</a>. &nbsp;Lucid Lynx's default <a title="AptGet" href="https://help.ubuntu.com/community/AptGet/Howto" target="_blank">apt</a> setup doesn't include the correct repositories needed to install OpenJDK. &nbsp;To get this to work, you need to add the correct repository to apt. &nbsp;I accomplished this by using the 'add-apt-repository' python library, like so:<br />
<pre>
$&gt; sudo apt-get install python-software-properties
$&gt; sudo add-apt-repository &quot;deb http://archives.canonical.com/ lucid partner&quot;
</pre>
Once this is done, you need to update the the apt-get cache. &nbsp;You can do this with the following command:<br />
<pre>
$&gt; sudo apt-get update
</pre>
Now that apt-get is all up to date, you can finally install OpenJDK 6 JRE with the following command:<br />
<pre>
$&gt; sudo apt-get install openjdk-6-jdk
</pre>
I hope this helps!</p>
</p>
  			<a href="/blog/my-continuous-delivery-talk-at-aln-dc.html"><h1>My Continuous Delivery talk at ALN DC</h1></a>
  			<p>07 September 2012</p>
  			<p><p><a href="http://earlyandoften.files.wordpress.com/2012/09/logo.jpg"><img align="right" title="DC ALN Logo" src="http://earlyandoften.files.wordpress.com/2012/09/logo.jpg?w=300" alt="" width="299" height="143" /></a>Last night I gave the latest installment of my <a title="Continuous Delivery at MCJUG" href="https://earlyandoften.wordpress.com/2011/06/17/cd-at-mcjug/" target="_blank">ever</a> <a title="Second Continuous Delivery Talk at MCJUG" href="https://earlyandoften.wordpress.com/2012/02/17/mcjug-return/" target="_blank">evolving</a> Continuous Delivery talk to the DC Chapter of the <a title="Agile Leadership Network (ALN)" href="http://aplndc.com/" target="_blank">Agile Project Leadership</a> (ALN) group last night.  It was a great group with an attentive audience and tons of great questions.  I thoroughly enjoyed the experience and I hope I can give more talk there in the future.</p>
<p>I want to thank the organizers of the ALN for asking me to come speak last night.  I look forward to giving more talks at ALN in the future.</p>
<p>Also, if you happened to attend the presentation, please rate my talk at <a title="Rate this Talk!" href="http://speakerrate.com/talks/15781-continuous-delivery-applied" target="_blank">SpeakerRate.com</a>. The slides are below, I hope you enjoyed my talk!</p>
<p><iframe src="http://www.slideshare.net/slideshow/embed_code/14204775" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/jmcgarr/continuous-delivery-applied" title="Continuous delivery applied" target="_blank">Continuous delivery applied</a> </strong> from <strong><a href="http://www.slideshare.net/jmcgarr" target="_blank">Mike McGarr</a></strong> </div></p>
</p>
  			<a href="/blog/vagrant-cheatsheat.html"><h1>Vagrant Cheatsheat</h1></a>
  			<p>06 September 2012</p>
  			<p><p>I have been using Vagrant on and off for a while and I find myself forgetting some of the commands.  Instead of looking through Vagrant documentation to find the specific commands that I was looking for, I decided to capture the commands here.  I hope that this reference helps somebody out.</p>
<ul>
<li><a title="Installing a Box" href="http://vagrantup.com/v1/docs/boxes.html#installing_a_box" target="_blank">vagrant box add</a> - allows you to install a box (or VM) to the local machine</li>
<li><a title="Removing Boxes" href="http://vagrantup.com/v1/docs/getting-started/boxes.html#removing_boxes" target="_blank">vagrant box remove</a> - removes a box from the local machine</li>
<li><a title="List Vagrant Boxes" href="http://vagrantup.com/v1/docs/boxes.html#listing_installed_boxes" target="_blank">vagrant box list</a> - lists the locally installed Vagrant boxes</li>
<li><a title="Vagrant Project Setup" href="http://vagrantup.com/v1/docs/getting-started/setup.html#vagrant_project_setup" target="_blank">vagrant init</a> - initializes a project to use Vagrant</li>
<li><a title="Your First Vagrant Environment" href="http://vagrantup.com/v1/docs/getting-started/index.html#your_first_vagrant_virtual_environment" target="_blank">vagrant up</a> - starts up the vagrant VM</li>
<li><a title="Suspend Vagrant" href="http://vagrantup.com/v1/docs/getting-started/teardown.html#suspending_the_environment" target="_blank">vagrant suspend</a> - saves the state of the current VM.</li>
<li><a title="Resume the VM" href="http://vagrantup.com/v1/docs/getting-started/teardown.html#suspending_the_environment" target="_blank">vagrant resume</a> - will load up the suspended VM.</li>
<li><a title="Halting a Vagrant VM" href="http://vagrantup.com/v1/docs/getting-started/teardown.html#halting_the_environment" target="_blank">vagrant halt</a> - will shut down the VM, saving configuration. (restart with 'up' command)</li>
<li><a title="Destroy the VM" href="http://vagrantup.com/v1/docs/getting-started/teardown.html#destroying_the_environment" target="_blank">vagrant destroy</a> - will destroy the VM with all config changes.</li>
<li><a title="Apply Port Forwarding" href="http://vagrantup.com/v1/docs/getting-started/ports.html#applying_forwarded_ports" target="_blank">vagrant reload</a> - apply Vagrant configuration changes (like port forwarding) without rebuilding the VM.</li>
<li>vagrant status - tells you the current state of the Vagrant project's VM</li>
<li><a title="Vagrant Plugins" href="http://vagrantup.com/v1/docs/plugins.html" target="_blank">vagrant gem</a> - install Vagrant plugins via RubyGems</li>
<li><a title="Vagrant SSH" href="http://vagrantup.com/v1/docs/getting-started/ssh.html" target="_blank">vagrant ssh</a> - short cut to SSH into the running VM</li>
<li><a title="Packaging a Vagrant Project" href="http://vagrantup.com/v1/docs/getting-started/packaging.html#packaging_the_project" target="_blank">vagrant package</a> - create a distribution of the VM you have running.</li>
<li><a title="Vagrant Help" href="http://vagrantup.com/v1/docs/commands.html#builtin_help" target="_blank">vagrant &lt;command&gt; --help</a> - Command that will provide man pages for a vagrant command.</li>
</ul>
<p>There is extensive documentation on the Vagrant website.  I hope this helps!</p>
</p>
  			<a href="/blog/git-tip-branch-your-previous-commit.html"><h1>Git Tip: Branch your previous commit</h1></a>
  			<p>21 August 2012</p>
  			<p><p>I just made a commit (6452234) to master, but realized that is should have been committed to a branch and I want master pointing at a previous commit (bb5331e).  How do I resolve this?</p>
<pre>
C:\code\project&gt;git lg
* 6452234 - (HEAD, master) reformat test variables
* bb5331e - (origin/master) more unit tests
</pre>
<p>First, create the new branch where you would like your commit to live:</p>
<pre>
git checkout -b cool-feature
</pre>
<p>Now your master and the new branch are pointing to the same commit, like this:</p>
<pre>
C:\code\project&gt;git lg
* 6452234 - (HEAD, master, cool-feature) reformat test variables
* bb5331e - (origin/master) more unit tests
</pre>
<p>Go back to the master branch.</p>
<pre>
git checkout master
</pre>
<p>Now, reset your master branch to point the revision that you want to go back to:</p>
<pre>
git reset --hard bb5331e
</pre>
<p>Master is now pointing to the old revision and the new revision is on the branch only.  Checking the log, we can confirm this:</p>
<pre>
C:\code\project&gt;git lg
* bb5331e - (HEAD, master, origin/master) more unit tests
</pre>
<p>To confirm that the commit has been moved to your branch, just checkout the branch and run the log:</p>
<pre>
C:\code\project&gt;git checkout cool-feature
Switched to a new branch 'cool-feature'
C:\code\project&gt;git lg
* 6452234 - (HEAD, cool-feature) reformat test variables
* bb5331e - (master, origin/master) more unit tests
</pre>
<p>Special thanks to <a href="http://longair.net/blog/2009/04/16/git-fetch-and-merge/" target="_blank">Mark's great blog entry</a> on not using Git pull. Also if you want to know how I got my Git logs to show up using 'git lg', check out my <a href="http://earlyandoften.wordpress.com/2012/05/02/simple-git-aliases/" target="_blank">previous entry on git alias</a>.</p>
</p>
  			<a href="/blog/vim-syntax-highlighting.html"><h1>Vim Syntax Highlighting</h1></a>
  			<p>27 May 2012</p>
  			<p><p>I just discovered how to turn on syntax highlighting by default on Vim.  All you have to do is add the following line to your ~/.vimrc file:</p>
<pre>
:syntax on
</pre>
<p>If you don't have a .vimrc file, a quick way to add one is by running the following command:</p>
<pre>
$ echo &quot;:syntax on&quot; &gt;&gt; ~./vimrc
</pre>
<p>I was impressed to find that Vim contains Groovy syntax highlighting by default.  Enjoy!</p>
</p>
  			<a href="/blog/jmeter-crash-course.html"><h1>JMeter Crash Course</h1></a>
  			<p>07 May 2012</p>
  			<p><p>I have had a lot of success using <a title="JMeter" href="http://jmeter.apache.org/index.html" target="_blank">JMeter</a> to provide quick performance tests, and this guide will help you get started with JMeter.  I have used JMeter with success on web applications, web services and databases, and I find that it works extremely well.  I have even used JMeter on .NET projects.  This doesn't cover performance testing best practices.  I will save those for another post.</p>
<h3>Download and install the Java SDK</h3>
<ol>
<li>Download the SDK from Oracle <a title="Java SE Development Kit 6 Update 27" href="http://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-javase6-419409.html#jdk-6u27-oth-JPR" target="_blank">here </a>(Note: Recommend Java SE 6 update 27.  I've had issues with update 29)</li>
<li>Run the installer.  Take note of the install location</li>
<li>Add $java_install_dir/bin/ to your system path</li>
</ol>
<h3>Install JMeter</h3>
<ol>
<li>Download JMeter from Apache's website: <a title="JMeter Downloads" href="http://jmeter.apache.org/download_jmeter.cgi" target="_blank">http://jmeter.apache.org/download_jmeter.cgi</a></li>
<li>Unzip to a location on your machine.</li>
<li>Add $jmeter_install_dir/bin to your path (Note: if you are using Windows, then I recommend just creating a shortcut to $jmeter_install_dir/bin/jmeter.bat)</li>
<li>Run the bin/jmeter command and you should see JMeter open a window.</li>
</ol>
<div><a href="https://earlyandoften.files.wordpress.com/2012/05/jmeter-window.png"><img class=" wp-image-1166" title="jmeter-window" src="https://earlyandoften.files.wordpress.com/2012/05/jmeter-window.png?w=1024" alt="" width="614" height="402" /></a></div>
<h3>Recording a Script</h3>
<p>The following instructions will setup JMeter to record a performance script that you can use for replay.  This is the fastest way of setting up a performance test script.</p>
<ol>
<li>Right-click on Test Plan and then select Add &gt; Threads (Users) &gt;  and Create a ThreadGroup</li>
<li>Right-click on the Workbench then select Add &gt; Non-Test Elements &gt; HTTP Proxy Server
<ol>
<li>Set the Target Controller to "Test Plan &gt;  Thread Group"</li>
<li>Set the Grouping to "Store 1st sampler of each group only"</li>
<li>Add Exclusions</li>
<li>Change Port (Optional)</li>
<li>Start the Proxy Server</li>
</ol>
</li>
<li>Click the Start button on the Http Proxy Server</li>
<li>Update IE to use a Proxy Server
<ol>
<li>Internet Options</li>
<li>Connections Tab</li>
<li>LAN Settings</li>
<li>Click 'User Proxy Server'</li>
<li>Enter localhost and port.</li>
<li>Click OK and OK.</li>
</ol>
</li>
<li>Start clicking through your application (make sure JMeter is recording your clicks)</li>
<li>Save the recording.</li>
</ol>
<h3>Adding Listeners</h3>
<p>JMeter uses listeners to record the results of the performance test.  Take a look at the various types of listeners <a title="JMeter Listeners" href="http://jmeter.apache.org/usermanual/listeners.html" target="_blank">here</a> and add one by right clicking on the Thread Group and adding a Listener there.</p>
<h3>Running a Performance Test</h3>
<p>Once your script is recorded and you have added listeners, make sure you save your script.  Now you can run it!</p>
<ol>
<li>Open up the ThreadGroup node and make the following changes:
<ol>
<li>Change the Number of Threads to the number of concurrent users you would like to run in the performance test.</li>
<li>Change the Ramp-up Period to the number of seconds it takes for all the users to start.</li>
</ol>
</li>
<li>In the menu, click Run, Start.</li>
<li>Sit back and watch JMeter ramp up!</li>
</ol>
<h3>Final Thoughts</h3>
<p>This post is intended to get you started with a simple JMeter performance test.  I also only focused on using JMeter to performance test a web application.  JMeter can performance test web apps, databases, JMS servers, email servers, LDAP servers, web services, and much more.  I recommend taking a look at JMeter's manual, available <a title="JMeter Manual" href="http://jmeter.apache.org/usermanual/index.html" target="_blank">here</a>.</p>
</p>
  			<a href="/blog/ruby-broke-my-path.html"><h1>Ruby Broke my $PATH</h1></a>
  			<p>06 May 2012</p>
  			<p><p>Yesterday I spent some time <a title="Octopress on OS X" href="http://earlyandoften.wordpress.com/2012/05/05/octopress-on-os/" target="_blank">getting Ruby up and running on my Mac</a>, with the intent of playing with <a title="Octopress" href="http://octopress.org/" target="_blank">Octopress</a>.  Today, I wanted to go back to a <a title="Grails" href="http://grails.org/" target="_blank">Grails</a> app I had been working on, when I realized that Grails was no longer in my PATH.  Somehow, my PATH variable had been "hijacked" by the <a title="Ruby" href="http://www.ruby-lang.org/en/" target="_blank">Ruby</a> or <a title="Ruby RVM" href="https://rvm.io/" target="_blank">RVM</a> installs.  I immediately started to investigate the issue.</p>
<pre>
$&gt; grails run-app
-bash: grails: command not found[/sourcecode" frameborder="0" allowfullscreen>
</pre>
First, I double checked my <em>~/.profile</em> file, where I added Grails to my PATH.  This was unchanged, but Grails was stil not being added to my PATH.<br />
<pre>
export GRAILS_HOME=~/Tools/grails-1.3.7
export PATH=/opt/local/bin:/opt/local/sbin:$GRAILS_HOME/bin:$PATH
</pre>
Ok, so <em>.profile</em> was no longer being run when I opened Terminal.  Interesting.  Now if you are a Unix sys admin, the solution will seem immediately apparent.  I had a strong suspicion that the issue was that some <em>~/.bash*</em> files were being run instead of the <em>.profile</em>.  I Googled around and learned more about how about the differences between <em>~/.bash_profile</em>, <em>~/.bash_login</em>, <em>~/.bashrc</em>, and my <em>~/.profile</em>.</p>
<p>Turns out my suspicion was correct.  The Ruby RVM installation had created a <em>.bashrc</em>, and now when my Bash shell logged in, it only ran the <em>.bash*</em> files and not my <em>.profile</em>.  In order to fix this, I had to tell Bash to load both my <em>.profile</em> and my <em>.bashrc</em>.  A simple way to do this was to add the following two lines to my <em>~/.bash_profile</em>:<br />
<pre>
. ~/.profile
. ~/.bashrc
</pre>
Once this was added and I reloaded Terminal, my Grails path entries were back and Ruby was still working fine.  Success!</p>
<p>For more on how Bash shell operates, check these useful resources out:</p>
<ul>
<li><a target="_blank">http://stefaanlippens.net/bashrc_and_others</a></li>
<li><a href="http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html" target="_blank">http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html</a></li>
</ul>
</p>
  			<a href="/blog/octopress-on-os.html"><h1>Octopress on OS X</h1></a>
  			<p>05 May 2012</p>
  			<p><p>I have been wanting to try <a title="Octopress" href="http://octopress.org/" target="_blank">Octopress</a> for a while, so I decided to spent my Friday night setting it up.  Unfortunately, I ran into a few issues installing and getting my environment setup, and I figured I would share my setup issues with everybody else.  I started with the instructions from the Octopress website.</p>
<p><a href="http://octopress.org/docs/setup/" target="_blank">http://octopress.org/docs/setup/</a></p>
<p>As you run into issues, the solutions are listed below.</p>
<h3>RVM and Ruby Installation</h3>
<p>First, you will need to install <a title="RVM" href="https://rvm.io/" target="_blank">RVM</a>.  I followed the instructions I found on the <a href="http://pragmaticstudio.com/blog/2010/9/23/install-rails-ruby-mac" target="_blank">Pragmatic Press article</a> for installing <a title="Ruby" href="http://www.ruby-lang.org/en/" target="_blank">Ruby</a> 1.9.  You can continue on with the <a title="Ruby on Rails" href="http://rubyonrails.org/" target="_blank">Rails</a> portion of the installation, but you don't need to for Octopress.  The only thing I would change is the version mentioned in the instructions from 1.9.3 to 1.9.2-p320, which is the version needed for Octopress.</p>
<h3>Bundler</h3>
<p>Once you get Ruby installed, you will also hit issues with installing bundler with <a href="https://github.com/thibaudgg/rb-fsevent" target="_blank">rb-fsevent</a>.  I found this <a href="https://github.com/thibaudgg/rb-fsevent/issues/26" target="_blank">bug report</a> that provides the <a href="https://github.com/thibaudgg/rb-fsevent/issues/26#issuecomment-4050279" target="_blank">solution</a> (mad props <a href="https://github.com/clippit" target="_blank">clippit</a>).  In short, you will need to run the following command before setting up Octopress:</p>
<pre>
sudo xcode-select -switch /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/
</pre>
<h3>Rake</h3>
<p>When I ran the 'rake install' command, I got the following error:</p>
<pre>
$ rake install rake aborted! You have already activated rake 0.9.2.2, but your Gemfile requires rake 0.9.2. Using bundle exec may solve this.[/sourcecode" frameborder="0" allowfullscreen>
</pre>
<p>There is also a <a href="https://github.com/imathis/octopress/issues/250" target="_blank">bug report</a> for this on Octopress, but it was easy enough to fix by just updating the Gemfile.lock to point to rake 0.9.2.2 instead of 0.9.2.  I imagine there is a better way to do this with Ruby, but since this is my first foray into Ruby development.</p>
<p>That should resolve your issues.  Best of luck!</p>
</p>
  			<a href="/blog/writing-user-stories.html"><h1>Writing User Stories</h1></a>
  			<p>04 May 2012</p>
  			<p><p>A friend recently asked me if I had any advise on how to write <a title="User Story (Wikipedia)" href="http://en.wikipedia.org/wiki/User_story" target="_blank">user stories</a>.  While I don't claim to be an expert on writing user stories, I knew enough to guide him.  Here's what I came up with.</p>
<h3>Why User Stories?</h3>
<p>User stories are a terse requirements format that puts emphasis on conversations rather than comprehensive documentation.  User stories are the preferred requirements format for <a title="Manifesto of Agile Software Development" href="http://agilemanifesto.org/" target="_blank">Agile</a> software development projects.  Other requirements formats, like <a title="Use Cases" href="http://en.wikipedia.org/wiki/Use_case" target="_blank">use cases</a>, attempt to provide a definitive requirements definition.  Unfortunately, due to their verbose nature, they do not allow for changes to the requirements that are discovered over time.  User stories excel at this.</p>
<h3>The 3 C's</h3>
<p><a title="Ron Jeffries" href="http://xprogramming.com/index.php" target="_blank">Ron Jeffries</a> defines <a title="Ron Jeffries 3 C's of User Stories" href="http://xprogramming.com/articles/expcardconversationconfirmation/" target="_blank">3 C's</a> which are the critical aspects of a user story:</p>
<ul>
<li><em><strong>Card</strong></em> - user stories should be written on a card.  This helps keep them small.  The card serves a placeholder for the conversation.  The card is what is used during <a title="Release Planning" href="http://www.extremeprogramming.org/rules/planninggame.html" target="_blank">release planning</a>.</li>
<li><em><strong>Conversation</strong></em> - as previously stated, a user story puts emphasis on having a conversation between the customer and the programmers.  Ron points out that these conversations can be supplemented by documents, and the best documents at examples.</li>
<li><em><strong>Confirmation</strong></em> - this refers to the acceptance criteria or test for each user story.  The customer should communicate the acceptance tests prior to development.  The best type of confirmation for a user story is an example, and preferably automated.</li>
</ul>
<h3>User Story Format</h3>
<p>User stories traditionally conform to the following format:</p>
<blockquote><p>As a &lt;type of user&gt;,<br />
I want &lt;some feature&gt;,<br />
So that &lt;some reason or business value&gt;</p></blockquote>
<p>Most agile experts would agree that the most important part of a user story is the last line, which defines the business value.  Since this the most important line, I tend to prefer <a title="Elizabeth Keogh" href="http://lizkeogh.com/" target="_blank">Elizabeth Keogh</a>'s <a title="Elizabeth Koening's User Story Format" href="http://sirenian.livejournal.com/47679.html" target="_blank">user story format</a>, that looks like this:</p>
<blockquote><p>In order to &lt;some reason or business value&gt;<br />
As a &lt;type of user&gt;,<br />
I want &lt;some feature&gt;</p></blockquote>
<p>This format places the business value statement first.  When writing a ne story, you are forced to think about the business value before the feature.</p>
<h3>INVEST</h3>
<p>The <a title="INVEST in good stories" href="http://xp123.com/articles/invest-in-good-stories-and-smart-tasks/" target="_blank">INVEST</a> model is a way of evaluating the quality of a user story.  Here's what it stands for:</p>
<ul>
<li><em><strong>Independent</strong></em> - a user story should not be dependent upon another story.</li>
<li><em><strong>Negotiable</strong></em> - the details of the story will be worked out during the conversation.  Talk about the story before working on it.</li>
<li><em><strong>Valuable</strong></em> - the user story needs to be valuable to the customer or user.</li>
<li><em><strong>Estimable</strong></em> - the estimation need not be perfect, but good enough so you can rank and schedule a story.</li>
<li><em><strong>Small</strong></em> - small is good.  Small is easier to estimate.</li>
<li><em><strong>Testable</strong></em> - make sure that you can validate the user story is done.  Write tests!</li>
</ul>
<h3>Further Reading</h3>
<p>For more information on user stories, I highly recommend these resources.  I especially recommend <a title="Fadi Stephan" href="https://twitter.com/#!/FadiStephan" target="_blank">Fadi Stephan</a>'s (a fellow <a title="Excella Consutling" href="http://excella.com/" target="_blank">Excellain</a>) great presentation, <a title="The Art of Storytelling" href="http://www.agilejourneyman.com/2010/10/art-of-storytelling.html" target="_blank">the Art of Storytelling</a>.</p>
<ul>
<li><a title="User Stories" href="http://www.mountaingoatsoftware.com/topics/user-stories">Michael Cohn on User Stories</a></li>
<li><a title="Wikipedia on User Stories" href="http://en.wikipedia.org/wiki/User_story" target="_blank">Wikipedia on User Stories</a></li>
<li><a title="User Stories at ExtremeProgramming.com" href="http://www.extremeprogramming.org/rules/userstories.html" target="_blank">Extreme Programming on User Stories</a></li>
<li><a title="Ron Jeffries on the 3C's" href="http://xprogramming.com/articles/expcardconversationconfirmation/" target="_blank">Ron Jeffries on the 3 C's</a></li>
<li><a title="Elizabeth Keogh on User Story Format" href="http://sirenian.livejournal.com/47679.html" target="_blank">Elizabeth Keogh on User Story Format</a></li>
<li><a title="Dan North on User Stories" href="http://dannorth.net/whats-in-a-story/" target="_blank">Dan North on User Stories</a></li>
</ul>
</p>
  			<a href="/blog/git-crashcourse.html"><h1>Git Crash Course</h1></a>
  			<p>03 May 2012</p>
  			<p><p>Our current team has decided to adopt Git and some members aren't familiar with it.  I wanted to put together a short introduction to the <a title="Git" href="http://git-scm.com/" target="_blank">Git</a> command line for these team members.  The goal is to make team members productive immediately, while learning the nuances of Git over time.  My introduction assumes that you have Git installed and setup.  For installation instructions, go to <a href="http://git-scm.com/">http://git-scm.com/</a>.  For instructions on configuring Git, I recommend <a title="GitHub" href="https://github.com/" target="_blank">Github</a>'s tutorials for <a title="Setup Github (Windows)" href="http://help.github.com/win-set-up-git/" target="_blank">Windows</a>, <a title="Setup GitHub (Mac)" href="http://help.github.com/mac-set-up-git/" target="_blank">OS X</a> and <a title="Setup GitHub (Linux)" href="http://help.github.com/linux-set-up-git/" target="_blank">Linux</a>.</p>
<h3>Cloning a Repository</h3>
<p>First, you need to get a copy of the source code on your machine from a repository.  With Git, you do this by cloning the repository locally.  Since Git is a distributed version control system (DVCS), it will copy the whole source code repository locally.  For more on DVCS, check out <a title="Not so quick guide to DVCS" href="http://www.infoq.com/articles/dvcs-guide" target="_blank">this</a>.</p>
<p>To clone a remote repository, you will need to use the Git <a title="Git clone Man Page" href="http://schacon.github.com/git/git-clone.html" target="_blank">clone</a> command.  The following is example of clone a public GitHub repository:</p>
<pre>
$&gt; git clone git@github.com:jmcgarr/java-bdd-examples.git
</pre>
<h3>Checking in Code</h3>
<p>Now that you have the code, you can begin making changes.  Once you are ready to check in these changes, there are a few steps you need to take to get the changes into a remote repository:</p>
<pre>
$&gt; git status -S
$&gt; git add . -A
$&gt; git commit -m &quot;Add a commit message here&quot;
$&gt; git push origin master
</pre>
<p>Line 1 issues a <a title="Git status man page" href="http://schacon.github.com/git/git-status.html" target="_blank"><em>status</em></a> command, telling you which files have changed locally.  The <a title="Git add man page" href="http://schacon.github.com/git/git-add.html" target="_blank">add</a> command on line 2 tells Git to stage all changed files so that they can be committed to your local repository.  The <a title="Git commit Man Page" href="http://schacon.github.com/git/git-commit.html" target="_blank">commit</a> command on line 3 will commit the changes you added to your local repository.  Line 4 is where you will <a title="Git push Man Page" href="http://schacon.github.com/git/git-push.html" target="_blank">push</a> the changes in your local repository to the remote repository.</p>
<blockquote><p>Note: Your fellow team members will not see your changes until you push them to the remote repository.  When you commit, you are only commit the change to your local copy of the repository</p></blockquote>
<h3>Getting the Latest Version</h3>
<p>Prior to pushing your changes to a remote repository, you may want to grab the latest code from the repository.  To get the latest remote changes, use the following commands:</p>
<pre>
$&gt; git fetch origin
$&gt; git merge master
</pre>
<p>Line 1 will sync your local Git repository with the remote Git repository.  Your working copy of the code will not be updated until you issue a merge command (line 2).  Git provides a way of combining these two commands into one, by using the <a title="Git pull Man Page" href="http://schacon.github.com/git/git-pull.html" target="_blank">pull</a> command:</p>
<pre>
$&gt; git pull origin master
</pre>
<p>This command will fetch the remote repository changes, and merge them into the master branch.</p>
<h3>Learn More</h3>
<p>Git is a powerful version control tool and it is extremely useful.  This tutorial should get you started immediately.  But be warned, that you should take the time to learn more about Git and how it works.  Here are some useful resources for learning more about Git:</p>
<ul>
<li><a title="Git Reference" href="http://gitref.org/" target="_blank">http://gitref.org/</a></li>
<li><a title="Git Visual Guide" href="http://marklodato.github.com/visual-git-guide/index-en.html" target="_blank">http://marklodato.github.com/visual-git-guide/index-en.html</a></li>
<li><a title="GitHub Help" href="http://help.github.com/remotes/" target="_blank">http://help.github.com/remotes/</a></li>
<li><a title="Scott Chacon on Git" href="http://www.youtube.com/watch?v=ZDR433b0HJY" target="_blank">http://www.youtube.com/watch?v=ZDR433b0HJY</a></li>
</ul>
</p>
  			<a href="/blog/simple-git-aliases.html"><h1>Simple Git Aliases</h1></a>
  			<p>02 May 2012</p>
  			<p><p>I have been using <a title="Git" href="http://git-scm.com/" target="_blank">Git</a> for a while now and in that time, I have learned the value of using aliases.  Whenever I setup a new machine with git, adding my favorite aliases is first on my list.  I wanted to capture some of my favorite aliases here.  This will serve as not only a reference for myself, but hopefully helpful for others.</p>
<p>The following code snippet shows the alias portion of my ~/.gitconfig.  :</p>
<pre>
[alias" frameborder="0" allowfullscreen>
 st = status -s
 br = branch
 pl = pull origin master
 rm = remote -v
 lg = log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)%Creset' --abbrev-commit --date=relative
</pre>
<p>Here are the commands you can run to add the aliases to your global config.</p>
<pre>
$&gt; git config --global alias.st &quot;status -s&quot;
$&gt; git config --global alias.lg &quot;log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit --date=relative&quot;
$&gt; git config --global alias.pl &quot;pull origin master&quot;
$&gt; git config --global alias.rm &quot;remote -v&quot;
</pre>
<p>Here is a list of some other git aliases:</p>
<ul>
<li><a href="http://superuser.com/questions/169695/what-are-your-favorite-git-aliases">http://superuser.com/questions/169695/what-are-your-favorite-git-aliases</a></li>
<li><a href="http://viget.com/extend/three-magical-git-aliases">http://viget.com/extend/three-magical-git-aliases</a></li>
<li><a href="http://www.catonmat.net/blog/git-aliases/">http://www.catonmat.net/blog/git-aliases/</a></li>
</ul>
</p>
  			<a href="/blog/sonar.html"><h1>Assessing Code Quality with Sonar</h1></a>
  			<p>01 May 2012</p>
  			<p><p>I recently joined a development team where I was asked to help improve the team’s code quality and engineering practices.  Soon after joining the team, I noticed numerous code quality issues that needed to be addressed.  In order to justify the effort to improve code quality to non-technical decision makers, I needed a quantitative method for measuring the quality of the source code and possibly the technical debt.  I had heard a lot about a tool called <a title="Sonar" href="http://www.sonarsource.org/" target="_blank">Sonar</a>, so I decided to give a try.  It proved to be more than up to challenge and helped me quickly demonstrate the risk due to code quality the team had incurred.<br />
<strong><br />
What is Sonar?<img class="alignleft" title="Sonar" src="http://www.sonarsource.org/wp-content/themes/sonarsource.org/images/sonar.png" alt="" width="100" height="54" /><br />
</strong>Sonar is a Java-based open source server product that centrally hosts your organization’s source code quality rules and metrics.  It provides a hub for managing, viewing and comparing code quality throughout an organization.  Code quality metrics are neatly displayed in easy to read dashboards and charts.<br />
<strong><br />
</strong>Sonar provides a number of features that make managing code quality a snap.<br />
<strong><br />
Simple Project Integration<br />
</strong>Sonar makes it easy to integrate a new project.  All you have to do is point your build tool (<a title="Ant" href="http://ant.apache.org/" target="_blank">Ant</a>, <a title="Maven" href="http://maven.apache.org/" target="_blank">Maven</a> or <a title="Gradle" href="http://gradle.org/" target="_blank">Gradle</a>) at the Sonar server and run a build.  And that’s it.  The Sonar build integration will connect to the Sonar server, download any plugins or configurations and run them locally against your project’s source code.  It will then publish the results back to Sonar.  Sonar also provides a stand-alone publisher that you can run against source code if you aren’t using a build tool (although you really should be).<br />
<strong><br />
</strong>Traditionally, you would have to configure individual static code analysis tools inside your build script.  This build configuration would have to replicated to each project’s build script.  Sonar vastly reduces the need for this type of duplication.<br />
<strong><br />
Centralized Rules Management<br />
</strong>All static code analysis plugin configuration happens on the Sonar server.  Sonar allows you to define which plugins a project should use, as well as the rules to apply.  As you change the configurations on the server, every project will automatically download and run with these new plugins or configurations.  It is that simple!<br />
<strong><br />
Dashboards<br />
</strong>One of the best parts of Sonar is its dashboarding capability.  There is a variety of plugins and out of the box visualizations that you can add to a project’s dashboard.  These dashboards can be focused on a particular project, a module of a project or all of the projects within an organization.  Most of the information is presented to help you quickly find problem areas and address it.<br />
<strong><br />
<a href="https://earlyandoften.files.wordpress.com/2012/04/technical-debt.png"><img class="wp-image-1038 alignright" title="technical-debt" src="https://earlyandoften.files.wordpress.com/2012/04/technical-debt.png" alt="" width="380" height="123" /></a>Technical Debt Calculator<br />
</strong>One of the most compelling features of Sonar the build in Technical Debt Calculator.  For me, this is what single handedly caught the attention of my clients.  Sonar’s Technical Debt Calculator puts a dollar value on how much it will cost to fix the various code quality issues and defects.  Technical debt is calculated based on duplicated code, static code analysis violations, code comments, unit test coverage and cyclomatic complexity.   I recommend reading about how <a title="Technical Debt Calculator in Sonar" href="http://www.sonarsource.org/evaluate-your-technical-debt-with-sonar/" target="_blank">technical debt is calculated</a> on Sonar’s <a title="Sonar Blog" href="http://www.sonarsource.org/category/blog/" target="_blank">blog</a>.<br />
<strong><br />
Code Reviews<br />
</strong>I was pleasantly surprised to find that there was a code review tool built into Sonar.  In the past, I have hunted for a simple tool to enable asynchronous code reviews on a development team.  Sonar provides a Github like code commenting feature.  In addition, I can turn these comments into tasks and assign them to a developer to work on.  You can read more about Sonar’s code review features <a title="Code Reviews with Sonar" href="http://www.sonarsource.org/effective-code-review-with-sonar/" target="_blank">here</a>.<br />
<strong><br />
Cross-Language<br />
</strong>While Sonar provides first class support for Java, it also supports numerous other programming languages including C#, VB6, Groovy, PL/SQL, Cobol and more.  This makes Sonar an even more compelling code quality platform for an organization that has multiple technology platforms.</p>
<p>In my opinion, Sonar is an amazing compliment to any organization’s existing suite of development support tools.  It is simple, easy to setup and provides value almost immediately.  A great place to start is Sonar's documentation, which can be found <a title="Sonar Documentation" href="http://www.sonarsource.org/support/documentation/" target="_blank">here</a>.</p>
</p>
  			<a href="/blog/avoid-code-freezes.html"><h1>Avoid Code Freezes</h1></a>
  			<p>30 April 2012</p>
  			<p><p>A project manager recently told me that he wanted to implement a code freeze prior to user acceptance testing.  This request struck me as odd since I don’t recall having implemented a code freeze on a project in years.  My immediate response was that we do not need a code freeze.  All checked in code is tested for its production readiness via a deployment pipeline.</p>
<p>The intent of a code freeze is to identify and lock down a known "good" state of the source code.  The code can then be built, and then deployed from this known "good" state.  If a developer checks in a change after a code freeze, then this known "good" state can be considered tainted.   The intent behind implementing a code freeze is well placed, but the execution slows down a team’s progress.</p>
<p>The need to implement a code freeze demonstrates a lack of understanding of version control systems (VCS).  Most VCS allow you to tag a particular known state of source code.  By tagging a known “good” state of the source code, developers can continue checking in changes.  The tagged known “good” state can now be built and deployed, without slowing down developers.</p>
<p>Deployment pipelines make this process much simpler to administer.  As changes are checked into version control, the continuous integration server checks out the new revision and executes a build.  If the change passes all tests in the pipeline, then the revision is tagged.  Ideally, this tag maps back to the build number using a naming convention.  This provides traceability.</p>
<p>So if you find yourself in a situation where you want to implement a code freeze, think twice before you do.  It is likely that you can get around this by better utilizing your VCS.</p>
</p>
  			<a href="/blog/we-arent-failing-fast-enough.html"><h1>We arent failing fast enough...</h1></a>
  			<p>30 March 2012</p>
  			<p><p>I am sure many of you have read <a title="Jeff Atwood at CodingHorror.com" href="http://www.codinghorror.com/blog/" target="_blank">Jeff Atwood</a>s' last two blog posts regarding <a title="Coding Horror - What you can't see you can't get" href="http://www.codinghorror.com/blog/2012/03/what-you-cant-see-you-cant-get.html" target="_blank">WYSIWIG</a> and <a title="Coding Horror - Visualizing Code to fail faster" href="http://www.codinghorror.com/blog/2012/03/visualizing-code-to-fail-faster.html" target="_blank">visualizing failing faster</a>.  If you haven't, I definitely recommend reading both, playing with <a title="The Glimpse Project" href="http://www.aviz.fr/gliimpse/" target="_blank">Glimpse</a>, and watching <a title="Bret Victor" href="http://worrydream.com/" target="_blank">Bret Victor</a>'s video on <a title="Bret Victor - Inventing on Principle" href="http://vimeo.com/36579366" target="_blank">Inventing on Principle</a>.</p>
<p>Both of Jeff's posts focus on how you can and should be striving for a faster feedback loop for code/markup.  Glimpse provides a nice animation for rendering markup results with just a key press.  Glimpse still requires you to switch back and forth between the two views.  Bret Victor takes this a step further by allowing you to showing the results of your changes immediately and contiguously.  His tools also added features like slides to change values and get feedback on those you wouldn't be able to achieve otherwise.  Amazingly powerful and the further of IDE's in my opinion.</p>
<p>While I watched Bret Victor's presentation, I immediately felt the urge to learn more Javascript (it was cool to see how much you can visually).  My next thought was how cool his binary search example was.  Being able to see the method "trace" in real time as you type is the fastest feedback loop I can imagine (without the IDE being predictive).  This feature is amazingly powerful and I wanted to use it now.  As I watch more of the video, I realized that Bret's Javascript IDE is essentially an "always on" debugger.  Debugger usage is something that I discourage developers from using, in favor of unit tests.  How does Bret's vision of feedback fit into my development beliefs?</p>
<p>As I reflected on this more, I realized that Bret's vision fits in perfectly, so long as you could add another feature to his IDE.  The feedback Bret's IDE provides allows his to essentially define and run tests very quickly.  What is missing from this is capturing of the inputs and expected output into a repeatable test.  If the IDE was extended to capture various "tests" as unit tests, then you have the best of both worlds.  Now I can write code (and tests) rapidly, get my feedback and move on.</p>
<p>I am inspired by both of these posts and tools to find ways of improving my personal feedback loop and productivity.  There are slight improvements to my personal productivity that I can apply today.  <a title="InfiniTest" href="http://infinitest.github.com/" target="_blank">InifiniTest</a> is a great <a title="Eclipse IDE" href="http://www.eclipse.org/" target="_blank">Eclipse</a> plugin for automatically running unit tests as you change code.  <a title="Grails" href="http://grails.org/" target="_blank">Grails</a> (a <a title="Groovy" href="http://groovy.codehaus.org/" target="_blank">Groovy</a> web framework) is an example of a framework that dynamically recompile code that is deployed.  This allows developers to edit, save, refresh to see changes, as opposed to the edit, save, compile, package, deploy, refresh feedback loop of traditional Java web frameworks.  I look at my current project's Ant/Ivy build script that takes 10+ minutes to compile and run unit tests and I lament that it fails the <a title="Paul Julius - Cup of Coffee Metric" href="http://pauljulius.com/blog/2009/09/14/cup-of-coffee-metric-for-continuous-integration/" target="_blank">cup of coffee test</a>, but should I look further.  The faster the feedback, the faster you find bugs, the faster you develop.  How fast do you fail?</p>
</p>
  			<a href="/blog/developer-reading-lis.html"><h1>A Developers Reading List</h1></a>
  			<p>20 February 2012</p>
  			<p><p>I recently had an interesting conversation with a developer about unit testing, object-oriented design and in general, how to write good code.  Our discussion went around in circles, and I found myself where I usually end up in conversations like this, quoting experts like <a title="Martin Fowler's website" href="http://martinfowler.com/" target="_blank">Martin Fowler</a>, <a title="Uncle Bob on Twitter" href="https://twitter.com/#!/unclebobmartin" target="_blank">Uncle Bob</a>, and numerous others.  Having had the conversation numerous times before, I decided it was about time I compile a list of my favorite books that all developer's should read.  This is not intended to be a comprehensive list of the greatest books ever, but merely books that I have found invaluable to contributing to better code and projects.</p>
<ul>
<li><a title="The Pragmatic Programmer, the book" href="http://pragprog.com/the-pragmatic-programmer" target="_blank">The Pragmatic Programmer: From Journeyman to Master</a> (Andy Hunt and David Thomas) - This is probably the bible of the modern software engineer.  Provides practical advise about how to write software smartly.</li>
<li><a title="Amazon.com book" href="http://www.amazon.com/Growing-Object-Oriented-Software-Guided-Tests/dp/0321503627" target="_blank">Growing Object-Oriented Code, Guided by Tests</a> (Steve Freeman and Nat Pryce) - Exceptional book on how to execute Test Driven Development, with a special emphasis on mocking.  I especially like their approach of starting with end-to-end tests and working your way through the design.</li>
<li><a title="Continuous Delivery the book." href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912" target="_blank">Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation</a> (Jez Humble and David Farley) - When I read this book, I was furious at all the time I wasted on previous projects doing it wrong.  This book changed my view of how to run a software project.</li>
<li><a title="Clean Code, the book" href="http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882" target="_blank">Clean Code: A Handbook of Agile Software Craftsmanship</a> (Robert C. Martin) - This book contains an amazing collection of advise and guidance on how to write code.</li>
<li><a title="Working Effectively with Legacy Code, the book" href="http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052" target="_blank">Working Effectively with Legacy Code</a> (Michael Feathers) - This book is by no means just about Legacy Code, but it is also about refactoring, design and most importantly testing.  Even though some of the examples are in C++, I still found this book absolutely essential in the consulting industry.</li>
<li><a title="The Productive Programmer, the book" href="http://www.amazon.com/Productive-Programmer-Theory-Practice-OReilly/dp/0596519788" target="_blank">The Productive Programmer</a> (Neal Ford) - In my o pinion, an underrated book.  This book focuses on how to make yourself more productive as a programmer by automating tasks in your development environment.</li>
<li><a title="Release It!, the book" href="http://pragprog.com/book/mnee/release-it" target="_blank">Release It! Design and Deploy Production Ready Software</a> (Michael Nygard) - Great book about how to design scalable and stable systems that can with stand the test of production.</li>
<li><a title="Specification by Example, the book" href="http://www.amazon.com/Specification-Example-Successful-Deliver-Software/dp/1617290084" target="_blank">Specification by Example: How Successful Teams Deliver the Right Software</a> (Gojko Adzic) - My most recent addition to my favorite books list and the least technical of the bunch.  This book focuses on how your team identifies, evaluates and refine requirements into executable specifications.</li>
</ul>
<p>I would love to hear what other developers think should be on this list.  Enjoy!</p>
</p>
  			<a href="/blog/mcjug-return.html"><h1>My Return Visit to the Montgomery County Java Users Group</h1></a>
  			<p>17 February 2012</p>
  			<p><p>On Wednesday night, I returned to the <a title="MCJUG" href="http://www.mcjug.org/" target="_blank">Montgomery County Java User's Group (MCJUG)</a> to give a follow-up to last year's <a title="CD at MCJUG" href="http://earlyandoften.wordpress.com/2011/06/17/cd-at-mcjug/" target="_blank">Continuous Delivery talk</a>.  This week, I focused on the tools and techniques that a developer, team and organization can use to migrate to <a title="Continuous Delivery website" href="http://continuousdelivery.com/" target="_blank">Continuous Delivery</a>.  The subject areas which I touch on are:</p>
<ul>
<li>Version Control</li>
<li>Build Automation</li>
<li>Dependency Management</li>
<li>Static Code Analysis and Technical Debt</li>
<li>Test Automation</li>
<li>Continuous Integration</li>
<li>Deployment Automation</li>
<li>Infrastructure Management</li>
<li>Monitoring</li>
</ul>
<p>Like last time I talked here, the audience was great.  They had great questions and everybody felt comfortable sharing their experiences.  At times it felt almost like a conversation than a presentation, and I loved it.  All in all, I thought it was a great evening and I look forward to returning to the group in the future to give another talk.</p>
<p>After my presentation, <a title="Ben Muschko at Github.com" href="https://github.com/bmuschko" target="_blank">Ben Muschko</a> gave a great talk on <a title="Gradle" href="http://gradle.org/" target="_blank">Gradle</a>.  Ben is a super smart guy and is very his talk on Gradle sparked a lot of interest from the crowd, especially from the Maven users who have felt the pain of trying to break the convention.  I look forward to seeing Ben at a future <a title="Washington DC Area Groovy User Group" href="http://www.dcgroovy.org/" target="_blank">DC Groovy User Group</a> meeting, as well as diving deep into Gradle.</p>
<p>For those interested in getting a copy of my slides, you can download the PDF from my GitHub account.</p>
<p style="text-align:left;"><a href="https://github.com/jmcgarr/presentations/blob/master/continuousDeliveryTools-mcjug-20120215/Continuous%20Delivery%20-%20Tools%20and%20Techniques.pdf?raw=true"><img class="aligncenter" title="Click to download a PDF of the slides." src="http://dl.dropbox.com/u/3118373/blog-images/cd-tools-techniques.png" alt="" width="576" height="432" /></a></p>
<p style="text-align:left;"><a title="Download PDF" href="https://github.com/jmcgarr/presentations/blob/master/continuousDeliveryTools-mcjug-20120215/Continuous%20Delivery%20-%20Tools%20and%20Techniques.pdf?raw=true" target="_blank">Click here to download slides as PDF</a></p>
<p>I wanted to thank to <a title="Victor Semenov at Twitter.com" href="https://twitter.com/#!/victorsemenov" target="_blank">Victor Semenov</a> for organizing the event, as well as special thanks to my friends and colleagues who came out to see me talk.</p>
</p>
  			<a href="/blog/impress_js_github.html"><h1>Interactive presentations with impress.js + GitHub Pages</h1></a>
  			<p>16 January 2012</p>
  			<p><p>Next month, I am giving a follow-up of my <a title="Continuous Delivery Talk" href="http://earlyandoften.wordpress.com/2011/06/17/cd-at-mcjug/" target="_blank">Continuous Delivery talk</a> to the <a title="MCJUG" href="http://www.mcjug.org/" target="_blank">Montgomery County Java User's Group</a>.  In preparing for this talk, I decided that challenge myself by using a presentation tool other than PowerPoint.  In fact, I decided to avoid any desktop variant and try some of the next generation web-based presentation tools.</p>
<p>I first considered <a title="Showoff" href="https://github.com/schacon/showoff" target="_blank"><img class="alignright" src="http://www.ruby-lang.org/images/logo.gif" alt="" width="186" height="67" />Showoff</a>, a nice framework for building presentations in HTML (running on <a title="Ruby" href="http://www.ruby-lang.org/" target="_blank">Ruby</a>/<a title="Sinatra" href="http://www.sinatrarb.com/" target="_blank">Sinatra</a>).  This tool is hot in the developer community right now.  Since it is a running application, it depends on deploying to hosting provider like <a title="Heroku" href="http://www.heroku.com/" target="_blank">Heroku</a>.  It does have a nice simple markdown for capturing content and I would consider using it in the future.</p>
<p><img class="alignleft" src="http://www.w3.org/html/logo/downloads/HTML5_Logo_512.png" alt="" width="88" height="88" /><a title="HTML5 Slides" href="http://slides.html5rocks.com/#landing-slide" target="_blank">HTML5 Slides</a> is more of a demonstration on how you can use <a title="HTML5" href="http://en.wikipedia.org/wiki/HTML5" target="_blank">HTML5</a>/<a title="CSS3" href="http://www.css3.info/" target="_blank">CSS3</a>'s features to build web-based slide shows.  I considered this option as a way to learn more about HTML5.  The pages still need to hosted somewhere, and <a title="AWS S3" href="http://aws.amazon.com/s3/" target="_blank">AWS S3</a> would be the perfect location.</p>
<p><a title="Prezi" href="http://prezi.com/" target="_blank"><img class="alignright" src="http://upload.wikimedia.org/wikipedia/en/c/cd/Prezi_logo.jpg" alt="" width="169" height="68" />Prezi.com</a> is a service for building Flash-based presentations that break the convention of slides.  With Prezi.com, you can build dynamic visual presentations where the camera moves about on a page.  Public presentations are hosted for free, but you would have to pay for private presentations.  While Prezi <del datetime="2012-01-17T02:33:17+00:00">does</del> did offer a unique presentation style, I didn't feel the platform (Flash-based) fit my needs.</p>
<p>In the end, I chose <a title="impress.js" href="https://github.com/bartaz/impress.js" target="_blank">impress.js</a>, as it seemed to be the best of all solutions.  Impress.js is essentially an HTML5 presentation framework that enables you to build Prezi.com like presentations. (thanks to <a title="MattMakai.com" href="http://www.mattmakai.com/" target="_blank">Matt Makai</a> for pointing this tool out)  You build your presentations in html (div = slide) and using tags and css, you can manipulate size, position, scale and even animation within your slide.  It is also the newest tool on the scene and seems promising.  By building my presentation in impress.js, I will be forced to beef up my front-end skills, which have been lacking as of late.</p>
<p>I also discovered that impress.js presentations can easily be hosted on <a title="GitHub" href="https://github.com/" target="_blank">GitHub</a> using <a title="GitHub Pages" href="http://pages.github.com/" target="_blank">GitHub Pages</a>.  Since my presentation is just a web page, all I have to do is push my changes to the <em>gh-pages</em> branch of my GitHub repository and wait for the site to be displayed.  GitHub will deploy the website using a url following this convention:</p>
<blockquote><p>http://${username}.github.com/${repositoryname}</p></blockquote>
<p>Github Pages works for private repositories as well, and all you need to do to enable it is create the <em>gh-pages</em> branch.  Having my presentation displayed directly from version control with a simple url makes the process simple to manage.  Updates to the latest version are a git add, commit, push away.</p>
<p>Since I am just starting down this road, I may have some further feedback on how these tools work out, but so far, the presentation is looking great!  If interested in any or all of these presentation technologies, here are some sample presentations:</p>
<ul>
<li><a title="TDD your CLI presentation" href="http://tdd-ruby-cli.heroku.com/#1" target="_blank">TDD your CLI</a> by <a title="Dave Copeland's website" href="http://www.naildrivin5.com/" target="_blank">Dave Copeland</a> (showoff)</li>
<li><a title="HTML5 Slides" href="http://slides.html5rocks.com/#landing-slide" target="_blank">HTML5 Demo Slides</a> at <a title="HTML5 Rocks " href="http://www.html5rocks.com/en/" target="_blank">HTML5Rocks</a> (HTML5 slides)</li>
<li><a title="Coca Cola Company Presentation" href="http://prezi.com/ftv9hvziwqi2/coca-cola-company/" target="_blank">Coca Cola Company</a> (Prezi.com)</li>
<li><a title="12412.org Presentation" href="http://extra.12412.org/digibury/#/title" target="_blank">12412.org Presentation</a> (impress.js)</li>
</ul>
</p>
  			<a href="/blog/jenkins-github-int.html"><h1>Jenkins and GitHub: Integration</h1></a>
  			<p>30 December 2011</p>
  			<p><p>I've been trying to setup a <a title="Jenkins CI Server" href="http://jenkins-ci.org/" target="_blank">Jenkins</a> build of a private <a title="GitHub" href="https://github.com/" target="_blank">GitHub</a> project recently and found it wasn't as straight forward as I thought.  GitHub provides a feature called <a title="Github's Deploy Keys" href="http://help.github.com/deploy-keys/" target="_blank">Deploy Keys</a>, which are SSH keys used to authenticate servers to your GitHub repository.  Here's how I set them up.</p>
<ol>
<li>On your Jenkins server, generate a new SSH key if you don't already have one.  (Make sure you are logged in as the user that Jenkins runs as): ssh-keygen -t rsa</li>
<li>Log into your GitHub project and click the project's admin button.</li>
<li>Click the Deploy Keys link and add a new key.</li>
<li>Copy the contents of the public key you just generated (id_rsa.pub) into the GitHub Deploy Keys field.</li>
</ol>
<p>That's it!  Now, using the <a title="Jenkins Git Plugin" href="https://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin" target="_blank">Jenkins Git plugin</a>, you can point your Jenkins Build Job at your GitHub repository and it should authenticate just fine.</p>
<p>This will only work for one repository.  GitHub requires that your Deploy Keys be unique among your repositories.  Ideally, you should be able to create multiple SSH keys on your Jenkins server, but I had trouble getting this to work.  What I ended up doing instead was <a title="Git Setup" href="http://help.github.com/mac-set-up-git/" target="_blank">adding the SSH public key</a> to my <a title="Mike McGarr's GitHub account" href="https://github.com/jmcgarr" target="_blank">GitHub user account</a>.  This allows Jenkins build access to any of the private repositories I create.</p>
<p>I would ideally like to get the<a title="Jenkins GitHub Plugin" href="https://wiki.jenkins-ci.org/display/JENKINS/Github+Plugin" target="_blank"> Jenkins GitHub plugin</a> working, but after a 10 minute test, I stuck with my current setup so that I can move on to the next problem.</p>
</p>
  			<a href="/blog/dependency-management-in-net.html"><h1>Dependency Management in .NET</h1></a>
  			<p>17 December 2011</p>
  			<p><p>I have been a <a title="Java" href="http://www.oracle.com/technetwork/java/javase/overview/index.html" target="_blank">Java</a> developer for over 10 years, during which I have used <a title="Maven" href="http://maven.apache.org/" target="_blank">Maven</a> or one of it's successors (<a title="Gradle" href="http://gradle.org/" target="_blank">Gradle</a> or <a title="Ant" href="http://ant.apache.org/" target="_blank">Ant</a>+<a title="Apache Ivy" href="http://ant.apache.org/ivy/" target="_blank">Ivy</a>) for build and dependency management.  It was obvious to me early on that Maven's <a title="Dependency Management" href="http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html" target="_blank">dependency management</a> was its killer feature.  I began evangelizing Maven and converting teams to use it.  The days of checking .jar files into version control were over, and I rejoiced!</p>
<p>Six months ago, I started coaching a number of <a title="Microsoft .NET" href="http://www.microsoft.com/net" target="_blank">.NET</a> development teams on Agile Engineering best practices.  This was an eye-opening experience for me and I learned a lot about .NET.  While there were some bright spots, namely <a title="C Sharp, the programming Language" href="http://en.wikipedia.org/wiki/C_Sharp_(programming_language)" target="_blank">C#</a>, I was surprised how .NET seemed to be lacking in certain areas that were fairly mature in the Java community.  The most notable omision was the lack of a dependency management framework for .NET.</p>
<p>After my experiences with these teams, and discussing this problem with other .NET experts, I have come to realize that the standard practice is to check in .dlls to version control.  I was appalled.  When coaching teams on conduct unit testing, build automation, and continuous integration, I found the lack of a proper dependency management solution to be a huge problem.  Adding .dll's to version control works ok for third-party libraries, but when I want to consume a "working" version of another team's code as they change it, this becomes a burden that Maven solved gracefully.</p>
<p>I then discovered <a title="NuGet" href="http://nuget.codeplex.com/" target="_blank">NuGet</a>, and hope returned.  NuGet is a .NET open source project that's sole purpose is dependency management in .NET.  Yes, just what the agile engineering coach ordered.  Right?  Wrong.  NuGet, while a promising project, is still young and lacks numerous dependency management features.  NuGet was originally designed as a <a title="Microsoft Visual Studio IDE" href="http://msdn.microsoft.com/en-us/vstudio/aa718325" target="_blank">Visual Studio</a> extension for allowing developers to search for, download and add libraries to their solution.  Developers would then check in the .dlls to version control.  What!?  Isn't this what we are trying to avoid?</p>
<p>In reading the forums (<a title="Snapshot Functionality in NuGet" href="http://nuget.codeplex.com/discussions/238169" target="_blank">here</a>, <a title="NuGet for Large Teams" href="http://nuget.codeplex.com/discussions/268636" target="_blank">here</a>, <a title="NuGet Request" href="http://nuget.codeplex.com/discussions/268100" target="_blank">here</a>, and <a title="NuGet for Setup only" href="http://nuget.codeplex.com/discussions/236592" target="_blank">here</a>), it appears that users where complaining that NuGet wasn't doing enough dependency management.  In fact the project organizers were hesitant to add Maven-style dependency management.  "We need NuGet to support continuous integration!", the community cried.  Well thankfully, NuGet is an open source project and the features for restoring dependencies has been added to the <a title="NuGet 1.6 Release Notes" href="http://docs.nuget.org/docs/release-notes/nuget-1.6" target="_blank">1.6 release</a>.  With this release, you Nuget can be setup to restore packages that haven't been checked in, as well as support for "beta" releases.  For me, this change is still half cocked and fails to establish the benefits that Maven provided years ago.</p>
<p>NuGet is a promising young project and I hope that it will continue to grow and do well.  The .NET community desperately needs it to grow up fast and support more features.  In the spirit of open source development, I have done my part to support the project by submitting <a title="NuGet Bug Report" href="http://nuget.codeplex.com/workitem/1780" target="_blank">a bug report</a>.  I wish the Nuget team, as well as the rest of the .NET community the best of luck.</p>
</p>
  			<a href="/blog/teamcity-port.html"><h1>Gotcha when changing TeamCity&apos;s default port</h1></a>
  			<p>17 November 2011</p>
  			<p><p>I ran into an issue today where I changed my <a title="StackOverflow on changing TeamCity's default port" href="http://stackoverflow.com/questions/2387375/teamcity-change-port-for-web-server" target="_blank">TeamCity default port (from 8080)</a> and found that my build agents were suddenly disconnected.  After some fiddling around, I discovered that I needed to manually change each Build Agent's configuration to point to the new master server port.</p>
<p>To make this change, open up the $TEAMCITY_HOME/buildAgent/conf/buildAgent.properties file and update the following value:</p>
<pre>
serverUrl=http:\://localhost\:8080
</pre>
<p>In this case, the agent is running on the same server as the master server.  Once you restart the build agent, the master server recognizes the agent as back online.  Hope this helps.</p>
</p>
  			<a href="/blog/test-method-names.html"><h1>Exploring Test Method Names</h1></a>
  			<p>10 November 2011</p>
  			<p><p>When coaching individuals on how to name unit test methods, I have struggled to come up with a standard that I like.  I have read numerous posts and books on the subject with a wide variety of results and standards.  In this blog I will explore the various standards for naming unit test methods and present my perspective on the subject.</p>
<p>Prior to discussing unit test methods, I want to mention that the naming conventions for unit test <em>classes</em> are fairly well solidified.  I will assume that everybody will using the following naming convention for their unit test classes:</p>
<blockquote><p>[NameOfClassUnderTest" frameborder="0" allowfullscreen></iframe>Test</p></blockquote>
<p>Some conventions specify that the 'Test' postfix be 'Tests'.  I personally don't care about the difference between the two, so long as your team uses one or the other and not both.</p>
<p><strong>JUnit</strong></p>
<p><a title="JUnit" href="http://www.junit.org/" target="_blank">JUnit</a> is one of the first unit testing frameworks and one could argue is responsible for the explosion of unit testing over the past ten years.  In previous versions of JUnit, it was necessary that the name of the unit test method be prefixed with <strong>test</strong>.  This was how the JUnit runner identified unit test methods.  So a unit test method name might look like this:</p>
<pre class="prettyprint language-groovy">
public void testAddingTwoNumbers();
</pre>
<p>This framework limitation unit test method name was overcome in JUnit 4.  In JUnit 4, it is possible to use <a title="Java 5 Annotations" href="http://download.oracle.com/javase/1,5.0/docs/guide/language/annotations.html" target="_blank">Java 5's annotations</a> to tag a method as a test method.</p>
<pre class="prettyprint language-groovy">
@Test public void addingTwoNumbers();
</pre>
<p>Most modern test frameworks no longer force developers to prefix the test method name with the word test.  I prefer to avoid frameworks that impose this convention, but there are <a title="Grails unit testing" href="http://grails.org/doc/latest/guide/9.%20Testing.html" target="_blank">exceptions</a>.</p>
<p><strong>The Art of Unit Testing</strong></p>
<p><a title="Roy Osherove" href="http://osherove.com/blog" target="_blank">Roy Osherove</a> wrote a great book on unit testing called <a title="The Art of Unit Testing" href="http://artofunittesting.com/" target="_blank">the Art of Unit Testing</a>.  While this book was focused on <a title="Microsoft .NET" href="http://en.wikipedia.org/wiki/.NET_Framework" target="_blank">.NET</a> testing approaches, there is a lot of good recommendations there applicable to all developers, and I would recommend it.</p>
<p>In this book (as well as his <a title="Roy's Naming standards" href="http://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html" target="_blank">blog</a>), Roy recommends a unit test method naming convention that uses the following pattern:</p>
<blockquote><p>[MethodName_StateUnderTest_ExpectedBehavior" frameborder="0" allowfullscreen></iframe></p></blockquote>
<p>While I appreciate how comprehensive this standard is, I don't personally subscribe to this approach.  I find that this approach doesn't put enough emphasis on the overall behavior of the class under test, but rather inputs and outputs of methods on the class.  When applying TDD, I find that I think more about behavior than I do inputs/outputs.</p>
<p><strong>Introducing BDD</strong></p>
<p>Dan North introduced Behavior Driven Development, or BDD in 2006 with an article in Better Software magazine (which you can read <a title="Dan North introducing BDD" href="http://dannorth.net/introducing-bdd/" target="_blank">here</a>).  In this article, Dan discusses the series of revelations he had regarding unit test naming conventions before he came across BDD's Given When Then convention.  I am not going to go over BDD here, but I definitely recommend reading this article.</p>
<p>While I personally love BDD and feel it is extremely valuable in defining human readable tests, I feel it aligns much better with acceptance testing than unit testing.  What peaked my interest in this article was some of the intermediate steps Dan made on his way to BDD, namely "test method names should be sentences".  He references a friend's open source project <a title="AgileDox" href="http://agiledox.sourceforge.net/" target="_blank">agiledox</a> that turned a unit test class into a document describing what the class does.  For instance, given this unit test class:</p>
<pre class="prettyprint language-groovy">
 public class CalculatorTest {
     @Test public void addsTwoNumbers () {...}
     @Test public void subtractNumberFromAnother () {...}
     @Test public void multipliesTwoNumbers () {...}
     @Test public void dividesTwoNumbers () {...}
 }
</pre>
<p>Agiledox would produce documentation for the class that would look like this:</p>
<blockquote><p>Calculator</p>
<p>- adds two numbers</p>
<p>- subtracts number from another</p>
<p>- multiplies two numbers</p>
<p>- divides two numbers</p></blockquote>
<p><strong></strong>This was an aha moment for me.  While I have never used agiledox, I found this convention and approach to be extremely simple and easy.  The unit test names now provide a description of the behavior of the class under test.  When I write unit test methods, I imagine these agiledox style sentences being laid out, as a sanity check.</p>
<p><strong>Focus on Behavior</strong></p>
<p>For me, the best unit test name should be focused on a particular behavior of the class under test.  How you word the test name is up to you, so long as you focus on behavior.  You should make sure to include exception cases in this definition of the behavior as well.</p>
<p>Another nice side effect of this focus on behavior is it makes it easier to assess whether or not the class under test is violating the <a title="SRP Wikipedia page" href="http://en.wikipedia.org/wiki/Single_responsibility_principle" target="_blank">Single Responsibility Principle (SRP)</a>.  By quickly looking through the feature list, provided by unit test names, you can determine whether or not the class is doing too much and should be broken up into collaborating objects.</p>
<p><strong>Side Note: Method Names in Groovy</strong></p>
<p>Since Groovy allows method names to be strings, this allows you to write a unit test method that looks like this:</p>
<pre class="prettyprint language-groovy">
class CalculatorTest {
   @Test void &quot;adds two numbers&quot;() {...}
   @Test void &quot;subtracts a number from another&quot;() {...}
   @Test void &quot;multiplies two numbers&quot;() {...}
   @Test void &quot;divides two numbers&quot;() {...}
}
</pre>
<p>This allows you to write true sentences without the need for a tool like agiledox to break up the camel case. Another compelling reason to use Groovy for unit testing Java.</p>
</p>
  			<a href="/blog/grails-best-practice-resources.html"><h1>Grails Best Practice Resources</h1></a>
  			<p>11 October 2011</p>
  			<p><p>I have been spending some time learning <a href="http://groovy.codehaus.org/" target="_blank">Groovy</a> and <a href="http://grails.org/" target="_blank">Grails</a> recently.  As a Java developer, I find that they answer many of the problems that currently exist in the Java platform (and the .NET platform as well).  They provide an amazing, and Agile toolkit for developers to get started with.</p>
<p>I have also found some interesting resources on Grails best practices that I would like to share.</p>
<ul>
<li><a href="http://www.grailspodcast.com/blog/id/249" target="_blank">Grails Podcast - episode 127</a></li>
<li><a href="http://weblog.dangertree.net/2008/11/22/grails-package-naming/" target="_blank">Grails Package Naming (dangertree techblog)</a></li>
<li><a href="http://stackoverflow.com/questions/6226759/best-practices-to-be-followed-while-developing-grails-application" target="_blank">Grails Best Practice discussion on StackOverflow.com</a></li>
<li><a href="http://martinfowler.com/bliki/AnemicDomainModel.html" target="_blank">Martin Fowler on Anemic Domain Model</a> - not directly about Grails, but food for thought when talking about Domain object design</li>
</ul>
<div>As a Java developer, many of your instincts might be wrong, so it is definitely worth taking a look at these when starting with Grails.  I will likely post more as time goes on.  I hope that these resources were helpful.</div>
</p>
  			<a href="/blog/dvcs-ci.html"><h1>GitFlow and Continuous Integration</h1></a>
  			<p>14 September 2011</p>
  			<p><p>I came across an <a title="James Carr - My Current Java Workflow" href="http://blog.james-carr.org/2011/09/09/my-current-java-workflow/" target="_blank">interesting blog post</a> by James Carr discussing his workflow when building Java applications.  In general, I think that the stack and process he mentions is top notch.  I love <a title="Gradle" href="http://www.gradle.org/" target="_blank">Gradle</a>, <a title="Jenkins" href="http://jenkins-ci.org/" target="_blank">Jenkins</a>, <a title="Artifactory" href="http://www.jfrog.com/products.php" target="_blank">Artifactory</a> and <a title="Git" href="http://git-scm.com/" target="_blank">Git</a>/<a title="GitHub" href="https://github.com/" target="_blank">GitHub</a>.  I have been playing with or using in production all of these tools and they are amazing.  I especially like how the article provides a tutorial on how to setup your project to look just like his, something I will definitely try.</p>
<p>Where the article raised questions for me was when James started talking about <a title="GitFlow" href="https://github.com/nvie/gitflow" target="_blank">GitFlow</a> and Vincent Driessen's <a title="Vincent Driessen's Git Branching Model" href="http://nvie.com/posts/a-successful-git-branching-model/" target="_blank">Git Branching Model</a>.  If you haven't read this article, I recommend you stop and go read it now.</p>
<p>Vincent's approach to using Git takes full advantage of a major feature provided in DVCS, <a title="Why git is better than X - Cheap Local Branching" href="http://whygitisbetterthanx.com/#cheap-local-branching" target="_blank">cheap local branching</a>.  As an advocate of <a title="Continuous Integration" href="http://martinfowler.com/articles/continuousIntegration.html" target="_blank">continuous integration</a> however, I have always recommended that one should avoid the approach of excessive branching.  One of the principle practices of continuous integration is:</p>
<blockquote><p>Everyone commits to the mainline everyday</p></blockquote>
<p>Martin Fowler goes on to say,</p>
<blockquote><p>"In practice it's often useful if developers commit more frequently than that. The more frequently you commit, the less places you have to look for conflict errors, and the more rapidly you fix conflicts."</p></blockquote>
<p>So taking this a basic rule of thumb, does Vincent's branching model conflict with continuous integration?  The short answer is no, so long as the developers are only branching locally and are pushing their changes to <em>origin</em> (the centralized git repository) daily.</p>
<p>In Vincent's approach however, he says</p>
<blockquote><p>"But besides the centralized push-pull relationships, each developer may also pull changes from other peers to form sub teams. For example, this might be useful to work together with two or more developers on a big new feature, before pushing the work in progress to <code>origin</code> prematurely."</p></blockquote>
<p>This is an approach to feature branching Martin Fowler calls <a title="Martin Fowler on Feature Branching " href="http://martinfowler.com/bliki/FeatureBranch.html" target="_blank">Promiscuous Integration</a>.  Martin Fowler attempts to assess whether the concept of promiscuous integration is a good idea or not.  I recommend you read the article yourself, but he ends up saying he thinks it's not the best idea (but doesn't outright say don't do it).  He recommends using <a title="Feature Toggles" href="http://martinfowler.com/bliki/FeatureToggle.html" target="_blank">Feature Toggles</a> or <a title="Branch by Abstraction" href="http://martinfowler.com/bliki/BranchByAbstraction.html" target="_blank">Branch by Abstraction</a> as approaches to avoiding Feature Branches in long running development cycles.  This same advice is reinforced in the book <a title="Continuous Delivery" href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912" target="_blank">Continuous Delivery</a> by <a title="Jez Humble" href="http://jezhumble.net/" target="_blank">Jez Humble</a> and <a title="Dave Farley" href="http://www.davefarley.net" target="_blank">Dave Farley</a>.  I highly recommend this book!</p>
<p>So, what does one do with this information?  Is use of GitFlow or promiscuous integration a bad idea?  I think that it can work very well for some teams and could be very dangerous in others.  In general, I like it when the VCS stays out of the way and the team gets in the habit of pushing changes and looking to the CI server validation that everything is ok.  Introducing promiscuous integration could interrupt this cycle and allow code changes to circumvention the mainline longer than they should.  This branching scheme feels complex, even with the addition of GitFlow.</p>
<p>I plan on trying GitFlow and further investigating it's merits, hopefully writting a more in depth analysis of how it works.  I think that it is an interesting idea (worth blogging about) and has a lot of potential.  I would love to hear what you think about GitFlow, promiscuous integration, feature branching and how they are good or bad, so please comment below!</p>
</p>
  			<a href="/blog/ut-vs-it.html"><h1>Unit vs. Integration Tests</h1></a>
  			<p>24 June 2011</p>
  			<p><p>I have been doing more and more testing recently and I wanted to start capturing some of my thoughts on testing.  An important topic is the differences between a unit test and an integration test.  I feel like this is pretty straight forward, but is still worth clarifying, since I feel like it is done incorrectly way too often.  My definition of each breaks down as follows:</p>
<p><strong>Unit Tests:</strong></p>
<ul>
<li>Focused on defining (not testing) the behavior of a particular class, and that class only.</li>
<li>Fast (less than 0.1 second per test)</li>
<li>No external implementation dependencies (filesystem, database, web services, etc.).  All dependencies are faked for the test context.</li>
<li>Can easily be parallelized, since each test is atomic</li>
</ul>
<p><strong>Integration Tests:</strong></p>
<ul>
<li>Focused on verifying the integration of one or more components together.</li>
<li>May have external dependencies. (in fact, it is likely testing the integration with this dependency)</li>
<li>A test that takes longer than a unit Test should (longer than 0.1 seconds per test)</li>
</ul>
<p>Both unit and integration are focused on the internal quality of the application, whereas acceptance tests focus on the external, or business quality of the application.</p>
<p><strong>Code Coverage</strong><br />
I feel very strongly that developers should focus on achieving &gt;80%  code coverage by unit tests only.  Unit tests should target happy case logic as well as exception logic.  With integration tests, it is not necessarily to target a high code coverage.  Integration test coverage needs to cover integration points.  For instance, write integration tests to ensure your Hibernate database mappings are wired correctly.  Exceptions that could result from a integration failure should be defined behavior in the unit test, and expressed easily through fakes.</p>
<p><strong>Summary</strong></p>
<p>Your team should have a testing strategy that focuses on using both unit and integration tests, as both have a different focus and goal.  If you have additional criteria to add to this discussion, please feel free to share it.</p>
</p>
  			<a href="/blog/cd-at-mcjug.html"><h1>Continuous Delivery Presentation at the MC Java Users Group</h1></a>
  			<p>17 June 2011</p>
  			<p><p><a href="http://www.mcjug.org/"><img class="alignright" title="MCJUG Logo" src="http://www.mcjug.org/_/rsrc/1292297278055/home/mcjug_logo.png" alt="Mo" width="240" height="120" /></a>This past Wednesday night, I gave a presentation to the <a title="Montgomery County Java User's Group" href="http://www.mcjug.org/" target="_blank">Montgomery Country Java User's Group</a> on Continuous Delivery.  I was lucky enough to be given the opportunity to speak to a  smart and attentive audience, and I look forward to going back and giving another presentation in the future.  I want to thank <a title="Victor Semenov at Twitter" href="https://twitter.com/#!/victorsemenov" target="_blank">Victor Semenov</a>, who organizes the MCJUG, for setting this up.</p>
<p>The presentation serves as an introduction to the concept and practices of Continuous Delivery.  The presentation cover the concept and need for continuous delivery, and then talks about the core practices necesarry for continuous delivery, such as:</p>
<ul>
<li>Agile</li>
<li>Configuration Management</li>
<li>Continuous Integration</li>
<li>Testing</li>
<li>Build Pipelines</li>
</ul>
<p>I intended to cover both the core practices as well as tools, but I ran out of time.  In the future, I will likely break this presentation up into two halves that cover an introduction, and then a specific roadmap with tools and techniques.</p>
<p>I have included a link to the slide deck I used for the presentation.  Check it out and add comments.    I hope that you enjoy it!</p>
<iframe src="http://www.slideshare.net/slideshow/embed_code/8341276" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/jmcgarr/continuous-delivery-8341276" title="Continuous Delivery" target="_blank">Continuous Delivery</a> </strong> from <strong><a href="http://www.slideshare.net/jmcgarr" target="_blank">Mike McGarr</a></strong> </div>
</p>
  			<a href="/blog/java-ee-interview.html"><h1>Java EE Interview for the SD Times</h1></a>
  			<p>15 June 2011</p>
  			<p><p>Last Friday, an article on" <a title="SD TImes Article" href="http://www.sdtimes.com/content/article.aspx?ArticleID=35628&amp;page=1" target="_blank">Java EE:  The state of the environment</a>" was published by the <a title="SD Times" href="http://www.sdtimes.com/" target="_blank">SD Times</a>.  I was interviewed for this article and you can check my quotes in the article at the SD Times website.  Please note, that I was misquoted in the article.  Any reference to C++ should be a reference to C#.  Hope you enjoy it otherwise!</p>
<p>Article: <a href="http://www.sdtimes.com/content/article.aspx?ArticleID=35628&amp;page=1">http://www.sdtimes.com/content/article.aspx?ArticleID=35628&amp;page=1</a></p>
</p>
  			<a href="/blog/top-200-agile-hm.html"><h1>Honorable Mention in Top 200 Agile Blogs</h1></a>
  			<p>08 June 2011</p>
  			<p><p><a href="http://agilescout.com/top-agile-blogs-200/"><img class="alignright" title="Top 200 Agile Blogs" src="http://agilescout.com/wp-content/uploads/2011/06/agile-top-200-blogs.png" alt="" width="125" height="125" /></a>I am happy to announce that my blog just received an honorable mention in <a title="Agile Scout" href="http://agilescout.com/" target="_blank">Agile Scout'</a>s <a title="Top 200 Agile Blogs" href="http://agilescout.com/top-agile-blogs-200/" target="_blank">Top 200 Agile Blogs</a>.  I am humbled and inspired by this great honor, and it just means that I have to push harder and write more and more.  I would also like to congratulate my fellow Excellian Richard Cheng, who's blog, One More Agile Blog, has been ranked 162.  Nicely done Richard!</p>
<p>I hope to make the Top 200 next year!</p>
</p>
  			<a href="/blog/excella-craftsmanship.html"><h1>Dojos, Katas and Software Craftsmanship at Excella</h1></a>
  			<p>21 April 2011</p>
  			<p><p><img class="alignright" title="Clean Code Logo" src="http://butunclebob.com/files/images/clean_code_72_color.png" alt="Clean Code" width="200" height="200" />The <a title="Manifest for Software Craftsmanship" href="http://manifesto.softwarecraftsmanship.org/" target="_blank">Software Craftsmanship movement</a> is creating quite a <a title="Software Craftsmanship criticisms" href="http://www.infoq.com/news/2011/02/north-craftsmanship-manifesto" target="_blank">stir</a> in the software development community, with experts on both sides of the fence arguing its value.   At <a title="Excella Consulting" href="http://www.excella.com/" target="_blank">Excella Consulting</a>, we have embraced the Software Craftsmanship movement and feel that the benefits of writing <a title="Clean Code, the book" href="http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882" target="_blank">clean code</a> does not conflict with the needs of our customers.  Our desire to continuously learn and improve how we write code has led us to gather regularly for <a title="What is a Code Dojo?" href="http://codingdojo.org/" target="_blank">Coding Dojos</a>.</p>
<p>A coding dojo is a gathering of developers to work together to learn how best to solve a problem.  The purpose of a dojo is not to produce a product, rather to learn how to write code better.  A coding dojo can take on numerous formats but at Excella we have decided to focus on conducting <a title="Code Kata" href="http://codekata.pragprog.com/2007/01/code_kata_backg.html#more" target="_blank">code katas</a>.  Code katas are predefined exercises or problems that the dojo members attempt to solve.  Katas are written to be domain problems that are simple and should be familiar to the developers, like <a title="Uncle Bob at Twitter.com" href="https://twitter.com/#!/unclebobmartin" target="_blank">Uncle Bob</a>'s <a title="Bowling Game Kata" href="http://butunclebob.com/ArticleS.UncleBob.TheBowlingGameKata" target="_blank">Bowling Game</a>.  Katas are intended to be repeated over and over again.  The code resulting from the kata is disposable, as the process of solving the problem is considered more significant.</p>
<p>Both the concepts of dojos and katas are derived from the world of martial arts.  Martial artists attend dojos to learn from masters.  Katas are the repetitive movements that martial artists conduct to build muscle memory.  By applying the concept of mentorship and practice, we have found that this provides the most effective means of sharing best practices.</p>
<p><a href="http://www.excella.com/"><img class="alignleft" title="Excella Logo" src="http://dl.dropbox.com/u/3118373/blog-images/excella_logo.gif" alt="Excella Consulting" width="200" height="115" /></a>At Excella, our katas focus on <a title="Test Driven Development" href="http://c2.com/cgi/wiki?TestDrivenDevelopment" target="_blank">test driven development (TDD)</a> and <a title="Paired Programming" href="http://www.extremeprogramming.org/rules/pair.html" target="_blank">paired programming</a>.  At the beginning of a dojo, a kata is introduced and everybody breaks up into pairs.  Each pair uses a single computer.  The first developer in the pair writes a simple failing test and then passes the computer to the second developer.  The second developer writes just enough code to pass the test.  Once the test passes, the second developer writes a failing test and then passes the computer back to the first developer.  This back and forth approach to paired programming is known as <a title="Paired Programming Ping Pong" href="http://www.c2.com/cgi/wiki?PairProgrammingPingPongPattern" target="_blank">ping pong</a>.</p>
<p>It is also worth noting that since Excella is composed of both <a title="Java at Oracle" href="http://download.oracle.com/javase/6/docs/technotes/guides/language/" target="_blank">Java</a> and <a title="Microsoft .NET" href="http://www.microsoft.com/net/" target="_blank">.NET</a> developers, we tend to pair up accordingly.  There is, however, an interesting opportunity to learn a new programming language by pairing with somebody who knows it.  Just this week, I paired up with <a title="Roberto Hernandez" href="http://blog.overridethis.com/blog/" target="_blank">Roberto Hernandez</a>, a senior .NET developer, <a title="Excella's CoE Xperts" href="http://www.excella.com/Services/coe.htm" target="_blank">Excella Xpert</a> and a <a title="Microsoft MVP" href="http://mvp.support.microsoft.com/" target="_blank">Microsoft MVP</a>.  It was a great experience and as a Java developer <a title="C#" href="http://en.wikipedia.org/wiki/C_Sharp_%28programming_language%29" target="_blank">C#</a> extremely similar (don't worry, I am still a Java guy).  In future katas, I plan on trying other languages such as <a title="The Groovy Programming Language" href="http://groovy.codehaus.org/" target="_blank">Groovy</a> or <a title="The Scala Programming Language" href="http://www.scala-lang.org/" target="_blank">Scala</a>.</p>
<p>For now, we hold dojos twice a month.  I have been impressed with the voluntary turnout and the enthusiasm, evidence that Excellians enjoy what they do and want to get better at it.  I am happy to know that regardless of the communities debate on Software Craftsmanship, we at Excella belief in it's benefits and actively practice it.  I am sure future posts will touch on other topics in this arena, so stay tuned.</p>
</p>
  			<a href="/blog/alm.html"><h1>Thoughts on Application Lifecycle Management (ALM)</h1></a>
  			<p>04 March 2011</p>
  			<p><p>Last week, I was asked to give my opinion on Application Lifecycle Management or ALM.  Specifically, I was asked how can teams effectively manage their design, development, test and deploy processes as well as pick the right tools for the job.  Here is the answer I gave:</p>
<div>
<blockquote><p><span style="font-family:tahoma;">The cornerstone of a strong ALM<a></a> process is based in <a title="The Agile Manifesto" href="http://agilemanifesto.org/" target="_blank">Agile</a> practices  and <a title="Agile Principles" href="http://agilemanifesto.org/principles.html" target="_blank">principles</a>.  Iterative software development is useful for breaking work up  into small chunks that provides fast and frequent feedback to both the team and  the customer.  Developing software using <a title="Test Driven Development" href="http://www.agiledata.org/essays/tdd.html" target="_blank">test driven development</a> (with an  emphasis on <a title="Behavior Driven Development" href="http://dannorth.net/introducing-bdd/" target="_blank">behavior driven development</a>) allows developers to focus on behavior  first as well as quality.  Developers will iteratively <a title="Evolutionary Design" href="http://martinfowler.com/articles/designDead.html" target="_blank">evolve the design</a> of the  software based on the tests, and will limit the amount of up front design.   Automated tests are executed as part of an automated build process that is in  turn executed by a <a title="Continuous Integration" href="http://martinfowler.com/articles/continuousIntegration.html" target="_blank">continuous integration</a> server monitoring version control.   Developers should be checking in their changes frequently, triggering multiple  builds, resulting in multiple feedback cycles.  All development should take  place on the trunk in version control and branching should be  limited.</span></p><br/>
<p><span style="font-family:tahoma;">Taking ALM<a></a> a step further lies the <a title="Continuous Delivery" href="http://continuousdelivery.com/2010/02/continuous-delivery/" target="_blank">continuous delivery</a> practice of  <a title="Deployment Pipelines" href="http://www.scribd.com/doc/196739/The-Deployment-Pipeline-by-Dave-Farley-2007" target="_blank">deployment pipelines</a>.  Like with standard continuous integration, each change to  source triggers a new build on the CI server.  With deployment pipelines, you  are chaining together a series of builds, each responsible for validating a  certain condition or set of conditions (like acceptance tests or coding style).   Each build should expand on the previous with an increasingly rigorous  criteria<a></a>.  The goal of deployment pipelines is validate a change to  source to see if it is production worthy, i.e.<a></a> a release candidate.  In  some environments, deployment pipelines are <a title="Continuous Deployment" href="http://timothyfitz.wordpress.com/2009/02/08/continuous-deployment/" target="_blank">automated all the way to production</a>,  where a change from a developer can go to production without a single person  touching it.  To achieve this, automation and feedback are essential.  Unit,  Integration, Acceptance and Performance Tests must all be phases of the  deployment pipelines with rigorous criteria to keep a build out of production  that doesn't meet the standard.  Managing code is also an essential part of the pipeline, which is achieved using static code analysis tools.  In addition, automating the deployment of the  application from source to the Dev, Test, Staging and Production is also an  essential practice.</span></p><br/>
<p><span style="font-family:tahoma;">In regards to tools to enable this process, it is hard to  come up with a list without assuming certain technologies and biases for/against  open source.  For the sake of this discussion, I will assume a Java application  where open source is king.  For version control, Subversion gets the job done,  but distributed version control systems (git<a></a> and mercurial) are extremely popular and gaining  ground.  For Agile project management, unless you are on a distributed team, I  recommend sticking with cards and a scrumboard<a></a> and avoid complex tools.  For testing, there are  a multitude<a></a> of tools available, <a title="JUnit" href="http://www.junit.org/" target="_blank">JUnit</a><a></a> being the core of the testing world.  <a title="Mockito" href="http://mockito.org/" target="_blank">Mockito</a><a></a> is an excellent and  simple mocking framework, but <a title="JMock" href="http://www.jmock.org/" target="_blank">JMock</a><a></a> provides some valuable features not found in Mockito<a></a>.  <a title="Selenium" href="http://seleniumhq.org/" target="_blank">Selenium</a> is a  great web application testing tool (but avoid <a title="Selenium IDE" href="http://seleniumhq.org/projects/ide/" target="_blank">recording</a> and use <a title="Page Objects Pattern" href="http://code.google.com/p/selenium/wiki/PageObjects" target="_blank">page objects</a>),  especially when coupled with a BDD<a></a> framework like <a title="easyb" href="http://www.easyb.org/" target="_blank">easyb</a><a></a> or <a title="JBehave" href="http://jbehave.org/" target="_blank">JBehave</a><a></a>.  <a title="JMeter" href="http://jakarta.apache.org/jmeter/" target="_blank">JMeter</a><a></a> is a great tool for performance testing.  For build  tools, I feel that <a title="Gradle" href="http://www.gradle.org/" target="_blank">Gradle</a><a></a> or <a title="Buildr" href="http://buildr.apache.org/" target="_blank">Buildr</a><a></a> are better than <a title="Maven" href="http://maven.apache.org/" target="_blank">Maven</a>, which is better than <a title="Ant" href="http://ant.apache.org/" target="_blank">Ant</a>.   Gradle<a></a>/Buildr<a></a> build on the legacy  of Maven and Ant and improve on them in different ways.  For continuous  integration, I highly recommend using <a title="Hudson" href="http://java.net/projects/hudson/" target="_blank">Hudson</a>/<a title="Jenkins" href="http://jenkins-ci.org/" target="_blank">Jenkins</a> for most environments, but  it lacks some of the advanced deployment pipeline features you can find in <a title="ThoughtWorks" href="http://www.thoughtworks.com/" target="_blank">ThoughtWorks</a><a></a> <a title="Go" href="http://www.thoughtworks-studios.com/go-agile-release-management/" target="_blank">Go</a> product  (not <a title="FOSS" href="http://en.wikipedia.org/wiki/Free_and_open_source_software" target="_blank">FOSS</a>).  For measuring code quality, I recommend <a title="Checkstyle" href="http://checkstyle.sourceforge.net/" target="_blank">Checkstyle</a>, <a title="PMD/CPD" href="http://pmd.sourceforge.net/">PMD/CPD</a>, <a title="Findbugs" href="http://findbugs.sourceforge.net/" target="_blank">Findbugs</a>, <a title="Crap4j" href="http://www.crap4j.org/" target="_blank">Crap4j</a> and <a title="Cobertura" href="http://cobertura.sourceforge.net/" target="_blank">Cobertura</a> for measuring code coverage.  I also highly recommend Liquibase<a></a> for database management and a tool like <a title="Puppet" href="http://www.puppetlabs.com/puppet/puppet-platform/" target="_blank">Puppet</a> or  <a title="Chef" href="http://www.opscode.com/chef/" target="_blank">Chef</a> to manage your infrastructure.  In addition, I also recommend using <a title="Nexus" href="http://nexus.sonatype.org/" target="_blank">Nexus</a> as a binary repository for build artifacts produced in the  pipeline.</span></p></blockquote>
</div>
<p>My thoughts were somewhat off the cuff and could likely be more comprehensive given time, but I still found them valuable.  I would to hear what you think of this answer and if you have differing opinions.  Enjoy!</p>
</p>
  			<a href="/blog/ebooks.html"><h1>Why I Love eBooks</h1></a>
  			<p>24 February 2011</p>
  			<p><p><a href="http://earlyandoften.files.wordpress.com/2011/02/kindleapp.jpg"><img class="alignright size-full wp-image-712" title="kindleapp" src="http://earlyandoften.files.wordpress.com/2011/02/kindleapp.jpg" alt="Amazon Kindle App" width="175" height="175" /></a>I've recently fallen in love with reading books on my <a title="Apple iPad" href="http://www.apple.com/ipad/" target="_blank">iPad</a>.  When I first bought my iPad, I was nervous about reading a book on it since in general I hate reading on a computer screen.  Plus, my friends rave about the <a title="Amazon Kindle" href="http://www.amazon.com/Kindle-Wireless-Reader-3G-Wifi-Graphite/dp/B002FQJT3Q/ref=amb_link_354886182_2" target="_blank">Amazon Kindle</a> and the great reading experience it offers.  Eventually, I decided to take the plunge and ordered an eBook for the <a title="Amazon Kindle iPad app" href="http://www.amazon.com/gp/feature.html/ref=kcp_ipad_mkt_lnd?docId=1000490441" target="_blank">Amazon Kindle iPad app</a>.  After reading a few chapters, I found myself falling completely in love with reading books this way.  Of course, there are disadvantages as well as advantages of this relatively new medium.</p>
<p><strong>Advantage #1: Cloud Persistence</strong></p>
<p>The fact that your book lives on the cloud is the biggest advantage.  I love that I can start reading my book on my iPad, continue reading it on my iPhone and then continue reading on my PC or Mac.  Amazon's Kindle app has multiple clients and it allows you to access your book from all of these locations.  The clients all sync the last read location to the cloud, so you can pick up exactly where you left off.</p>
<p><strong>Advantage #2: Burn-Proof</strong></p>
<p>Since books are stored in cloud, my eBook is essentially burn proof.  If my house burns down and I lose all my books, I don't lose any of my eBooks.  They are all stored online in Amazon's cloud.  Now, this isn't a fool proof system, but I will touch on this later when I refer to questions of ownership.</p>
<p><strong>Advantage #3: Note Taking</strong></p>
<p>I read a fair amount of technical books and I highlight text or take notes on sections that I really like.  When the book is done, I often want to convert those notes and highlights into a single resource.  With a physical book, I have to flip through every page of the book to find the highlighted text and/or notes and then write them down.</p>
<p>With an eBook, you highlight text using the eReader your notes from each passage are indexed  for easy access later.  I can even take notes on passages in the book which are also indexed.  I don't need to switch context by picking up a highlighter or pen as I would need to with a real book.  I can read something, reflect on its significance and then "touch" the words I like to highlight them.</p>
<p>Additionally, since my eBook is cloud persistent, I can access all my highlights and notes are available from other computers.  I can access them from another Kindle app or log into <a title="Kindle at Amazon.com" href="https://kindle.amazon.com" target="_blank">kindle.amazon.com</a>.  This is a powerful tool and it should not be underestimated, especially if you are a studious software developer.</p>
<p><strong><a href="http://earlyandoften.files.wordpress.com/2011/02/ipad.jpg"><img class="alignleft size-full wp-image-710" title="ipad" src="http://earlyandoften.files.wordpress.com/2011/02/ipad.jpg" alt="" width="252" height="252" /></a>Advantage #4: Books as Hypermedia</strong></p>
<p>The Internet is composed of hypermedia, which is defined as documents on the web that link to other documents, audio, video, images through hyperlinks.  Web browsers are our conduits to hypermedia, allowing us to jump back and forth between documents via their hyperlinks.  These documents and their hyperlinks intertwine to form the World Wide Web.</p>
<p>Physical books aspire to be like hypermedia, as evident by footnotes, endnotes and references to other books.  You can "browse" back and forth between the bibliography and the page you are reading, but in general, this becomes an interruption in flow.  With an eBook, the ability to "browse" is analogous to using a web browser that allows you to jump back and forth between a page you are reading and another linked section of the book.  I was quite surprised to find that my eBook felt more like a web page than a book, which made my experience of jumping around more enjoyable.</p>
<p><strong>Advantage #5: Inline Definitions</strong></p>
<p>Another simple advantage of eBooks that caught me by surprise was inline definitions.  If you come across a word that you don't know, all you have to do is highlight the word and the definition pops up.  Once again, having access to this feature without switching contexts by opening up a dictionary and looking up the word is huge advantage over physical books.</p>
<p><strong>Advantage #6: Recommended Passages</strong></p>
<p>The Amazon Kindle app also provides something I didn't see coming:  recommended passages.  When I bought my book, I noticed that certain passages were already highlighted.  These passages were not recommended by Amazon employees themselves, rather by other Kindle readers who had also highlighted that text.  I can even see how many people highlighted a particular recommended passage, which in a way can be seen as an indicator of its significance.</p>
<p><strong>Advantage #7: Travel Light</strong></p>
<p>Another great advantage of e-books is I can carry my whole library with me whenever I go.  Books can all be downloaded and stored on my iPad without taking up space in my suitcase.  While I am focusing on the advantages for my next beach trip, I am sure students also love this advantage.  No more bulky textbooks?</p>
<p><strong>Disadvantage #1: Tactile Loss</strong></p>
<p>Of course, one of the disadvantages of using an eBook is the loss of a physical book.  This is an obstacle that will keep many book stalwarts from adopting an eReader.  While I do love reading on my iPad, I do miss the feeling of pages in my hand.  I miss being able to look quickly at how many pages I had left based on the location of the bookmark.  This is just something you have to get over if you want to take advantage of eBooks.</p>
<p><strong>Disadvantage #2: Battery Operated</strong></p>
<p>I am writing this article right now and not reading my book because my iPad ran out of batteries and needs to charge.  I could have picked up right where I left off with my Mac or my iPhone, but the experience of reading from these devices isn't the same.  The iPad's screen is just the right size for reading a book.  The iPad itself is about the size of a large book, although much heavier.  It's portability makes it better than a laptop, and it's size makes it better than an iPhone for reading books.</p>
<p><strong>Disadvantage #3: Not Always Accessible</strong></p>
<p>Even though I can access my eBook from multiple devices all with varying degrees of portability, there are some locations that you will never be allowed to use an electronic device.  If you are a frequent traveller, then the 30 minutes or so at take off and landing are perfect examples where you can't read your eBook on any device.  If you work in a secure environment where portable electronics are prohibited, you may not have access to your eBook.</p>
<p><strong>Disadvantage #4: No More Page Numbers</strong></p>
<p>This is another disadvantage of eBooks.  If I wanted to refer somebody else to my favorite passage, I could not point them to a page number since Kindle and the rest of the eReaders don't use page numbers.  The Kindle uses Locations to point to specific points in the book, which don’t map to page numbers, but likely maps to paragraphs.  If you are joining a book club, you may want to figure out how to map to pages first.</p>
<p><strong>Disadvantage #5: Questions of ownership</strong></p>
<p>If Amazon goes out of business or if they change their terms of use, I may find myself with limited access to books that I thought I owned.  This is why I would prefer to buy an eBook and download the raw file, upload that file to an eReader, and then store that file in my own backup location.  This allows me to manage my own collection of eBooks without having to rely on the upon an Internet giant. (I can't imagine Amazon imploding, but hey you never know.)</p>
<p><strong>Conclusion</strong></p>
<p>If you are hesitant to try eBooks, I highly recommend you give it a shot and download one.  If you are a developer like myself who reads a lot of technical books, then I think it is a must that you get an eBook reader.  I personally prefer the Amazon Kindle app over Apple's iBook, but that is a matter of preference.  Both have similar features, and if you are using an iPad, you can switch between them.</p>
</p>
  			<a href="/blog/disable-maven-profile.html"><h1>Maven Tip: Disabling Profiles when a Property Does Not Exist</h1></a>
  			<p>09 February 2011</p>
  			<p><p>I wanted to share a method for enabling a <a title="Maven" href="http://maven.apache.org/" target="_blank">Maven</a> <a title="Maven Profiles" href="http://maven.apache.org/guides/introduction/introduction-to-profiles.html" target="_blank">Build Profile</a> in the absense of a system property.  I did not see this approach documented in the current version of the Maven Build Profile documentation, so I thought I would share it.</p>
<p>I find this approach particularly useful for turning off build features whenever you are disabling tests.  In Maven, there are two properties that will <a title="Skipping tests" href="http://maven.apache.org/plugins/maven-surefire-plugin/examples/skipping-test.html" target="_blank">skip the execution of all tests</a>, but I prefer the "skipTests" property.</p>
<p>As an example, let's take a Maven <a title="Maven Project Object Model" href="http://maven.apache.org/pom.html#What_is_the_POM" target="_blank">POM</a> file that runs <a title="Managing Database Changes with Liquibase" href="http://earlyandoften.wordpress.com/2010/06/28/intro-to-liquibase/" target="_blank">Liquibase </a>to update the database.   If you want to run a Maven install without executing the tests, then you would run the following command (Note: I am not advocating that tests be skipped, but I think this is a useful example):</p>
<pre>
mvn clean install -DskipTests
</pre>
<p>If I wanted to also disable Liquibase whenever the tests were skipped, I would configure Liquibase is a profile.  This profile would be triggered in absence of the  the "skipTests" property.  This means that when the property is not declared, Liquibase will run.  Here is how you would declare this profile:</p>
<pre class="prettyprint language-xml">
&lt;profiles&gt;
   &lt;profile&gt;
      &lt;id&gt;update-database&lt;/id&gt;
      &lt;activation&gt;
         &lt;property&gt;
            &lt;name&gt;!skipTests&lt;/name&gt;
         &lt;/property&gt;
      &lt;/activation&gt;
      ...
      &lt;!-- Liquibase Plugin Configuration Here --&gt;
      ...
   &lt;/profile&gt;
&lt;/profiles&gt;
</pre>
<p>An alternative to this approach is to turn off the profile explicitly:</p>
<pre>
mvn clean install -DskipTests -P !update-database
</pre>
<p>Using this approach does make it clear what you are trying to do, which is also an advantage.  There is an advantage in turning features on and off based on a related trigger, like a single system property.</p>
<p>In regards to the <a title="Liquibase Maven Plugin" href="http://www.liquibase.org/manual/maven" target="_blank">Liquibase Maven plugin</a>, a feature was added to <a title="Skip Liquibase Feature" href="http://liquibase.jira.com/browse/CORE-495" target="_blank">allow property based skipping</a>.  This is only available as of <a title="Liquibase 2.0 Released" href="http://blog.liquibase.org/2011/01/liquibase-2-0-officially-released.html" target="_blank">Liquibase 2.0</a>.</p>
</p>
  			<a href="/blog/java-live.html"><h1>Article Published in Linux Insider...Java Lives</h1></a>
  			<p>28 December 2010</p>
  			<p><p>I was lucky enough to have an article published in Linux Insider today on the future of Java.  I do have to say that writing an article for a publication is not as easy as writing a blog post.  I would love to tell you what it is all about, but I would rather you go and check it out for yourself!</p>
<p><a href="http://www.linuxinsider.com/story/71532.html">http://www.linuxinsider.com/story/71532.html</a></p>
</p>
  			<a href="/blog/scrum-walls.html"><h1>Scrum Boards: Physical or Virtual</h1></a>
  			<p>07 December 2010</p>
  			<p><div>
<p>I'm lucky enough to have spent the last two years immersed in a culture that strongly endorses <a title="Manifesto for Agile Software Development" href="http://agilemanifesto.org/" target="_blank">Agile Software Development</a>.  Not only does my employer, <a title="Excella Consulting" href="http://www.excella.com/" target="_blank">Excella Consulting</a>, strongly believe in Agile, we also have a number of strong Agile experts who are significant contributors to both the local and national Agile community.  Most project teams at Excella implement some variation of Agile and the project I currently work on is no exception.</p>
<p>When our project started, there was some debate as to whether we should use a traditional physical Scrum Board or utilize a web based virtual solution.  Our team's <a title="ScrumMaster" href="http://www.mountaingoatsoftware.com/scrum/scrummaster" target="_blank">ScrumMaster</a>, <a title="One More Agile Blog" href="http://www.onemoreagileblog.com/" target="_blank">Richard Cheng</a>, advocated using a traditional Scrum Board comprised of index cards for each user story or task posted on the board.  The user stories and tasks would initially be captured and maintained in an Excel spreadsheet, then exported into a printable card format and posted to the Scrum Board.  The spreadsheet would then be stored in version control for posterity.  Whenever the team wanted to know what to work on next and determine the progress made over a sprint, then they would have to reference the Scrum Board.</p>
<p><img class="  " title="Scrum Board" src="http://farm6.static.flickr.com/5170/5231854212_7b304d02b8.jpg" alt="" width="500" height="374" /></p>
<p>Concurrently, we were using <a title="Atlassian's JIRA" href="http://www.atlassian.com/software/jira/" target="_blank">JIRA</a> for defect tracking and I recommended that we store all of our user stories and tasks in JIRA.  I advocated that this would provide a number of advantages over the physical Scrum Board, including remote accessibility, search and eliminating the need for printing the cards from Excel.  The team agreed and I got to work adding custom workflows, fields and plugins to JIRA to support our Scrum process.  After some work, our team was set up to use JIRA as our Agile Project Management tool, and without any incarnation of Scrum Board.</p>
<p><strong>Problems Arise</strong></p>
<p>One of the first problems we had was when we conducted <a title="Daily Stand-up Meetings" href="http://en.wikipedia.org/wiki/Scrum_(development)#Meetings" target="_blank">daily stand-up meetings</a>.  For those who don't know, in <a title="Scrum" href="http://en.wikipedia.org/wiki/Scrum_(development)" target="_blank">Scrum</a>, the team meets daily for 15 minutes to talk about what they worked on yesterday, what they are working on today and if they have any impediments.  During this meeting, the team stands in front of the Scrum Board talking to the cards and moving them through each of the status columns (open, in progress, ready for review and done).  Since our team was using JIRA without any Scrum Board, our stand-ups lacked a central focal point.  Team members had trouble remembering the work that was still open since it was back at their desks in JIRA.  We considered projecting JIRA during stand-ups, but we were limited in space and resources, so we decided against that solution.</p>
<p>The second problem we encountered was our inability to evaluate our progress mid-sprint.  When using a Scrum Board, all the work that needs to get done for a sprint is right in front of you.  Work on the left of the board in the "open" column hasn't been started and work on the far right is complete.  Additionally, if you use colors to denote priority of tasks, it makes it very easy to ensure your team is focusing on the high priority items first.  A physical Scrum Board is a simple data visualization tool that makes it easy to gauge progress.  Since we had eliminated the use of a Scrum Board, we had trouble getting JIRA to show us this same information on a single screen.  While there were plugins for JIRA that allowed us to use similar features, we found that most out of box features lacked the same impact.  The result of this problem was we began to find ourselves woefully behind schedule with only 2 days left in the sprint on a regular basis.</p>
<p><strong>Best of Both Worlds</strong></p>
<p>In an attempt to address these issues, we developed a hybrid approach.  Our team conducted all sprint planning and closeout meetings in a conference room, where JIRA was projected and updated in real time based on conversations in the room.  Once a planning meeting was complete and the stories for a sprint were set, the ScrumMaster would then use JIRA's built in export to Excel feature to create an Excel spreadsheet of the work for the upcoming sprint.  Then, a Microsoft Word Mail Merge template was used to read the data from the spreadsheet and to create a card for each User Story, Task, Spike, etc.  The stories were then printed out on colored paper, which we used to quickly denote priority (red for high priority, yellow for medium, green for low priority and blue for stretch tasks).  Once printed, the ScrumMaster would then cut the cards out and post them to the Scrum Wall.  It may seem like a lot of work to duplicate JIRA data on a physical board, but it only took one person less than an hour per sprint, an acceptance burden.</p>
<p>By using this hybrid approach, we were able to solve both our problems.  The team now had a physical Scrum Board which they could interact with on a daily basis during meetings, which also reflected the work assigned to the sprint in JIRA.  We also were able to access progress being made on a sprint in real time quickly by inspecting the physical Scrum Board.  Team members still had their personal task lists in JIRA, and we could still (and do) search through old stories from previous sprints to find out what happened in the past.  Using JIRA to record our project's complete history is extremely powerful, but having a physical Scrum Board makes managing work during a sprint critical.  By marrying these two solutions, we were able to achieve the best of both worlds.</p>
</div>
</p>
  			<a href="/blog/ci-interview.html"><h1>Continuous Integration Interview with SD Times</h1></a>
  			<p>03 November 2010</p>
  			<p><p>I was recently interviewed for the SD Times for an article on <a href="http://martinfowler.com/articles/continuousIntegration.html" target="_blank">Continuous Integration</a>.    The focus of the article is on using Continuous Integration on non-Agile projects.  It is a very good article and my name is mentioned on page 33.  I hope that you enjoy!</p>
<p><a href="http://www.sdtimes.com/content/SDTimesPDFEdition.aspx?File=sdtimes256.pdf">http://www.sdtimes.com/content/SDTimesPDFEdition.aspx?File=sdtimes256.pdf</a></p>
</p>
  			<a href="/blog/shortcuts-to-productivity.html"><h1>Shortcuts to Productivity</h1></a>
  			<p>02 November 2010</p>
  			<p><p>Earlier this year, I read <a href="http://www.nealford.com/" target="_blank">Neal Ford</a>'s book, <a href="http://oreilly.com/catalog/9780596519544" target="_blank">The Productive Programmer</a>.  It is a great book and a short read as well, so I highly recommend it.  In this book, Ford talks about ways to make yourself more productive and the book contains a wealth of useful tips.  This inspirational text got me thinking how I could increase my own productivity.  As a result, I made a few changes; one that has been extremely helpful is expanding my use of keyboard shortcuts, also known as hotkeys.</p>
<p>For my non-technical friends, hotkeys are key strokes that you can use to execute functions you might otherwise use a mouse to access through a menu.  Most computer savvy people are already familiar with some hotkeys, like <strong><em>Ctrl-C</em></strong> to copy and <strong><em>Ctrl-V</em></strong> to paste.  If you're a UNIX guy, then you have likely mastered the art of the keyboard already and may think that I am stating the obvious.</p>
<p>The reason hotkeys are useful is that keyboards tend to be more expressive than a mouse in the variety of functions you can express.  Additionally, if you are writing a document or coding, your hands are already on the keyboard.  It slows you down to move your hand from the keyboard, find the mouse, move the cursor to the correct location, click on sub menus until you find your command and then click the command.  If you know the shortcut for that command, you can just press it and you are done.  It is one of those things that once you start learning them, you will find that you are much more efficient than you were before.</p>
<p>As I embarked on my journey to find shortcuts for all my favorite tools, I was amazed by how many web applications had keyboard shortcuts.  For instance, if you are reading this blog using <a href="http://www.google.com/reader" target="_blank">Google Reader</a> through an RSS feed, type the letter '<strong><em>S</em></strong>', and you will notice that my blog entry is <strong><em>starred</em></strong>.  If you type '<strong><em>M</em></strong>', you can mark an entry as viewed, and if you type '<strong><em>V</em></strong>', the browser will open up a new tab or window to my blog entry.  Typing '<strong><em>J</em></strong>' or '<strong><em>K</em></strong>' will take you to the next or previous blog entry, respectively.  Once you know the basics of navigating, you can fly through your RSS feeds!</p>
<p>I have compiled <a href="http://www.delicious.com/porterhouse91/hotkeys" target="_blank">a list of hotkey reference sites</a> for commonly used software such as Windows, Mac OS X, Microsoft Office, Google Reader, GMail, Eclipse and many more.  I am using <span style="color:#000000;"><a href="http://www.delicious.com/" target="_blank">Delicious</a></span> to keep a running list so I can add to it over time, so check in with me periodically.  I recommend trying to tackle only set of hotkeys at a time.  Print out the keys and put them next to your computer.  Once you have tried out a few of them, try going completely mouse-free. See if you can author a document or write some code in <a href="http://www.eclipse.org/" target="_blank">Eclipse</a> without touching the mouse.  Every time you need to do something, and don't know how...look it up!  It will be slow going at first, but once you get the hang of it, you will be impressed with how much faster you can work.  If you have any other useful keyboard shortcuts/hotkeys, please comment below.  Enjoy!</p>
</p>
  			<a href="/blog/build-once-deploy-many.html"><h1>Build Once, Deploy Many</h1></a>
  			<p>09 September 2010</p>
  			<p><p>It is not uncommon to find a development team building their application binary from source every time they deploy a new version of their application to an environment.  While this approach works (and depending on the technology, may be necessary), it introduces significant opportunities for errors and makes debugging a failed deployment increasingly difficult.  By migrating to a <strong><em>Build Once, Deploy Many</em></strong> approach, your team can simplify their deployment process, by making it repeatable and easier to debug.</p>
<p style="text-align:center;"><img class="aligncenter" title="Build Once Deploy Many" src="https://docs.google.com/drawings/pub?id=1DWlh5PbduUlPMwlWVYxLH3YQbUtPbntXeNpfMO2MqZ4&amp;w=791&amp;h=383" alt="" width="487" height="235" /></p>
<p>In my experience, if you are rebuilding the application from source every time you deploy, it makes it harder to isolate deployment issues.  Specifically, it is hard to tell if the problem is the result of  a build time issue (the developer's responsibility), or a runtime environment issue (the sysadmin's responsibility).   So, when a deployment does fail, the inevitable battle between developers and sysadmins ensues, with fingers pointing at each other and denial emails flying.  Hopefully you work in a collaborative environment where there isn't contention between developers and sysadmins, but I still argue, there is a better way.</p>
<p><strong>What does "Build Once, Deploy Many" Mean?</strong></p>
<p>Rather than compiling and rebuilding your application for every environment you plan to deploy to, build your application binary only once, and then migrate the same binary file from Development to Test and then to Production.  By building once and deploying that binary many times, you have eliminated half of the aforementioned deploy time variables that could lead to errors.  For example, if your binary file worked fine in the development environment, but failed to run in the test environment, it quickly becomes clear that there is a delta between these two environments.</p>
<p><strong>Official Builds</strong></p>
<p>In order to adopt this approach, you will need to make sure that your build process is highly automated and repeatable, allowing you to produce an <em><span style="text-decoration:underline;">official build</span></em>.  In order to produce official builds, you need to be drawing your source code from a version control system like <a href="http://subversion.tigris.org/" target="_blank">Subversion</a>, running an automated build with tools like <a href="http://ant.apache.org/" target="_blank">Ant</a> or <a href="http://maven.apache.org/" target="_blank">Maven</a>, and lastly you need a dedicated build machine, preferably a <a href="http://martinfowler.com/articles/continuousIntegration.html" target="_blank">continuous integration</a> server.</p>
<p>Most teams already use version control and build automation, so I won't belabor their tenets.  By adding a dedicated build machine to the mix, you are increasing consistency at build time and eliminating variables when producing an official build.  I would avoid using a developer's machine as the dedicated build machine, as this likely an unstable environment with limited accessibility.  The dedicated build machine should be available to all team members.  Continuous integration servers, like <a href="http://hudson-ci.org/" target="_blank">Hudson</a>, provide a simple solution to this requirement and add much more value to your development process...for free!</p>
<p><strong>Binary Repositories</strong></p>
<p>Once the binary is produced, it should archived for future retrieval in a binary repository.  In Java, this is greatly simplified with tools like Maven and Ant+<a href="http://ant.apache.org/ivy/" target="_blank">Ivy</a> which provide simple mechanisms for archiving binaries at build time.  The Maven project has defined a <a href="http://www.sonatype.com/books/mvnex-book/reference/simple-project-section-simple-repo.html" target="_blank">standard structure</a> for a Java binary files repository, which can be accessed in Ant through Ivy.  These repositories are simple to setup, since they are built on a file system, so the only question is how you provide access to these repositories.  You could setup an Apache HTTP server to provide access, but I have found that Maven <a href="http://maven.apache.org/repository-management.html" target="_blank">repository managers</a>, like <a href="http://nexus.sonatype.org/" target="_blank">Nexus</a>, provide search repository caching that also adds value to an organization.</p>
<p><strong>Environment Agnostic</strong></p>
<p><strong> </strong>One of the major problems that most people have with this approach is Environment Variables.  One of the reasons teams build a new binary per environment is to inject environment variables into the source code, building a binary specific to the target environment.  <a href="http://ant.apache.org/manual/Tasks/property.html" target="_blank">Ant properties</a> and <a href="http://maven.apache.org/guides/getting-started/index.html#How_do_I_filter_resource_files" target="_blank">Maven filters</a> can make this very easy, but I would like to propose a much better approach.</p>
<p>The goal should be to build an <em><span style="text-decoration:underline;">environment agnostic</span></em> binary file that discovers any environment specific information at startup.  There are a number of ways to do this, but I find that it is easiest to do this in the database.  When your application starts up, it looks into the database and loads data from a key/value pair table that contains environment specific properties.  The reason I prefer using the database to say, a property file, is that you have already setup an environment specific configuration for your <a href="http://www.oracle.com/technetwork/java/index-jsp-137536.html" target="_blank">JNDI</a> data source in the application server.  You also likely already have some type of deployment process for the database, which you can utilize to manage the key/value table.  If you don't, then I recommend looking at a database management tool like <a href="http://www.liquibase.org/" target="_blank">Liquibase</a>, which I mentioned in my <a href="http://earlyandoften.wordpress.com/2010/06/28/intro-to-liquibase/" target="_blank">previous post</a>.</p>
<p>To further simplify this implementation, I recommend using a configuration abstraction framework like <a href="http://commons.apache.org/configuration/" target="_blank">Commons Configuration</a>, which allows you to load properties from a variety of sources, including a database.</p>
<p><strong>Automate</strong></p>
<p>I would be remiss if I did not mention <span style="text-decoration:underline;"><em>automated testing</em></span>.  You could implement a Build Once Deploy Many approach without implementing any automated tests, but you that your confidence in your builds increases significantly if you automate your tests and integrate them into your build process.  If you are able to achieve test coverage of 80% or higher, you will find you are able to make changes faster and deploy more often with less headaches.</p>
<p>What you will find once you implement this process is that it enables a variety of other process improvements.   One of these processes is <em><span style="text-decoration:underline;">automated deployments</span></em>, which your continuous integration server can easily orchestrate this whole process and provide you with nightly and/or push button deployments.</p>
</p>
  			<a href="/blog/intro-to-liquibase.html"><h1>Manage Database Changes with Liquibase</h1></a>
  			<p>28 June 2010</p>
  			<p><p>I love discovering a new tool, especially when it completely changes the way you approach developing software.  <a title="Liquibase" href="http://www.liquibase.org/" target="_blank">Liquibase</a> is one of those tools.  Once I came across their site and started reading more about it and how simple it was, I started to reflect back on all the failed production migrations I had in the past, and I shed a tear for all the weekend hours I lost.  No longer will that be the case!</p>
<p><img class="alignright" title="Liquibase Logo" src="http://www.liquibase.org/custom_images/liquibase_logo.gif" alt="Liquibase" width="342" height="64" /></p>
<p><strong>What is Liquibase?</strong></p>
<p>Liquibase is an open source database change management tool built on Java.  Rather than writing SQL directly against the database to create, update or drop database objects, developers define their desired database changes in XML files.  The XML file, called a <a title="Liquibase Changelog" href="http://www.liquibase.org/manual/databasechangelog" target="_blank">changelog</a>, contains a list of <a title="Liquibase Changesets" href="http://www.liquibase.org/manual/changeset" target="_blank">changesets</a> that define a desired database change in an database agnostic abstraction.  The changelog is intended to contain an evolving list of database changes the team would like to apply to a target database.  This list is additive over time.  Here is a simple example:</p>
<pre class="prettyprint language-xml">
&lt;databaseChangeLog&gt;
   &lt;changelog id=&quot;FOO-196-01&quot; author=&quot;Mike McGarr&quot; &gt;
      &lt;createTable tableName=&quot;users&quot;&gt;
         &lt;column name=&quot;id&quot; type=&quot;int&quot;&gt;
            &lt;constraints primaryKey=&quot;true&quot; nullable=&quot;false&quot;/&gt;
         &lt;/column&gt;
         &lt;column name=&quot;name&quot; type=&quot;varchar(100)&quot;&gt;
            &lt;constraints nullable=&quot;false&quot;/&gt;
         &lt;/column&gt;
      &lt;/createTable&gt;
   &lt;/changelog&gt;
&lt;/databaseChangeLog&gt;
</pre>
<p>Liquibase can be executed through either the command line or as part of a build using Ant, Maven or the like (I would recommend build integration).  Liquibase will apply the changesets directly to the database and can handle rollbacks and tagging of database state.</p>
<p><strong>How does it work?</strong></p>
<p>When Liquibase is executed, you must specify the database against which to apply your changesets.  Liquibase uses two tables to manage changes to the database: databasechangelog and databasechangelock.  If the tables don't exist on the target database, they are created.  An entry is added to the databasechangelock table which ensures only one instance of Liquibase is running at a time.  The databasechangelog table contains a listing of every changeset that has been applied to this database.  Liquibase conducts a diff of the table contents with the XML files and determines which changes still need to be applied.  Once this is determined, Liquibase will then apply the changes to the database.  If you are new to Liquibase, then I recommend checking out their documentation on how to setup and get <a title="Liquibase Quick Start" href="http://www.liquibase.org/quickstart" target="_blank">started</a>.</p>
<p><strong>Using Liquibase on a Team</strong></p>
<p>When working on a team, I found that there are two key lessons to learn.  The first is to make sure that you organize your changelog files in version control.  The current Liquibase <a title="Organizing your Changelogs" href="http://www.liquibase.org/bestpractices#organizing_your_changelogs" target="_blank">Best Practice page</a> recommends organizing your changelog files in a single directory, with each file named by a release number.  A previous version of the Liquibase <a title="Previous Version of Organizing your changelogs" href="http://www.liquibase.org/bestpractices?rev=1237998242#organizing_your_changelogs" target="_blank">Best Practice page</a> recommended using a folder per release and allowed for multiple changelog files per release.  This also allows developers to create a changelog file for a set of logical changes as part of a release.  Our team chose the later approach and have been successful with a small team.  I can see the advantages of using the "single file per release" approach as well, but the key point is you should choose one approach for organizing your files.</p>
<p>The second key lesson we learned was to utilize a separate database schema for each developer.  You do not want developers to be testing out their database changes against the same database schema prior to check-in.  For the same reason developers test their code changes locally on their own machine before checking code in, you want them to be able to test their database changes.</p>
<p><strong>Guidelines for Using Liquibase</strong></p>
<p>In addition to the team recommendations I outlined above, I have a few other guidelines for how to best utilize Liquibase in your environment.</p>
<ul>
<li><span style="text-decoration:underline;">Follow their Best Practices</span> - When I first started using Liquibase, their Best Practices page had a number of recommendations on it that I found very helpful.  They have since trimmed this page down and I am not sure why.  Since their main site is a Wiki, I recommend reading the previous versions of this <a title="Best Practices" href="http://www.liquibase.org/bestpractices?rev=1237998242" target="_self">page</a>.</li>
<li><span style="text-decoration:underline;">Minimize Rollbacks</span> - While in the midst of development, a developer should minimize the amount of rollbacks they conduct.  You should reserve rollbacks for failed migrations or backing code out from a test environment.  If a developer adds a table, and decides they no longer need this table, then simply add another entry in the changelog to drop the table.</li>
<li><span style="text-decoration:underline;">Only Use Liquibase</span> - If your team is starting to use Liquibase, it is a good idea to make it a rule that all database changes should be made through Liquibase.  If you only use Liquibase, it makes it easier to keep track of all the changes you made.  But if you only sometimes use Liquibase, there is good chance you will miss something when it comes time to migrate.</li>
<li><span style="text-decoration:underline;">Consider Continuous Integration</span> - I find it hard to envision using Liquibase without automating its use through a Continuous Integration Server.  By using a Continuous Integration Server, you can have your development database updated on a nightly basis, integrating all changes checked in that day.  This of course should coincide with a deployment of the application that matches the version of the database, which should also be automated through your CI Server.</li>
<li><span style="text-decoration:underline;">Make Sure You Test!</span> - It is important to add some integration tests to your automated build.  This helps ensure that your code has been updated to take into account the changes to the database schema.</li>
<li><span style="text-decoration:underline;">Define a Volatile Schema</span> - In our automated build, we defined a database schema that our nightly build points to that is only used for nightly builds.  Our Liquibase process runs before the integration tests that depend on these changes.  If our build fails for whatever reason, we don't want the database changes to have been migrated to our development database.  If the build is successful, then we re-run Liquibase, this time pointing it at the development database.  This takes longer but ensures that changes migrated to the development database will work.</li>
<li><span style="text-decoration:underline;">Be Consistent about Naming!</span> - Liquibase doesn't force you to name every constraint you define, which allows you to leave it up to the database to autogenerate a name.  This can get you into trouble, especially if some of your constraint names are explicitly defined and use the same naming convention as the database.  I recommend explicit naming to avoid this issue. (Remember, names should be portable between environments.)</li>
<li><span style="text-decoration:underline;">Use a Context</span> - Liquibase provides a context feature that allows you define when this changelog gets applied.  It is useful for defining changes that should only be applied to say a test or demo database.  Just add the context to the changeset and then when you configure your various databases, make sure each one defines the contexts it uses.  Don't get carried away though!</li>
<li><span style="text-decoration:underline;">Reset your Changelogs Periodically</span> - If your project uses Liquibase for long enough, you will find that you accumulate a lot of changelogs.  It is a good idea to use Liquibase to build a completely new changelog after a major release.  This will cut down on the time it takes to build.</li>
</ul>
<p><strong>A Caution about Schemas</strong></p>
<p>What I found very early on is that you have to determine whether or not you are going to define schemas in your changelogs.  This decision should be based on the environment you are in.  In our environment, we decided to have the schema implied based on the default schema of the connection, which is usually the username.  This was due to the fact that each developer had their own schema on the same machine for development.  If we had hardcoded a schema for our application, this would mean each developer would need their own database server with that schema name.  We found this approach to be easier and it worked, so long as you have the correct database schema defined for the connection.</p>
</p>
  			<a href="/blog/interview-for-sd-times.html"><h1>Interview for the SD Times</h1></a>
  			<p>18 June 2010</p>
  			<p><p>I was recently interviewed by the Software Development Times on my opinions Java 7, the OpenJDK, Java EE 7 and the future of Java.  The article was recently published in this month's issue of the SD Times.  If you are interested in viewing the article, check out the PDF version of the SD Times <a href="http://www.sdtimes.com/content/SDTimesPDFEdition.aspx?File=sdtimes248.pdf" target="_blank">here</a>, just flip to page 22.  You have to sign-up for an account, but that takes but a second.  Enjoy and let me know your thoughts!</p>
</p>
  			<a href="/blog/practical-unit-testing.html"><h1>A Practical Approach to Unit Testing</h1></a>
  			<p>07 May 2010</p>
  			<p><p>Last year I was asked to give a one day workshop on how to write unit tests.  I put together a presentation and workshop format and it was a huge success.  The team quickly took to not only writing unit tests but was able to quickly utilize mock frameworks and other testing tools.  The team's code coverage for the application quickly increased and management was pleased.  I recently took another look at this presentation to see if I wanted to revise anything and I thought I would share some of the thoughts here.  These guidelines are intended to get somebody started with unit testing quickly, but could be a welcome refresher for somebody who has been writing tests for a while.</p>
<p><strong> Benefits of Unit Testing</strong></p>
<p>I won't belabor this point, simply because there is too much literature floating around the internet on why to unit test your code.  In fact, I think that you would be hard pressed to find anybody who would disagree on this point.  I have found however that a surprisingly high percentage of developers I have encountered agree that writing unit tests is good, but still don't know how to do it.  Regardless, here is a list of some (but not all) of the benefits of conducting unit testing:</p>
<ul>
<li>Reduces New Bugs</li>
<li>Reduces Bugs from Reappearing</li>
<li>Enables Refactoring</li>
<li>Improves Design</li>
<li>Forces you to Think</li>
<li>Reduces Fear</li>
<li>Speeds the Development Process</li>
<li>Can Provide a Form of Documentation</li>
</ul>
<p>I am certain that there are more than this, so feel free to leave me a comment and let me know your thoughts.</p>
<p><strong>Where to Start Testing</strong></p>
<p>Projects that are trying to start unit testing usually stop when they try to determine which part of their code they should test first.  I decided that my guidance on where to start depends on the developer's level of proficiency with writing unit tests.</p>
<p>If you are a unit testing newbie, then you should start by writing unit tests against a utility class.  Utility classes tend to have very little external dependencies and have a simple input/output approach.  You will find that a basic lesson in using <a title="JUnit's Website" href="http://www.junit.org/" target="_blank">JUnit</a> will provide you all the information you need to test these methods.</p>
<p>For developers experienced in unit testing, then your goal should be to focus on the most critical components in your application.  This code should meet at least one of the following criteria:</p>
<ul>
<li>most commonly used functions</li>
<li>most critical functions (security, DAOs, business/service classes)</li>
<li>most complex functions (high cyclomatic complexity)</li>
</ul>
<p>My preferred IDE, <a title="Eclipse" href="http://www.eclipse.org/" target="_blank">Eclipse</a>, provides some simple wizards for creating unit tests quickly.  I also prescribe the to <a title="Maven" href="http://maven.apache.org/" target="_blank">Maven</a> <a title="Maven Standard Directory Layout" href="http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html" target="_blank">project structure convention</a> of storing all of my unit tests in the project's src/test/java directory.  If this is your first time writing unit tests, then I recommend that you follow the <a title="JUnit Cookbook" href="http://junit.sourceforge.net/doc/cookbook/cookbook.htm" target="_blank">JUnit cookbook</a> for a guide on how to write unit tests with JUnit.</p>
<p><strong>Writing Meaningful Tests</strong></p>
<p>It is important to understand how to write meaningful unit tests, which are tests that focus on testing the behavior of the Class Under Test (CUT).  This focus on behavior is the central motivation of <a title="BDD" href="http://behaviour-driven.org/" target="_blank">Behavior Driven Development (BDD)</a>, which teaches that unit tests should be structure in a <a title="Given When Then" href="http://blog.objectmentor.com/articles/2008/11/27/the-truth-about-bdd" target="_blank">"Given, When, Then"</a> structure.  While I would support any team moving to a full BDD implementation using frameworks like <a title="easyb" href="http://www.easyb.org/" target="_blank">easyb</a> or <a title="JBehave" href="http://jbehave.org/" target="_blank">JBehave</a>, it isn't necessary.  If you read Dan North's article on the <a title="Introducing BDD" href="http://blog.dannorth.net/introducing-bdd/" target="_blank">evolution of BDD</a>, he discusses how he struggled to teach developers how to write good unit tests, and the key was semantics.  He first wanted developers to think of their test names as sentences rather following the existing convention of prefixing the word test to the method under test. I really liked this concept and I felt that the focus on behavior coupled with the meaningful test names helps developers significantly.  So came up with these guidelines:</p>
<ul>
<li>Each test method should map to a behavior and/or condition of the CUT</li>
<li>Each test method's name should be descriptive enough to define the behavior/conditions being tested</li>
<li>Each test method should have assertions that validate the behavior/conditions being tested</li>
</ul>
<p>Sounds great, but I think that an example might be more meaningful.  Let's imagine we are testing a utility class that will convert Celsius to Fahrenheit and back again.  When we stub out a unit test class, this is what it looks like.</p>
<pre class="prettyprint language-java">
public class TemperatureUtilTest
{
  @Test public void testCanConvertCelsiusToFahrenheit () {...}
  @Test public void testCanHandleNullFahrenheit() {...}
  @Test public void testCanHandleInvalidFahrenheit() {...}
  @Test public void testCanConvertFahrenheitToCelsius() {...}
  @Test public void testCanHandleNullCelsius() {...}
  @Test public void testCanHandleInvalidCelsius() {...}
}
</pre>
<p>What is great about this format, as Dan North points out, is if you remove the Java syntax and the word "test" from the code, you are left with:</p>
<blockquote><p>TemperatureUtil...</p>
<p>...can convert Celsius to Fahrenheit.</p>
<p>...can handle null Fahrenheit.</p>
<p>...can handle invalid Fahrenheit.</p>
<p>...can convert Fahrenheit to Celsius.</p>
<p>...can handle null Celsius.</p>
<p>...can handle invalid Celsius.</p></blockquote>
<p>This serves as a good depiction of the behavior of the CUT.   This is a good example of how unit tests can serve as documentation.  One of the problems with this documentation is that it is deeply embedded in the code and not easily extracted, a problem which is further addressed with BDD and <a title="Acceptance Test Driven Development" href="http://www.methodsandtools.com/archive/archive.php?id=72" target="_blank">Acceptance Test Driven Development (ATDD)</a> frameworks and tools.</p>
<p><strong>Write Simple Assertions</strong></p>
<p>Now that you have your test methods stubbed out, start writing your tests.  Your tests should be short and sweet, passing in the control input data to the method under test and then asserting the results of the test.  Many sites state that a unit test should only have one assertion and I agree with the philosophy of this approach, but I don't enforce it in practice.  Rather, your assertions should be testing the behavior, which may mean more than one assertion.  Let's look at a quick example of a test method.</p>
<pre class="prettyprint language-java">
@Test public void testCanConvertCelsiusToFarhenheit()
{
  Fahrenheit fTemp = new Fahrenheit(32);
  Celsius cTemp = TemperatureUtil.convert(fTemp);
  assertEquals(0, celsius.getTempAsInt());
}
</pre>
<p>Pretty straight forward.</p>
<p><strong>Some final thoughts</strong></p>
<p>I definitely do not consider this the most comprehensive approach to unit testing, but I think that some of this information could be helpful to somebody starting out.  Good luck and remember that unit testing can be fun!</p>
</p>
  			<a href="/blog/follow-the-leaders.html"><h1>Follow the Leaders</h1></a>
  			<p>19 April 2010</p>
  			<p><p>Do you want to get smarter on technology topics?  Me too!  In fact, in the software industry, there is way too much to learn and I am constantly adding to my "Learn This" list.  This list is useful (and sometimes daunting), and I try to work hard to widdle it down.  But my "Learn This" list is subjects and topics that I am aware of.  What about areas of software innovation that I am unaware of that might be useful for me to learn...how does one find out about the new and exciting?</p>
<p>What I have found that works is to simply <strong>Follow the Leaders</strong>.  Most industries have thought leaders (established and emerging) who push the boundaries of the establishment to redefine what we already know to be true, or define something we don't yet know.  Some of these leaders are world renown and some of them are only known in very small circles.  Most all of them, however, take full advantage of Web 2.0 technologies and use simple and cheap tools like blogs, micro-blogging and other social media tools to share their knowledge, and this can be a huge advantage for the rest of us!</p>
<p><strong>RSS is your friend<a href="http://earlyandoften.files.wordpress.com/2010/04/fig2.gif"><img class="alignright size-full wp-image-293" title="rssicon" src="http://earlyandoften.files.wordpress.com/2010/04/fig2.gif" alt="RSS icon" width="160" height="160" /></a><br />
</strong></p>
<p>If you want to make yourself smarter in your field, one of the simplest things you can do is follow the blogs and <a href="http://www.twitter.com">Twitter</a> feeds of industry leaders.  You could bookmark all the URLs to their blogs and check them constantly, but that can be extremely cumbersome.  My suggestion is to take advantage of a <a href="http://en.wikipedia.org/wiki/RSS">RSS</a> (Really Simple Syndication) reader.</p>
<p>I won't go into full blown definition of RSS, but if you're interested in more information, <a href="http://www.whatisrss.com/">check this out</a>.  What is important is that an RSS reader will allow you to subscribe to a website (news, blogs, even Twitter) and then receive a copy of the latest article from the site, without ever having to go there.  There are a number of RSS readers on the market right now, but the one I am using and have had a lot of success with is <a title="Google Reader" href="http://www.google.com/reader" target="_blank">Google Reader</a>.  I would recommend you set up an account for free and check it out.</p>
<p><strong>Twitter as a business tool</strong></p>
<p>Forget what you think about Twitter.  It isn't like <a href="http://www.facebook.com">Facebook</a>.  Well, ok, it is in the sense that many people will tell you what they are doing every minute of every day to the point that you don't care.  But Twitter can be an extremely useful tool for finding out new information and discovering new people of interest in your field.  I mainly follow technologists and I find that their tweets to be a wealth of information.  If you don't believe me, read this article from the NY Times about <a href="http://www.nytimes.com/2010/03/04/technology/04basics.html?adxnnl=1&amp;partner=rss&amp;emc=rss&amp;adxnnlx=1267829868-WyDipNIEpqJGOt1cbWGgKA">getting the most out of Twitter</a>.</p>
<p><strong>Start Small</strong></p>
<p>Once you have a RSS reader setup, you will need to add some useful sites to it.  Start by googling somebody you know from the industry.  What's the name of the guy that created that open source project I love?  Who was that guy that spoke at that conference?  Who just left Sun/Oracle?  Google them, find their blog and add the RSS feed to you reader.  If they have a Twitter account, follow them.  Don't try and find everybody you can think of immediately, because you just won't be able to do it; just start small.</p>
<p><strong>5 Minutes a Day</strong></p>
<p>Make an effort to check your RSS reader everyday.  A simple way of doing this is to check Google Reader from your smart phone (don't have a smart phone? why not?).  I have Google Reader bookmarked on my iPhone and I check it any chance I get.  My wife loves it when I do this.  It only takes 5 minutes a day to open up the reader and read one article or blog entry.  You will find that you are reading articles waiting in line, at the doctor's office, wherever you have a spare few minutes.</p>
<p><strong>Build Your Network</strong></p>
<p><strong><span style="font-weight:normal;">As you begin reading blogs, you will notice that most experts also tend to refer to or quote other experts.  Usually they will provide a link to another blog.  You should make a point of adding this individual to your RSS as well.  If somebody you respect is quoting somebody else, it means they either agree or disagree with this person.  In either case, it is useful to add this person to your blog too.  You want to build a network of experts with a variety of experience, who can paint a diverse picture of a subject for you.  One perspective is usually not good enough (something I learned as a History major!).</span></strong></p>
<p><strong><span style="font-weight:normal;">Also, don't stop at blogs.  Most of these experts also have Twitter feeds which allow them to micro-blog.  These experts are more likely to say, "Hey, check out this cool article" on Twitter than on a blog.  You can also see who an expert follows on Twitter, which may mean you should follow them.  If you see your expert retweeting this individual's tweets or engaging in a dialogue, then check them out!  Usually a Twitter feed has a reference to an individual's blog on it.  Now you can add their blog to your RSS reader!</span></strong></p>
<p><strong><span style="font-weight:normal;"><strong>Keep it Organized</strong></span></strong></p>
<p>This process can lead to an explosion of blogs in your Reader.  I currently subscribe to 78 different blogs.  Luckily, Google Reader allows me to set up folders for these blog feeds so that I can at least apply some organization to them.  You will find that your ever expanding blog subscription list will feel a lot more manageable.  Also, don't be afraid to cut some fat.  If you find that you never like or read entries from an certain blog, unsubscribe to it.</p>
<p><strong>Remember to Have Fun</strong></p>
<p>My last bit of advice is to have fun.  You need to have a balance of work and fun.  You can add ESPN to your RSS reader and find out what's going on with the Red Sox or you can subscribe to your friends food blog and find out how to make a restaurant quality steak.  You will find that having this balance keeps you coming back for more.</p>
</p>
  			<a href="/blog/getting-back-into-the-swing-of-things.html"><h1>Getting back into the swing of things</h1></a>
  			<p>18 April 2010</p>
  			<p><p>After almost two months of digital silence, I am inching my way back online.  I took a brief hiatus to get married and go an awesome honeymoon, and I think that I am now just getting back to my blog, twitter feed and general nerding.  It is also golf season and I couldn't be more excited to get out there and play.</p>
<p>So, regarding technology, I have working on a lot of fun stuff and in general just refining my craft.  I expect to be updating my blog with a lot of good stuff, and maybe even some questions, so stay tuned...cause I am not going anywhere!</p>
</p>
  			<a href="/blog/branching-a-multi-module-maven-project-in-eclipse.html"><h1>Branching Problems with a Multi-Module Maven Project</h1></a>
  			<p>16 February 2010</p>
  			<p><p>I was impressed last year when I found that the <a href="http://m2eclipse.sonatype.org/" target="_blank">M2eclipse</a> <a href="http://www.eclipse.org/" target="_blank">Eclipse</a> plugin handled multi-module projects checked out of <a href="http://subversion.tigris.org/" target="_blank">Subversion</a> using <a href="http://subclipse.tigris.org/" target="_blank">Subclipse</a> with ease.  Eclipse does <a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=35973" target="_blank">not natively support</a> a nested multi-module project structure <a href="http://maven.apache.org/guides/getting-started/index.html#How_do_I_build_more_than_one_project_at_once" target="_blank">recommended by Maven</a>, and getting the two to work well together has historically been a pain.  M2eclipse has solved this by "mapping" the child modules of the project you are importing to sibling projects in your Eclipse workspace.  For example, lets take the following multi-module Maven project:</p>
<p style="text-align:center;"><a href="http://earlyandoften.files.wordpress.com/2010/02/multimodelproject.png"></a><a href="http://earlyandoften.files.wordpress.com/2010/02/finder-view.png"></a><a href="http://earlyandoften.files.wordpress.com/2010/02/finder-view1.png"><img class="size-full wp-image-226 aligncenter" title="Project Structure." src="http://earlyandoften.files.wordpress.com/2010/02/finder-view1.png" alt="" width="164" height="154" /></a></p>
<p>This project consists of one parent project (springapp) which has four child modules (core, model, utility and webapp).  In the second image below, you can see that when this project is imported into Eclipse using M2eclipse, 5 projects have been created.  There is one project for each of the child modules and one for the parent project.  As you can see from the expanded view of parent module, it still includes the directories of the child modules, even though they are also contained in sibling projects in Eclipse.  This is only moderately confusing.</p>
<p style="text-align:center;"><a href="http://earlyandoften.files.wordpress.com/2010/02/eclipse-view.png"></a><a href="http://earlyandoften.files.wordpress.com/2010/02/eclipse-view1.png"></a><a href="http://earlyandoften.files.wordpress.com/2010/02/eclipse-view1.png"><img class="size-full wp-image-215 aligncenter" title="Project view from inside Eclipse" src="http://earlyandoften.files.wordpress.com/2010/02/eclipse-view1.png" alt="View of project from Eclipse." width="204" height="258" /></a></p>
<p>It has served us well and I haven't experienced any real issues until today.  As is common practice, I reached a point where I wanted take my work from the trunk and create a branch.  I had a bunch of working files not checked in, so I wanted to just create a branch right from my working directory.  There is this option in Subclipse to Branch/Tag (remember that in Subversion, the act of branching or tagging is essentially no different, both are simple copy commands to another directory).  So I went ahead and highlighted all Eclipse projects, right click on them and then choose the Branch/Tag option, following the wizard that walked me through the process.  When I was done and my code was branched, I felt pretty good, until I took a closer look at the code in the branch.</p>
<p style="text-align:center;"><a href="http://earlyandoften.files.wordpress.com/2010/02/subversion-view.png"><img class="size-full wp-image-222 aligncenter" title="Project Incorrectly Branched in Subversion" src="http://earlyandoften.files.wordpress.com/2010/02/subversion-view.png" alt="View of Subversion After bad Branching" width="203" height="421" /></a></p>
<p>If you compare the project structure in the trunk to the project structure in new-work-branch, focusing on the highlighted folder, you can see that something is amiss.  I checked in the 5 Eclipse projects as if they were separate modules of the springapp project instead of treating them like one project to check in.  Luckily I caught this before I did any real damage, although my solution was to remove the branch and start over again.  What I should have done was to select only the parent project when I started my branching effort, since the parent project in Eclipse encompasses all of the child projects as well.  Lesson learned!</p>
<p>While we could easily blame this problem on Maven for having a multi-module setup or even m2eclipse for allowing this happen, the truth is, the Eclipse platform should natively support hierarchical or nested project structures, like other IDE's do.  This has been a user request for some time, and with my experience today, I feel even more strongly about the need to make this change.</p>
</p>
  			<a href="/blog/why-i-hate-ant.html"><h1>Why I Hate Ant</h1></a>
  			<p>15 February 2010</p>
  			<p><p>OK, let me address the title of this blog before the whole Java open source community jumps down my throat.  I do not really hate Ant, in fact Ant is a great and invaluable tool.  Ant helps simplify building and deploying Java applications.  It is extremely powerful and flexible and allows you to do pretty much anything you want as part of your build process.  Ant's flexibility is what has helped it gain popularity in the Java community, and this flexibility is at the core of my Ant critique.</p>
<p>I came to this realization recently when I recommended to a colleague that I help him convert his open source project from Ant to Maven.  I have spent the last three years evangelizing the tenants of Maven over Ant and how it solves many of Ant's problems (conventions over convenience, dependency management).  I also enumerated some of the issues I have experienced with using Maven, such as dependency bloat, steeper learning curve, and decreased build transparency to name a few.  In spite of this, I still felt that Maven was a better solution for most open source projects and can help projects integrate quicker.</p>
<p>Once it was agreed that Maven was to be used as the build management tool, I set off looking at the Ant build script for the project.  I began this endeavor confident that I could quickly dissect the build script and convert the project to Maven.  This confidence, however, was misplaced as I forgot how complex Ant build scripts can get.  I spent the next hour or so building a reverse call tree from the Ant target hierarchy.  Once I had this call tree, my next step was to figure out what each of these targets did so I could map them to a Maven lifecycle phase and an appropriate plugin.</p>
<p>The biggest problem with Ant is the complexity of the builds scripts.  A new developer has no way of knowing what the build steps are until he literally walks through the call stack of the Ant targets.  This can take a while and can be complex, especially if the Ant script was written by a pro.  Now this process may sound similar to following the call stack of any application you are new to, and it is.  But Java applications have Javadocs (or they should) to provide a simple way of understanding the code and most applications utilize design patterns as a common language for how the code is organized.  Ant doesn't have a documentation standard and it doesn't utilize design patterns for organizing targets.  An Ant script is essentially a functional program for your build process.</p>
<p>There are other reasons why I prefer Maven over Ant, some of which I mention above, but in the end, this reason far outweighs all the others.  Maven's convention over configuration approach makes understanding build scripts exponentially easier than it does in the Ant world.</p>
</p>
  			<a href="/blog/enforcing-coding-standards.html"><h1>Enforcing Coding Standards</h1></a>
  			<p>10 February 2010</p>
  			<p><p>While most teams recognize the importance of coding standards, I have witnessed too many development teams who define a set of coding standards, yet do not enforce them.  If you are not enforcing the coding standard, then you have no way of knowing your team's compliance with the standard and its effectiveness is negated.  In this article, I hope to share some of my experiences with enforcing coding standards on software development projects.</p>
<p><strong>Why are Coding Standards Important?</strong></p>
<p>Convincing management of the importance of  implementing coding standards is one of the first steps to successfully adoption.  You will need to justify the time you will spend defining, documenting, communicating, fostering adoption and enforcing your coding standards.  Your project manager will likely ask you the question, "So what are the benefits of implementing coding standards on our project?".  Here are a few of the benefits of coding standards:</p>
<ul>
<li><span style="text-decoration:underline;">Increased maintainable</span> - developers can quickly look at another developer's code and easily read it</li>
<li><span style="text-decoration:underline;">Increased staffing flexibility</span> - developers can move between modules in the application and not have to adjust to a team members coding styles</li>
<li><span style="text-decoration:underline;">Facilitates better designs</span> - for instance, limiting all methods to 40 lines forces developers to think about the functionality of the method</li>
<li><span style="text-decoration:underline;">Coding standards can improve documentation</span> - one of my favorite rules is to enforce strict Javadocs throughout the code</li>
</ul>
<p>Great, you management is on board and you have clearance to define and implement coding standards...what's next?<br />
<strong> </strong></p>
<p><strong>Defining the Standard</strong></p>
<p><strong> </strong>In my opinion, this is where most teams go wrong (including myself).  They want to collect all the various standards that are publicly defined, meet with the whole development team and then discuss in detail each of the standards one by one.  This process can be time consuming, taking hours or even days, and you likely walk away without a team wide consensus.</p>
<p>I recommend taking an Agile approach to defining your coding standards: define your standards as early as possible and evolve them often (early and often).  Instead of building a consensus within the team by deliberating for days on the standards, start with an existing publicly available standard that you mostly agree with (like <a href="http://java.sun.com/docs/codeconv/" target="_blank">Sun's Java Coding Standards</a>) and adopt that. <a href="http://checkstyle.sourceforge.net/" target="_blank">Checkstyle</a>, a code standard enforcement tool, can enforce this standard out of the box with a standard definition file.  Check in a copy of the Checkstyle file into your source code.  When you apply this standard against your team's current source code, members of the team will begin the complain about certain violations being reported.  This is good.  They can make changes directly to the Checkstyle configuration file to change the standard.  The team should feel like their coding standard is theirs to change and update as they wish, so give them the opportunity to own it and change it, within reason of course.</p>
<p>It is also important to make sure that team knows what the standard is so they can start using it.  Part of this process is making sure that the coding standard is documented.  I personally do not recommend that you go out and create a lengthy Word document detailing every coding standard (I have done this before and it is painful and useless).  If you must document the standard, use a Wiki page which is easily accessible to the team and easy to maintain.  Your wiki page should merely point to the publicly available standard you previously chose and possibly provide a link to the Checkstyle definition file in source control.  Remember, you are defining a standard for developers, who prefer something functioning (like Checkstyle) over the written word.</p>
<p><strong>Adopting the Standard</strong></p>
<p>In order to facilitate the adoption process, there are a number of tools you should provide your team that will make it easy for them to migrate to the new coding standard.  We already mentioned using Checkstyle to define the standard.  Checkstyle is a command line tool that can be integrated with common build tools such as <a href="http://ant.apache.org/" target="_blank">Ant</a> or <a href="http://maven.apache.org/" target="_blank">Maven</a>.  While build time analysis of the coding standard is useful for reporting, developers need immediate feedback on their compliance as they write code.  To achieve this, I recommend using Checkstyle integration directly in your IDE.  Checkstyle has plugins for <a href="http://www.eclipse.org/" target="_blank">Eclipse</a>, <a href="http://netbeans.org/" target="_blank">Netbeans</a>, <a href="http://www.jetbrains.com/idea/" target="_blank">IntelliJ</a> and more.  This integration allows the developers to see the violation as they type and address it immediately, preventing new violations from entering the code.</p>
<p>In addition to Checkstyle integration, IDE like Eclipse provide out of the box code formatters that can format your code to a given standard.  Unfortunately, Eclipse's formatter definition is decoupled from a Checkstyle definition so as your Checkstyle definition file changes, you will also have to make changes to your Eclipse formatter definition, but it is worth the effort.</p>
<p>Once your standard is well defined, you can use a bulk formatting tool like <a href="http://jalopy.sourceforge.net/" target="_blank">Jalopy</a> to format all of your source code in one sweep.  I am hesitant to recommend this approach due to the possibility of introducing bugs due to formatting changes (this is possible).  If you have a lot of unit tests, then the risk of using this tool decreases significantly.  If you do want to use Jalopy, make a separate branch of your source code first, this will reduce the risk to the mainline of development, especially if you are working on legacy code.</p>
<p><strong>Enforcing the Standard</strong></p>
<p>Great, so now you have a code standard defined.  You need to start enforcing it.  After doing this on multiple projects, the most useful method of enforcing coding standards is to integrate Checkstyle into your Continuous Integration (CI) builds.  If you aren't using a CI server like <a href="http://hudson-ci.org/" target="_blank">Hudson</a>, consider adding this to your list of reasons why you need to add a build server to your infrastructure.  I have been using Hudson successfully for a while and I am huge fan of its simplicity.</p>
<p><img class=" " title="Checkstyle Trends" src="http://wiki.hudson-ci.org/download/attachments/31457291/graph-priority.png?version=1&amp;modificationDate=1242230697000" alt="Checkstyle Trends" width="410" height="170" /></p>
<p>Every night, our Hudson server runs Checkstyle against the code base to determine how many code standard violations exist in the code.  Hudson trends the number of violations over consecutive builds, which is useful for tracking the team's progress during a lengthy adoption effort.  Hudson's dashboarding capabilities allow the team easy access to the details of violations drilling down to the exact line of code.  Hudson can also be set up to define thresholds, which can mark the build as unstable or even fail the build if too many Checkstyle violations are introduced into a build.  This ability coupled with Hudson's multiple feedback mechanisms provides the team will daily reminders that the application code is in violation of the standard.</p>
<p>Another tool I utilize to help encourage adoption of the coding standard was a cool Hudson plugin called the <a href="http://wiki.hudson-ci.org/display/HUDSON/The+Continuous+Integration+Game+plugin" target="_blank">Continuous Integration game</a>.  This plugin assigns positive and negative point values to successful and failed builds, as well as Checkstyle violations.  It then provides the team with a Leaderboard showing how many points are assigned to each developer.  This may sound a bit sophomoric, but I saw a profound difference in each developer's attitude towards resolving coding standards.  This plugin taps into everybody's competitive spirit, but it should be used with some <a href="http://www.chillisoft.co.za/blog/?p=244" target="_blank">caution</a>.</p>
<p>In summary, if you want your team to quickly adopt a coding standard,  you need define the standard early, make the it easily available to the team and integrate standard checks with your continuous integration server.  The key to making this successful is ensuring that the whole process is inexpensive to setup and maintain.  Enjoy and good luck!</p>
</p>
  			<a href="/blog/maven-cobertura-and-aspectj.html"><h1>Maven, Cobertura and AspectJ</h1></a>
  			<p>04 January 2010</p>
  			<p><p>I recently ran into an issue running Cobertura code coverage reports on my Maven2 project.  It appears that Cobertura is not being run, since the code coverage reports always showed 0% code coverage in spite of the existence of numerous unit tests.  This problem had appeared early in the project and seemed to disappear magically, so I wrote it off.  Now that it is back, I was determined to find the answer, and I have.</p>
<p>Cobertura is a code coverage tool that measures the amount of code exercised by your unit tests.  Cobertura works by instrumenting your application's byte code, which occurs after compilation.  When the instrumented code is called by your unit tests, Cobertura records which packages, files, lines, methods and even conditions are covered by your unit tests.</p>
<p>When the problem started to occurred, I spent some time analyzing Maven build outputs from successful Cobertura executions and Cobertura executions that resulted in 0% coverage (thanks to Hudson for storing all of this historical information).  Here is the output from the failing Maven build:</p>
<pre>
[INFO] Preparing cobertura:cobertura
[INFO] [aspectj:compile {execution: default}
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [resources:resources {execution: default-resources}
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 16 resources
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [compiler:compile {execution: default-compile}
[INFO] Nothing to compile - all classes are up to date
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [cobertura:instrument {execution: default-instrument}
[INFO] Cobertura 1.9.2 - GNU GPL License (NO WARRANTY) - See COPYRIGHT file
Instrumenting 86 files to /opt/data/hudson/jobs/Trunk-Nightly/workspace/main/common/target/generated-classes/cobertura
Cobertura: Saved information on 86 classes.
Instrument time: 2161ms
[INFO] Instrumentation was successful.
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [resources:testResources {execution: default-testResources}
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 16 resources
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] Preparing hibernate3:hbm2ddl
[WARNING Removing: hbm2ddl from forked lifecycle, to prevent recursive invocation.
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [aspectj:compile {execution: default}
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [resources:resources {execution: default-resources}
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 16 resources
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [hibernate3:hbm2ddl {execution: default}
[INFO] Configuration XML file loaded: file:/opt/data/hudson/jobs/Trunk-Nightly/workspace/main/common/src/main/resources/hibernate.cfg.xml
[INFO] Configuration XML file loaded: file:/opt/data/hudson/jobs/Trunk-Nightly/workspace/main/common/src/main/resources/hibernate.cfg.xml
[INFO] Configuration Properties file loaded: /opt/data/hudson/jobs/Trunk-Nightly/workspace/main/common/target/test-classes/jdbc.properties
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [compiler:testCompile {execution: default-testCompile}
[INFO] Nothing to compile - all classes are up to date
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [dbunit:operation {execution: default}
[TASKS] Skipping maven reporter: there is already a result available.
[INFO] [surefire:test {execution: default-test}
[INFO] Surefire report directory: /opt/data/hudson/jobs/Trunk-Nightly/workspace/main/common/target/surefire-reports
T E S T S
</pre>
<p>At first glance, nothing looked wrong, but then I realized that Aspectj was being run a second time, after Cobertura had already instrumented the code.  I immediately recognized that this might  be the source of the problem, but didn't know why this was happening.  I started to researched the problem and found numerous posts on the topic, but nothing that seemed to answer my question.  Then I realized that Hibernate's hbm2ddl plugin was firing during the Maven process-test-resources phase.  Once I disabled the plugin, AspectJ no longer fired a second time and Cobertura worked just fine!</p>
<p>Great, but why is this happening?  Why is Hibernate's attachment to the process-test-resources phase triggering AspectJ to re-compile the sources?  The answer lies in the source code for all three plugins.  All three of these Maven plugins have a default lifecycle phase that they attach themselves to.  Here are the Maven Lifecycle phases in order of execution from start to test:</p>
<blockquote><p>1.  validate<br />
2.  initialize<br />
3.  generate-sources<br />
4.  process-sources (<strong>aspectj:compile</strong>)<br />
5.  generate-resources<br />
6.  process-resources (<strong>hibernate3:hbm2ddl</strong>)<br />
7.  compile<br />
8.  process-classes (<strong>cobertura:instrument</strong>)<br />
9.  generate-test-sources<br />
10. process-test-sources<br />
11. generate-test-resources<br />
12. process-test-resources<br />
13. test-compile<br />
14. process-test-classes<br />
15. test</p></blockquote>
<p>Hmmm, this doesn't seem right, cause according to the default phases, cobertura should have been the last to fire.  Well, it looks like the problem was in my build script, where I had hibernate3:hbm2ddl attached to the process-test-resources phase.  Ok, so now why is hibernate3:hbm2ddl triggering aspectj:compile to run a second time?  This part is still a mystery to me.  I plan on researching this topic further and when I find an answer, I will post an update to this blog entry.  If anybody has any additional insight, please feel free to leave a comment.</p>
</p>
  			<a href="/blog/justifying-dual-monitors.html"><h1>Justifying Dual Monitors</h1></a>
  			<p>04 December 2009</p>
  			<p><p>When I asked my management for dual monitors for our development team, I was promptly asked to provide justification for the request.  I hope the research I used for to support my case is helpful to others who may find themselves in the same boat.</p>
<p>Numerous studies have proven that providing staff with a multiple monitor setup is a cheap means of increasing productivity.  The results of the studies vary in the specific numbers, but overall, teams can expect anywhere from a <a href="http://research.microsoft.com/en-us/news/features/vibe.aspx" target="_blank">10 - 50% increase</a> in an individual's productivity, which results in a simple return on investment.  It is estimated that the cost of the hardware necessary to setup dual monitors for an individual would pay for itself in a matter of weeks.</p>
<p>One study conducted by the <a href="http://www.necus.com/necus/media/press_releases/template.cfm?DID=1947" target="_blank">NEC, ATI and the University of Utah</a> showed that individuals were "10 percent more productive", "increased their errorless production by 18 percent" and were "29 percent more effective for tasks, 24 percent more comfortable to use in tasks and found it 39 percent easier to move around sources of information".</p>
<p>The use of multiple monitors as a cheap way of increasing productivity has been written about in publications ranging from the <a href="http://www.nytimes.com/2006/04/20/technology/20basics.html?_r=2" target="_blank">NY Times</a> to <a href="http://www.computerworld.com/s/article/286833/Multiple_Monitor_Proponents_Point_to_Productivity_Benefits?taxonomyId=12&amp;pageNumber=1" target="_blank">ComputerWorld</a>.  Multiple monitors allow a developer to multi-task easily, which I have found invaluable.  For example, I can work on a piece of code while monitoring a log output of a batch job running on test server all at the same time.</p>
<p>Even <a href="http://money.cnn.com/2006/03/30/news/newsmakers/gates_howiwork_fortune/index.htm" target="_blank">Bill Gates</a> has weighed in on the topic on a few occasions, and details the importance of dual monitor screens in his own office setup:</p>
<blockquote><p>"If you look at this office, there isn't much paper in it. On my desk I have three screens, synchronized to form a single desktop. I can drag items from one screen to the next. Once you have that large display area, you'll never go back, because it has a direct impact on productivity."</p></blockquote>
<p>My favorite article on this topic so far has been Jeff Atwood's <a href="http://www.codinghorror.com/blog/archives/000666.html" target="_blank">Programmer's Bill of Rights</a>, which list a number of rights that every programmer should be entitled to, first on that list being:</p>
<blockquote><address><strong>"Number 1: </strong><strong>Every programmer shall have </strong><strong>two monitors</strong><br />
With the crashing prices of LCDs and the ubiquity of dual-output video cards, you'd be crazy to limit your developers to a single screen. The productivity benefits of doubling your desktop are well documented by now. If you want to maximize developer productivity, make sure each developer has two monitors."</address>
</blockquote>
<p>As a programmer, if you have not already transitioned to a multi-monitor setup, I highly recommend it, even if you add a monitor to your laptop setup.  Just send your boss this blog post.</p>
</p>
  			<a href="/blog/a-hack-to-syncing-multiple-google-calenders-with-your-iphone.html"><h1>A Hack to Syncing Multiple Google Calenders with your iPhone</h1></a>
  			<p>24 September 2009</p>
  			<p><p>As a proud iPhone owner, I have tried to integrate my phone with just about every aspect of my life, which of course includes all my calendars.  I also have been using Google Calendar for a long time and I love how easy it is to create multiple calendars and share them with friends and family.  I also have my work Outlook calendar I want to synchronize with my iPhone.  This sounds simple enough, right?</p>
<p>The problem is most guides I have found online only provided directions on how to sync your Google Calendar as the primary calender on your phone.  Since my primary calender is my work Outlook calender, I can't do this.  Google Sync looks very useful, but I haven't hooked it up since it uses Outlook's ActiveSync, and we all know that the iPhone can only have one ActiveSync account enabled at a time.  Google also provides a simple CalDav based solution for syncing your iPhone with your Google Calender.  If you only have Google Calender, then this solution works great and it is simple to setup.  I, however, want to see all of my multiple Google Calender show up on my iPhone, color coordinated by calendar.</p>
<p>My solution to this problem is definitely a hack (not illegal or jailbreaking, just not elegant by any stretch).  The solution is to subscribe to your Google calender through your iPhone.  This is simple in theory since all it requires is entering a URL into your iPhone.  Unfortunately, Google Calender's subscribe URL's are extremely long and it would be cumbersome to enter them into your phone.  My solution is fairly simple and successful.</p>
<p>First, on your computer, go to Google Calender and click on Settings.  Then click on the Calender tab and you should see a listing of all of the calendars you own as well as all of the calenders you are subscribed to.  Click on one of the calenders and scroll to the bottom, where you should see icons for XML, ICAL and HTML associated with both with your Calender Address and your Private Address.  Click on the ICAL icon under Private Address and copy that URL.  Paste that URL in an email to yourself that you can retrieve from your iPhone.  Open the email in your iPhone and click on the link.  Your iPhone will ask you if you want to subscribe to this calendar, just click Subscribe.  Your Google Calender should show up in your list of Calender on your iPhone.  Each one you add shows up in a different color.  It is as simple as that!</p>
</p>
	
	<hr />
	
	<p>Older posts are available in the <a href="/archive.html">archive</a>.</p>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="muted credit">&copy; 2013 | Mixed with <a href="http://twitter.github.com/bootstrap/">Bootstrap v2.3.1</a> | Baked with <a href="http://jbake.org">JBake v2.3.0-SNAPSHOT</a></p>
      </div>
    </div>
    
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="/js/jquery-1.9.1.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/run_prettify.js"></script>
    
  </body>
</html>